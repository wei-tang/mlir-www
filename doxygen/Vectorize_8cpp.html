<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: lib/Transforms/Vectorize.cpp File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">11.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_97aefd0d527b934f1d99a682da8fe6a9.html">lib</a></li><li class="navelem"><a class="el" href="dir_a72932e0778af28115095468f6286ff8.html">Transforms</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#define-members">Macros</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">Vectorize.cpp File Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &quot;<a class="el" href="LoopAnalysis_8h_source.html">mlir/Analysis/LoopAnalysis.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="NestedMatcher_8h_source.html">mlir/Analysis/NestedMatcher.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="SliceAnalysis_8h_source.html">mlir/Analysis/SliceAnalysis.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="Analysis_2Utils_8h_source.html">mlir/Analysis/Utils.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="AffineOps_8h_source.html">mlir/Dialect/AffineOps/AffineOps.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="Ops_8h_source.html">mlir/Dialect/StandardOps/Ops.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="VectorOps_8h_source.html">mlir/Dialect/VectorOps/VectorOps.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="VectorUtils_8h_source.html">mlir/Dialect/VectorOps/VectorUtils.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="AffineExpr_8h_source.html">mlir/IR/AffineExpr.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="IR_2Builders_8h_source.html">mlir/IR/Builders.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="Location_8h_source.html">mlir/IR/Location.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="Types_8h_source.html">mlir/IR/Types.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="Pass_8h_source.html">mlir/Pass/Pass.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="Functional_8h_source.html">mlir/Support/Functional.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="LLVM_8h_source.html">mlir/Support/LLVM.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="FoldUtils_8h_source.html">mlir/Transforms/FoldUtils.h</a>&quot;</code><br />
<code>#include &quot;<a class="el" href="Transforms_2Passes_8h_source.html">mlir/Transforms/Passes.h</a>&quot;</code><br />
<code>#include &quot;llvm/ADT/DenseMap.h&quot;</code><br />
<code>#include &quot;llvm/ADT/DenseSet.h&quot;</code><br />
<code>#include &quot;llvm/ADT/SetVector.h&quot;</code><br />
<code>#include &quot;llvm/ADT/SmallString.h&quot;</code><br />
<code>#include &quot;llvm/ADT/SmallVector.h&quot;</code><br />
<code>#include &quot;llvm/Support/CommandLine.h&quot;</code><br />
<code>#include &quot;llvm/Support/Debug.h&quot;</code><br />
</div><div class="textblock"><div class="dynheader">
Include dependency graph for Vectorize.cpp:</div>
<div class="dyncontent">
<div class="center"><img src="Vectorize_8cpp__incl.png" border="0" usemap="#lib_2Transforms_2Vectorize_8cpp" alt=""/></div>
<map name="lib_2Transforms_2Vectorize_8cpp" id="lib_2Transforms_2Vectorize_8cpp">
</map>
</div>
</div>
<p><a href="Vectorize_8cpp_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="define-members"></a>
Macros</h2></td></tr>
<tr class="memitem:ad78e062f62e0d6e453941fb4ca843e4d"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#ad78e062f62e0d6e453941fb4ca843e4d">DEBUG_TYPE</a>&#160;&#160;&#160;&quot;early-vect&quot;</td></tr>
<tr class="memdesc:ad78e062f62e0d6e453941fb4ca843e4d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements a high-level vectorization strategy on a Function.  <a href="#ad78e062f62e0d6e453941fb4ca843e4d">More...</a><br /></td></tr>
<tr class="separator:ad78e062f62e0d6e453941fb4ca843e4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a90add7804d73d82485a8df45343bbd8e"><td class="memItemLeft" align="right" valign="top">static llvm::cl::OptionCategory&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a90add7804d73d82485a8df45343bbd8e">clOptionsCategory</a> (&quot;vectorize <a class="el" href="PassManagerOptions_8cpp.html#a708ec942a8188388392fb8fa522c3d35">options</a>&quot;)</td></tr>
<tr class="separator:a90add7804d73d82485a8df45343bbd8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a249c54678124db83efe31374e672bf61"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classllvm_1_1cl_1_1list.html">llvm::cl::list</a>&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a249c54678124db83efe31374e672bf61">clVirtualVectorSize</a> (&quot;virtual-vector-size&quot;, llvm::cl::desc(&quot;Specify an n-D virtual vector size for vectorization&quot;), llvm::cl::ZeroOrMore, llvm::cl::cat(<a class="el" href="Vectorize_8cpp.html#a90add7804d73d82485a8df45343bbd8e">clOptionsCategory</a>))</td></tr>
<tr class="separator:a249c54678124db83efe31374e672bf61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5535db4ae1556dbf24ef382b8ef61141"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classllvm_1_1cl_1_1list.html">llvm::cl::list</a>&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a5535db4ae1556dbf24ef382b8ef61141">clFastestVaryingPattern</a> (&quot;test-fastest-varying&quot;, llvm::cl::desc(&quot;Specify a 1-D, 2-D or 3-D pattern of fastest varying memory&quot; &quot; dimensions to match. See defaultPatterns in Vectorize.cpp for a&quot; &quot; description and examples. This is used for testing purposes&quot;), llvm::cl::ZeroOrMore, llvm::cl::cat(<a class="el" href="Vectorize_8cpp.html#a90add7804d73d82485a8df45343bbd8e">clOptionsCategory</a>))</td></tr>
<tr class="separator:a5535db4ae1556dbf24ef382b8ef61141"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b9ab70602b8ab5fa0c4dd6ca35e9185"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="namespacemlir.html#a899fdaa9e41cd3d5abb2b4cc44dba232">FilterFunctionType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a0b9ab70602b8ab5fa0c4dd6ca35e9185">isVectorizableLoopPtrFactory</a> (const <a class="el" href="namespacemlir.html#a59d6aae8a616cd9d13c8b1edb1095948">DenseSet</a>&lt; <a class="el" href="classmlir_1_1Operation.html">Operation</a> *&gt; &amp;parallelLoops, int fastestVaryingMemRefDimension)</td></tr>
<tr class="memdesc:a0b9ab70602b8ab5fa0c4dd6ca35e9185"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward declaration.  <a href="#a0b9ab70602b8ab5fa0c4dd6ca35e9185">More...</a><br /></td></tr>
<tr class="separator:a0b9ab70602b8ab5fa0c4dd6ca35e9185"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6022d905e9aef0a4801a182d6145c841"><td class="memItemLeft" align="right" valign="top">static std::vector&lt; <a class="el" href="classmlir_1_1NestedPattern.html">NestedPattern</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a6022d905e9aef0a4801a182d6145c841">makePatterns</a> (const <a class="el" href="namespacemlir.html#a59d6aae8a616cd9d13c8b1edb1095948">DenseSet</a>&lt; <a class="el" href="classmlir_1_1Operation.html">Operation</a> *&gt; &amp;parallelLoops, int vectorRank, <a class="el" href="classllvm_1_1ArrayRef.html">ArrayRef</a>&lt; int64_t &gt; fastestVaryingPattern)</td></tr>
<tr class="memdesc:a6022d905e9aef0a4801a182d6145c841"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a vectorization pattern from the command line arguments.  <a href="#a6022d905e9aef0a4801a182d6145c841">More...</a><br /></td></tr>
<tr class="separator:a6022d905e9aef0a4801a182d6145c841"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb1f05d0a7c2f37383e31c26fad740c6"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classmlir_1_1NestedPattern.html">NestedPattern</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#abb1f05d0a7c2f37383e31c26fad740c6">vectorTransferPattern</a> ()</td></tr>
<tr class="separator:abb1f05d0a7c2f37383e31c26fad740c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2770a30614289df9645750217ed5b86e"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a2770a30614289df9645750217ed5b86e">vectorizeLoopIfProfitable</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *loop, unsigned depthInPattern, unsigned patternDepth, VectorizationStrategy *strategy)</td></tr>
<tr class="separator:a2770a30614289df9645750217ed5b86e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b753fbff5d2aa2f6353b3ab53c4dcc6"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a7b753fbff5d2aa2f6353b3ab53c4dcc6">analyzeProfitability</a> (<a class="el" href="classllvm_1_1ArrayRef.html">ArrayRef</a>&lt; <a class="el" href="classmlir_1_1NestedMatch.html">NestedMatch</a> &gt; matches, unsigned depthInPattern, unsigned patternDepth, VectorizationStrategy *strategy)</td></tr>
<tr class="memdesc:a7b753fbff5d2aa2f6353b3ab53c4dcc6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements a simple strawman strategy for vectorization.  <a href="#a7b753fbff5d2aa2f6353b3ab53c4dcc6">More...</a><br /></td></tr>
<tr class="separator:a7b753fbff5d2aa2f6353b3ab53c4dcc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0a9229e47312d2c3eb2ba0ca6056134"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#aa0a9229e47312d2c3eb2ba0ca6056134">computeMemoryOpIndices</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op, <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> map, <a class="el" href="classmlir_1_1ValueRange.html">ValueRange</a> mapOperands, <a class="el" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl</a>&lt; <a class="el" href="classmlir_1_1Value.html">Value</a> &gt; &amp;results)</td></tr>
<tr class="separator:aa0a9229e47312d2c3eb2ba0ca6056134"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42c564b5056469c006d10fd180f42c0a"><td class="memTemplParams" colspan="2">template&lt;typename LoadOrStoreOpPointer &gt; </td></tr>
<tr class="memitem:a42c564b5056469c006d10fd180f42c0a"><td class="memTemplItemLeft" align="right" valign="top">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a42c564b5056469c006d10fd180f42c0a">vectorizeRootOrTerminal</a> (<a class="el" href="classmlir_1_1Value.html">Value</a> iv, LoadOrStoreOpPointer memoryOp, VectorizationState *state)</td></tr>
<tr class="memdesc:a42c564b5056469c006d10fd180f42c0a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Handles the vectorization of load and store MLIR operations.  <a href="#a42c564b5056469c006d10fd180f42c0a">More...</a><br /></td></tr>
<tr class="separator:a42c564b5056469c006d10fd180f42c0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa75c99bf8471189cb860537801c6cac"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#aaa75c99bf8471189cb860537801c6cac">vectorizeAffineForOp</a> (AffineForOp loop, int64_t step, VectorizationState *state)</td></tr>
<tr class="memdesc:aaa75c99bf8471189cb860537801c6cac"><td class="mdescLeft">&#160;</td><td class="mdescRight">end TODO(ntv): Hoist to a VectorizationMaterialize.cpp when appropriate. ///  <a href="#aaa75c99bf8471189cb860537801c6cac">More...</a><br /></td></tr>
<tr class="separator:aaa75c99bf8471189cb860537801c6cac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62fafc0565a73ab9db82fc280e623036"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a62fafc0565a73ab9db82fc280e623036">vectorizeLoopsAndLoadsRecursively</a> (<a class="el" href="classmlir_1_1NestedMatch.html">NestedMatch</a> oneMatch, VectorizationState *state)</td></tr>
<tr class="memdesc:a62fafc0565a73ab9db82fc280e623036"><td class="mdescLeft">&#160;</td><td class="mdescRight">Apply vectorization of <code>loop</code> according to <code>state</code>.  <a href="#a62fafc0565a73ab9db82fc280e623036">More...</a><br /></td></tr>
<tr class="separator:a62fafc0565a73ab9db82fc280e623036"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af472fb41d533cf014150abdc2158f2ba"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#af472fb41d533cf014150abdc2158f2ba">vectorizeConstant</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op, <a class="el" href="classConstantOp.html">ConstantOp</a> <a class="el" href="LinalgToLLVM_8cpp.html#a6d6f472e257d29b0c75fa01732f79e44">constant</a>, <a class="el" href="classmlir_1_1Type.html">Type</a> type)</td></tr>
<tr class="memdesc:af472fb41d533cf014150abdc2158f2ba"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tries to transform a scalar constant into a vector splat of that constant.  <a href="#af472fb41d533cf014150abdc2158f2ba">More...</a><br /></td></tr>
<tr class="separator:af472fb41d533cf014150abdc2158f2ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a814b7fc67087d49891b27ae9de8118d1"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a814b7fc67087d49891b27ae9de8118d1">vectorizeOperand</a> (<a class="el" href="classmlir_1_1Value.html">Value</a> operand, <a class="el" href="classmlir_1_1Operation.html">Operation</a> *op, VectorizationState *state)</td></tr>
<tr class="memdesc:a814b7fc67087d49891b27ae9de8118d1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tries to vectorize a given operand <code>op</code> of Operation <code>op</code> during def-chain propagation or during terminal vectorization, by applying the following logic:  <a href="#a814b7fc67087d49891b27ae9de8118d1">More...</a><br /></td></tr>
<tr class="separator:a814b7fc67087d49891b27ae9de8118d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec3e6b2c8e10d7b0538f41c56f4dfe8e"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#aec3e6b2c8e10d7b0538f41c56f4dfe8e">vectorizeOneOperation</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *opInst, VectorizationState *state)</td></tr>
<tr class="memdesc:aec3e6b2c8e10d7b0538f41c56f4dfe8e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Encodes Operation-specific behavior for vectorization.  <a href="#aec3e6b2c8e10d7b0538f41c56f4dfe8e">More...</a><br /></td></tr>
<tr class="separator:aec3e6b2c8e10d7b0538f41c56f4dfe8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a140d324505dcc37eb813e187b6ff2f05"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a140d324505dcc37eb813e187b6ff2f05">vectorizeNonTerminals</a> (VectorizationState *state)</td></tr>
<tr class="memdesc:a140d324505dcc37eb813e187b6ff2f05"><td class="mdescLeft">&#160;</td><td class="mdescRight">Iterates over the forward slice from the loads in the vectorization pattern and rewrites them using their vectorized counterpart by:  <a href="#a140d324505dcc37eb813e187b6ff2f05">More...</a><br /></td></tr>
<tr class="separator:a140d324505dcc37eb813e187b6ff2f05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb897e398a417bdf284192b28c8e2710"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#adb897e398a417bdf284192b28c8e2710">vectorizeRootMatch</a> (<a class="el" href="classmlir_1_1NestedMatch.html">NestedMatch</a> m, VectorizationStrategy *strategy)</td></tr>
<tr class="memdesc:adb897e398a417bdf284192b28c8e2710"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vectorization is a recursive procedure where anything below can fail.  <a href="#adb897e398a417bdf284192b28c8e2710">More...</a><br /></td></tr>
<tr class="separator:adb897e398a417bdf284192b28c8e2710"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a8dce754dbf1fbce2a5498585d5133051"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="structmlir_1_1PassRegistration.html">PassRegistration</a>&lt; Vectorize &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="Vectorize_8cpp.html#a8dce754dbf1fbce2a5498585d5133051">pass</a> (&quot;affine-vectorize&quot;, &quot;Vectorize to a target independent n-D vector abstraction&quot;)</td></tr>
<tr class="separator:a8dce754dbf1fbce2a5498585d5133051"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Macro Definition Documentation</h2>
<a id="ad78e062f62e0d6e453941fb4ca843e4d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad78e062f62e0d6e453941fb4ca843e4d">&#9670;&nbsp;</a></span>DEBUG_TYPE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define DEBUG_TYPE&#160;&#160;&#160;&quot;early-vect&quot;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implements a high-level vectorization strategy on a Function. </p>
<p>The abstraction used is that of super-vectors, which provide a single, compact, representation in the vector types, information that is expected to reduce the impact of the phase ordering problem</p>
<h1>Vector granularity: </h1>
<p>This pass is designed to perform vectorization at a super-vector granularity. A super-vector is loosely defined as a vector type that is a multiple of a "good" vector size so the HW can efficiently implement a set of high-level primitives. Multiple is understood along any dimension; e.g. both vector&lt;16xf32&gt; and vector&lt;2x8xf32&gt; are valid super-vectors for a vector&lt;8xf32&gt; HW vector. Note that a "good vector size so the HW can
efficiently implement a set of high-level primitives" is not necessarily an integer multiple of actual hardware registers. We leave details of this distinction unspecified for now.</p>
<p>Some may prefer the terminology a "tile of HW vectors". In this case, one should note that super-vectors implement an "always full tile" abstraction. They guarantee no partial-tile separation is necessary by relying on a high-level copy-reshape abstraction that we call vector.transfer. This copy-reshape operations is also responsible for performing layout transposition if necessary. In the general case this will require a scoped allocation in some notional local memory.</p>
<p>Whatever the mental model one prefers to use for this abstraction, the key point is that we burn into a single, compact, representation in the vector types, information that is expected to reduce the impact of the phase ordering problem. Indeed, a vector type conveys information that:</p><ol type="1">
<li>the associated loops have dependency semantics that do not prevent vectorization;</li>
<li>the associate loops have been sliced in chunks of static sizes that are compatible with vector sizes (i.e. similar to unroll-and-jam);</li>
<li>the inner loops, in the unroll-and-jam analogy of 2, are captured by the vector type and no vectorization hampering transformations can be applied to them anymore;</li>
<li>the underlying memrefs are accessed in some notional contiguous way that allows loading into vectors with some amount of spatial locality; In other words, super-vectorization provides a level of separation of concern by way of opacity to subsequent passes. This has the effect of encapsulating and propagating vectorization constraints down the list of passes until we are ready to lower further.</li>
</ol>
<p>For a particular target, a notion of minimal n-d vector size will be specified and vectorization targets a multiple of those. In the following paragraph, let "k ." represent "a multiple of", to be understood as a multiple in the same dimension (e.g. vector&lt;16 x k . 128&gt; summarizes vector&lt;16 x 128&gt;, vector&lt;16 x 256&gt;, vector&lt;16 x 1024&gt;, etc).</p>
<p>Some non-exhaustive notable super-vector sizes of interest include:</p><ul>
<li>CPU: vector&lt;k . HW_vector_size&gt;, vector&lt;k' . core_count x k . HW_vector_size&gt;, vector&lt;socket_count x k' . core_count x k . HW_vector_size&gt;;</li>
<li>GPU: vector&lt;k . warp_size&gt;, vector&lt;k . warp_size x float2&gt;, vector&lt;k . warp_size x float4&gt;, vector&lt;k . warp_size x 4 x 4x 4&gt; (for tensor_core sizes).</li>
</ul>
<p>Loops and operations are emitted that operate on those super-vector shapes. Subsequent lowering passes will materialize to actual HW vector sizes. These passes are expected to be (gradually) more target-specific.</p>
<p>At a high level, a vectorized load in a loop will resemble: </p><div class="fragment"><div class="line">affine.for %i = ? to ? step ? {</div><div class="line">  %v_a = vector.transfer_read A[%i] : memref&lt;?xf32&gt;, vector&lt;128xf32&gt;</div><div class="line">}</div></div><!-- fragment --><p> It is the responsibility of the implementation of vector.transfer_read to materialize vector registers from the original scalar memrefs. A later (more target-dependent) lowering pass will materialize to actual HW vector sizes. This lowering may be occur at different times:</p><ol type="1">
<li>at the MLIR level into a combination of loops, unrolling, DmaStartOp + DmaWaitOp + vectorized operations for data transformations and shuffle; thus opening opportunities for unrolling and pipelining. This is an instance of library call "whiteboxing"; or</li>
<li>later in the a target-specific lowering pass or hand-written library call; achieving full separation of concerns. This is an instance of library call; or</li>
<li>a mix of both, e.g. based on a model. In the future, these operations will expose a contract to constrain the search on vectorization patterns and sizes.</li>
</ol>
<h1>Occurrence of super-vectorization in the compiler flow: </h1>
<p>This is an active area of investigation. We start with 2 remarks to position super-vectorization in the context of existing ongoing work: LLVM VPLAN and LLVM SLP Vectorizer.</p>
<h2>LLVM VPLAN: </h2>
<p>The astute reader may have noticed that in the limit, super-vectorization can be applied at a similar time and with similar objectives than VPLAN. For instance, in the case of a traditional, polyhedral compilation-flow (for instance, the PPCG project uses ISL to provide dependence analysis, multi-level(scheduling + tiling), lifting footprint to fast memory, communication synthesis, mapping, register optimizations) and before unrolling. When vectorization is applied at this <em>late</em> level in a typical polyhedral flow, and is instantiated with actual hardware vector sizes, super-vectorization is expected to match (or subsume) the type of patterns that LLVM's VPLAN aims at targeting. The main difference here is that MLIR is higher level and our implementation should be significantly simpler. Also note that in this mode, recursive patterns are probably a bit of an overkill although it is reasonable to expect that mixing a bit of outer loop and inner loop vectorization + unrolling will provide interesting choices to MLIR.</p>
<h2>LLVM SLP Vectorizer: </h2>
<p>Super-vectorization however is not meant to be usable in a similar fashion to the SLP vectorizer. The main difference lies in the information that both vectorizers use: super-vectorization examines contiguity of memory references along fastest varying dimensions and loops with recursive nested patterns capturing imperfectly-nested loop nests; the SLP vectorizer, on the other hand, performs flat pattern matching inside a single unrolled loop body and stitches together pieces of load and store operations into full 1-D vectors. We envision that the SLP vectorizer is a good way to capture innermost loop, control-flow dependent patterns that super-vectorization may not be able to capture easily. In other words, super-vectorization does not aim at replacing the SLP vectorizer and the two solutions are complementary.</p>
<h2>Ongoing investigations: </h2>
<p>We discuss the following <em>early</em> places where super-vectorization is applicable and touch on the expected benefits and risks . We list the opportunities in the context of the traditional polyhedral compiler flow described in PPCG. There are essentially 6 places in the MLIR pass pipeline we expect to experiment with super-vectorization:</p><ol type="1">
<li>Right after language lowering to MLIR: this is the earliest time where super-vectorization is expected to be applied. At this level, all the language/user/library-level annotations are available and can be fully exploited. Examples include loop-type annotations (such as parallel, reduction, scan, dependence distance vector, vectorizable) as well as memory access annotations (such as non-aliasing writes guaranteed, indirect accesses that are permutations by construction) accesses or that a particular operation is prescribed atomic by the user. At this level, anything that enriches what dependence analysis can do should be aggressively exploited. At this level we are close to having explicit vector types in the language, except we do not impose that burden on the programmer/library: we derive information from scalar code + annotations.</li>
<li>After dependence analysis and before polyhedral scheduling: the information that supports vectorization does not need to be supplied by a higher level of abstraction. Traditional dependence analysis is available in MLIR and will be used to drive vectorization and cost models.</li>
</ol>
<p>Let's pause here and remark that applying super-vectorization as described in 1. and 2. presents clear opportunities and risks:</p><ul>
<li>the opportunity is that vectorization is burned in the type system and is protected from the adverse effect of loop scheduling, tiling, loop interchange and all passes downstream. Provided that subsequent passes are able to operate on vector types; the vector shapes, associated loop iterator properties, alignment, and contiguity of fastest varying dimensions are preserved until we lower the super-vector types. We expect this to significantly rein in on the adverse effects of phase ordering.</li>
<li>the risks are that a. all passes after super-vectorization have to work on elemental vector types (not that this is always true, wherever vectorization is applied) and b. that imposing vectorization constraints too early may be overall detrimental to loop fusion, tiling and other transformations because the dependence distances are coarsened when operating on elemental vector types. For this reason, the pattern profitability analysis should include a component that also captures the maximal amount of fusion available under a particular pattern. This is still at the stage of rough ideas but in this context, search is our friend as the Tensor Comprehensions and auto-TVM contributions demonstrated previously. Bottom-line is we do not yet have good answers for the above but aim at making it easy to answer such questions.</li>
</ul>
<p>Back to our listing, the last places where early super-vectorization makes sense are:</p><ol type="1">
<li>right after polyhedral-style scheduling: PLUTO-style algorithms are known to improve locality, parallelism and be configurable (e.g. max-fuse, smart-fuse etc). They can also have adverse effects on contiguity properties that are required for vectorization but the vector.transfer copy-reshape-pad-transpose abstraction is expected to help recapture these properties.</li>
<li>right after polyhedral-style scheduling+tiling;</li>
<li>right after scheduling+tiling+rescheduling: points 4 and 5 represent probably the most promising places because applying tiling achieves a separation of concerns that allows rescheduling to worry less about locality and more about parallelism and distribution (e.g. min-fuse).</li>
</ol>
<p>At these levels the risk-reward looks different: on one hand we probably lost a good deal of language/user/library-level annotation; on the other hand we gained parallelism and locality through scheduling and tiling. However we probably want to ensure tiling is compatible with the full-tile-only abstraction used in super-vectorization or suffer the consequences. It is too early to place bets on what will win but we expect super-vectorization to be the right abstraction to allow exploring at all these levels. And again, search is our friend.</p>
<p>Lastly, we mention it again here:</p><ol type="1">
<li>as a MLIR-based alternative to VPLAN.</li>
</ol>
<h1>Lowering, unrolling, pipelining: </h1>
<p>TODO(ntv): point to the proper places.</p>
<h1>Algorithm: </h1>
<p>The algorithm proceeds in a few steps:</p><ol type="1">
<li>defining super-vectorization patterns and matching them on the tree of AffineForOp. A super-vectorization pattern is defined as a recursive data structures that matches and captures nested, imperfectly-nested loops that have a. conformable loop annotations attached (e.g. parallel, reduction, vectorizable, ...) as well as b. all contiguous load/store operations along a specified minor dimension (not necessarily the fastest varying) ;</li>
<li>analyzing those patterns for profitability (TODO(ntv): and interference);</li>
<li>Then, for each pattern in order: a. applying iterative rewriting of the loop and the load operations in DFS postorder. Rewriting is implemented by coarsening the loops and turning load operations into opaque vector.transfer_read ops; b. keeping track of the load operations encountered as "roots" and the store operations as "terminals"; c. traversing the use-def chains starting from the roots and iteratively propagating vectorized values. Scalar values that are encountered during this process must come from outside the scope of the current pattern (TODO(ntv): enforce this and generalize). Such a scalar value is vectorized only if it is a constant (into a vector splat). The non-constant case is not supported for now and results in the pattern failing to vectorize; d. performing a second traversal on the terminals (store ops) to rewriting the scalar value they write to memory into vector form. If the scalar value has been vectorized previously, we simply replace it by its vector form. Otherwise, if the scalar value is a constant, it is vectorized into a splat. In all other cases, vectorization for the pattern currently fails. e. if everything under the root AffineForOp in the current pattern vectorizes properly, we commit that loop to the IR. Otherwise we discard it and restore a previously cloned version of the loop. Thanks to the recursive scoping nature of matchers and captured patterns, this is transparently achieved by a simple RAII implementation. f. vectorization is applied on the next pattern in the list. Because pattern interference avoidance is not yet implemented and that we do not support further vectorizing an already vector load we need to re-verify that the pattern is still vectorizable. This is expected to make cost models more difficult to write and is subject to improvement in the future.</li>
</ol>
<p>Points c. and d. above are worth additional comment. In most passes that do not change the type of operands, it is usually preferred to eagerly <code>replaceAllUsesWith</code>. Unfortunately this does not work for vectorization because during the use-def chain traversal, all the operands of an operation must be available in vector form. Trying to propagate eagerly makes the IR temporarily invalid and results in errors such as: `vectorize.mlir:308:13: error: 'addf' op requires the same type for all operands and results s5 = addf a5, b5 : f32`</p>
<p>Lastly, we show a minimal example for which use-def chains rooted in load / vector.transfer_read are not enough. This is what motivated splitting terminal processing out of the use-def chains starting from loads. In the following snippet, there is simply no load:: </p><div class="fragment"><div class="line">func @fill(%A : memref&lt;128xf32&gt;) -&gt; () {</div><div class="line">  %f1 = constant 1.0 : f32</div><div class="line">  affine.for %i0 = 0 to 32 {</div><div class="line">    affine.store %f1, %A[%i0] : memref&lt;128xf32, 0&gt;</div><div class="line">  }</div><div class="line">  return</div><div class="line">}</div></div><!-- fragment --><h1>Choice of loop transformation to support the algorithm: </h1>
<p>The choice of loop transformation to apply for coarsening vectorized loops is still subject to exploratory tradeoffs. In particular, say we want to vectorize by a factor 128, we want to transform the following input: </p><div class="fragment"><div class="line">affine.for %i = %M to %N {</div><div class="line">  %a = affine.load %A[%i] : memref&lt;?xf32&gt;</div><div class="line">}</div></div><!-- fragment --><p>Traditionally, one would vectorize late (after scheduling, tiling, memory promotion etc) say after stripmining (and potentially unrolling in the case of LLVM's SLP vectorizer): </p><div class="fragment"><div class="line">affine.for %i = floor(%M, 128) to ceil(%N, 128) {</div><div class="line">  affine.for %ii = max(%M, 128 * %i) to min(%N, 128*%i + 127) {</div><div class="line">    %a = affine.load %A[%ii] : memref&lt;?xf32&gt;</div><div class="line">  }</div><div class="line">}</div></div><!-- fragment --><p>Instead, we seek to vectorize early and freeze vector types before scheduling, so we want to generate a pattern that resembles: </p><div class="fragment"><div class="line">affine.for %i = ? to ? step ? {</div><div class="line">  %v_a = vector.transfer_read %A[%i] : memref&lt;?xf32&gt;, vector&lt;128xf32&gt;</div><div class="line">}</div></div><!-- fragment --><p>i. simply dividing the lower / upper bounds by 128 creates issues when representing expressions such as ii + 1 because now we only have access to original values that have been divided. Additional information is needed to specify accesses at below-128 granularity; ii. another alternative is to coarsen the loop step but this may have consequences on dependence analysis and fusability of loops: fusable loops probably need to have the same step (because we don't want to stripmine/unroll to enable fusion). As a consequence, we choose to represent the coarsening using the loop step for now and reevaluate in the future. Note that we can renormalize loop steps later if/when we have evidence that they are problematic.</p>
<p>For the simple strawman example above, vectorizing for a 1-D vector abstraction of size 128 returns code similar to: </p><div class="fragment"><div class="line">affine.for %i = %M to %N step 128 {</div><div class="line">  %v_a = vector.transfer_read %A[%i] : memref&lt;?xf32&gt;, vector&lt;128xf32&gt;</div><div class="line">}</div></div><!-- fragment --><h1>Unsupported cases, extensions, and work in progress (help welcome :-) ): </h1>
<ol type="1">
<li>lowering to concrete vector types for various HW;</li>
<li>reduction support;</li>
<li>non-effecting padding during vector.transfer_read and filter during vector.transfer_write;</li>
<li>misalignment support vector.transfer_read / vector.transfer_write (hopefully without read-modify-writes);</li>
<li>control-flow support;</li>
<li>cost-models, heuristics and search;</li>
<li>Op implementation, extensions and implication on memref views;</li>
<li>many TODOs left around.</li>
</ol>
<h1>Examples: </h1>
<p>Consider the following Function: </p><div class="fragment"><div class="line">func @vector_add_2d(%M : index, %N : index) -&gt; f32 {</div><div class="line">  %A = alloc (%M, %N) : memref&lt;?x?xf32, 0&gt;</div><div class="line">  %B = alloc (%M, %N) : memref&lt;?x?xf32, 0&gt;</div><div class="line">  %C = alloc (%M, %N) : memref&lt;?x?xf32, 0&gt;</div><div class="line">  %f1 = constant 1.0 : f32</div><div class="line">  %f2 = constant 2.0 : f32</div><div class="line">  affine.for %i0 = 0 to %M {</div><div class="line">    affine.for %i1 = 0 to %N {</div><div class="line">      // non-scoped %f1</div><div class="line">      affine.store %f1, %A[%i0, %i1] : memref&lt;?x?xf32, 0&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  affine.for %i2 = 0 to %M {</div><div class="line">    affine.for %i3 = 0 to %N {</div><div class="line">      // non-scoped %f2</div><div class="line">      affine.store %f2, %B[%i2, %i3] : memref&lt;?x?xf32, 0&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  affine.for %i4 = 0 to %M {</div><div class="line">    affine.for %i5 = 0 to %N {</div><div class="line">      %a5 = affine.load %A[%i4, %i5] : memref&lt;?x?xf32, 0&gt;</div><div class="line">      %b5 = affine.load %B[%i4, %i5] : memref&lt;?x?xf32, 0&gt;</div><div class="line">      %s5 = addf %a5, %b5 : f32</div><div class="line">      // non-scoped %f1</div><div class="line">      %s6 = addf %s5, %f1 : f32</div><div class="line">      // non-scoped %f2</div><div class="line">      %s7 = addf %s5, %f2 : f32</div><div class="line">      // diamond dependency.</div><div class="line">      %s8 = addf %s7, %s6 : f32</div><div class="line">      affine.store %s8, %C[%i4, %i5] : memref&lt;?x?xf32, 0&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  %c7 = constant 7 : index</div><div class="line">  %c42 = constant 42 : index</div><div class="line">  %res = load %C[%c7, %c42] : memref&lt;?x?xf32, 0&gt;</div><div class="line">  return %res : f32</div><div class="line">}</div></div><!-- fragment --><p>The -affine-vectorize pass with the following arguments: </p><div class="fragment"><div class="line">-affine-vectorize -<span class="keyword">virtual</span>-vector-size 256 --test-fastest-varying=0</div></div><!-- fragment --><p>produces this standard innermost-loop vectorized code: </p><div class="fragment"><div class="line">func @vector_add_2d(%arg0 : index, %arg1 : index) -&gt; f32 {</div><div class="line">  %0 = alloc(%arg0, %arg1) : memref&lt;?x?xf32&gt;</div><div class="line">  %1 = alloc(%arg0, %arg1) : memref&lt;?x?xf32&gt;</div><div class="line">  %2 = alloc(%arg0, %arg1) : memref&lt;?x?xf32&gt;</div><div class="line">  %cst = constant 1.0 : f32</div><div class="line">  %cst_0 = constant 2.0 : f32</div><div class="line">  affine.for %i0 = 0 to %arg0 {</div><div class="line">    affine.for %i1 = 0 to %arg1 step 256 {</div><div class="line">      %cst_1 = constant dense&lt;vector&lt;256xf32&gt;, 1.0&gt; :</div><div class="line">               vector&lt;256xf32&gt;</div><div class="line">      vector.transfer_write %cst_1, %0[%i0, %i1] :</div><div class="line">               vector&lt;256xf32&gt;, memref&lt;?x?xf32&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  affine.for %i2 = 0 to %arg0 {</div><div class="line">    affine.for %i3 = 0 to %arg1 step 256 {</div><div class="line">      %cst_2 = constant dense&lt;vector&lt;256xf32&gt;, 2.0&gt; :</div><div class="line">               vector&lt;256xf32&gt;</div><div class="line">      vector.transfer_write %cst_2, %1[%i2, %i3] :</div><div class="line">               vector&lt;256xf32&gt;, memref&lt;?x?xf32&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  affine.for %i4 = 0 to %arg0 {</div><div class="line">    affine.for %i5 = 0 to %arg1 step 256 {</div><div class="line">      %3 = vector.transfer_read %0[%i4, %i5] :</div><div class="line">           memref&lt;?x?xf32&gt;, vector&lt;256xf32&gt;</div><div class="line">      %4 = vector.transfer_read %1[%i4, %i5] :</div><div class="line">           memref&lt;?x?xf32&gt;, vector&lt;256xf32&gt;</div><div class="line">      %5 = addf %3, %4 : vector&lt;256xf32&gt;</div><div class="line">      %cst_3 = constant dense&lt;vector&lt;256xf32&gt;, 1.0&gt; :</div><div class="line">               vector&lt;256xf32&gt;</div><div class="line">      %6 = addf %5, %cst_3 : vector&lt;256xf32&gt;</div><div class="line">      %cst_4 = constant dense&lt;vector&lt;256xf32&gt;, 2.0&gt; :</div><div class="line">               vector&lt;256xf32&gt;</div><div class="line">      %7 = addf %5, %cst_4 : vector&lt;256xf32&gt;</div><div class="line">      %8 = addf %7, %6 : vector&lt;256xf32&gt;</div><div class="line">      vector.transfer_write %8, %2[%i4, %i5] :</div><div class="line">               vector&lt;256xf32&gt;, memref&lt;?x?xf32&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  %c7 = constant 7 : index</div><div class="line">  %c42 = constant 42 : index</div><div class="line">  %9 = load %2[%c7, %c42] : memref&lt;?x?xf32&gt;</div><div class="line">  return %9 : f32</div><div class="line">}</div></div><!-- fragment --><p>The -affine-vectorize pass with the following arguments: </p><div class="fragment"><div class="line">-affine-vectorize -<span class="keyword">virtual</span>-vector-size 32 -<span class="keyword">virtual</span>-vector-size 256</div><div class="line">--test-fastest-varying=1 --test-fastest-varying=0</div></div><!-- fragment --><p>produces this more interesting mixed outer-innermost-loop vectorized code: </p><div class="fragment"><div class="line">func @vector_add_2d(%arg0 : index, %arg1 : index) -&gt; f32 {</div><div class="line">  %0 = alloc(%arg0, %arg1) : memref&lt;?x?xf32&gt;</div><div class="line">  %1 = alloc(%arg0, %arg1) : memref&lt;?x?xf32&gt;</div><div class="line">  %2 = alloc(%arg0, %arg1) : memref&lt;?x?xf32&gt;</div><div class="line">  %cst = constant 1.0 : f32</div><div class="line">  %cst_0 = constant 2.0 : f32</div><div class="line">  affine.for %i0 = 0 to %arg0 step 32 {</div><div class="line">    affine.for %i1 = 0 to %arg1 step 256 {</div><div class="line">      %cst_1 = constant dense&lt;vector&lt;32x256xf32&gt;, 1.0&gt; :</div><div class="line">               vector&lt;32x256xf32&gt;</div><div class="line">      vector.transfer_write %cst_1, %0[%i0, %i1] :</div><div class="line">               vector&lt;32x256xf32&gt;, memref&lt;?x?xf32&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  affine.for %i2 = 0 to %arg0 step 32 {</div><div class="line">    affine.for %i3 = 0 to %arg1 step 256 {</div><div class="line">      %cst_2 = constant dense&lt;vector&lt;32x256xf32&gt;, 2.0&gt; :</div><div class="line">               vector&lt;32x256xf32&gt;</div><div class="line">      vector.transfer_write %cst_2, %1[%i2, %i3] :</div><div class="line">               vector&lt;32x256xf32&gt;, memref&lt;?x?xf32&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  affine.for %i4 = 0 to %arg0 step 32 {</div><div class="line">    affine.for %i5 = 0 to %arg1 step 256 {</div><div class="line">      %3 = vector.transfer_read %0[%i4, %i5] :</div><div class="line">               memref&lt;?x?xf32&gt; vector&lt;32x256xf32&gt;</div><div class="line">      %4 = vector.transfer_read %1[%i4, %i5] :</div><div class="line">               memref&lt;?x?xf32&gt;, vector&lt;32x256xf32&gt;</div><div class="line">      %5 = addf %3, %4 : vector&lt;32x256xf32&gt;</div><div class="line">      %cst_3 = constant dense&lt;vector&lt;32x256xf32&gt;, 1.0&gt; :</div><div class="line">               vector&lt;32x256xf32&gt;</div><div class="line">      %6 = addf %5, %cst_3 : vector&lt;32x256xf32&gt;</div><div class="line">      %cst_4 = constant dense&lt;vector&lt;32x256xf32&gt;, 2.0&gt; :</div><div class="line">               vector&lt;32x256xf32&gt;</div><div class="line">      %7 = addf %5, %cst_4 : vector&lt;32x256xf32&gt;</div><div class="line">      %8 = addf %7, %6 : vector&lt;32x256xf32&gt;</div><div class="line">      vector.transfer_write %8, %2[%i4, %i5] :</div><div class="line">               vector&lt;32x256xf32&gt;, memref&lt;?x?xf32&gt;</div><div class="line">    }</div><div class="line">  }</div><div class="line">  %c7 = constant 7 : index</div><div class="line">  %c42 = constant 42 : index</div><div class="line">  %9 = load %2[%c7, %c42] : memref&lt;?x?xf32&gt;</div><div class="line">  return %9 : f32</div><div class="line">}</div></div><!-- fragment --><p>Of course, much more intricate n-D imperfectly-nested patterns can be vectorized too and specified in a fully declarative fashion. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00527">527</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="a7b753fbff5d2aa2f6353b3ab53c4dcc6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b753fbff5d2aa2f6353b3ab53c4dcc6">&#9670;&nbsp;</a></span>analyzeProfitability()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a> analyzeProfitability </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classllvm_1_1ArrayRef.html">ArrayRef</a>&lt; <a class="el" href="classmlir_1_1NestedMatch.html">NestedMatch</a> &gt;&#160;</td>
          <td class="paramname"><em>matches</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned&#160;</td>
          <td class="paramname"><em>depthInPattern</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned&#160;</td>
          <td class="paramname"><em>patternDepth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationStrategy *&#160;</td>
          <td class="paramname"><em>strategy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Implements a simple strawman strategy for vectorization. </p>
<p>Given a matched pattern <code>matches</code> of depth <code>patternDepth</code>, this strategy greedily assigns the fastest varying dimension ** of the vector ** to the innermost loop in the pattern. When coupled with a pattern that looks for the fastest varying dimension in load/store MemRefs, this creates a generic vectorization strategy that works for any loop in a hierarchy (outermost, innermost or intermediate).</p>
<p>TODO(ntv): In the future we should additionally increase the power of the profitability analysis along 3 directions:</p><ol type="1">
<li>account for loop extents (both static and parametric + annotations);</li>
<li>account for data layout permutations;</li>
<li>account for impact of vectorization on maximal loop fusion. Then we can quantify the above to build a cost model and search over strategies. </li>
</ol>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00661">661</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="Operation_8cpp_source.html#l00501">mlir::Operation::erase()</a>, <a class="el" href="LogicalResult_8h_source.html#l00045">mlir::failed()</a>, <a class="el" href="LogicalResult_8h_source.html#l00032">mlir::failure()</a>, <a class="el" href="Operation_8cpp_source.html#l00548">mlir::Operation::getNumResults()</a>, <a class="el" href="Operation_8h_source.html#l00248">mlir::Operation::getResult()</a>, <a class="el" href="AsmPrinter_8cpp_source.html#l02209">mlir::Operation::print()</a>, <a class="el" href="LogicalResult_8h_source.html#l00025">mlir::success()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00633">vectorizeLoopIfProfitable()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01153">vectorizeRootMatch()</a>.</p>

</div>
</div>
<a id="a5535db4ae1556dbf24ef382b8ef61141"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5535db4ae1556dbf24ef382b8ef61141">&#9670;&nbsp;</a></span>clFastestVaryingPattern()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="classllvm_1_1cl_1_1list.html">llvm::cl::list</a>&lt;int&gt; clFastestVaryingPattern </td>
          <td>(</td>
          <td class="paramtype">&quot;test-fastest-varying&quot;&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">llvm::cl::desc(&quot;Specify a 1-D, 2-D or 3-D pattern of fastest varying memory&quot; &quot; dimensions to match. See defaultPatterns in Vectorize.cpp for a&quot; &quot; description and examples. This is used for testing purposes&quot;)&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">llvm::cl::ZeroOrMore&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">llvm::cl::cat(<a class="el" href="Vectorize_8cpp.html#a90add7804d73d82485a8df45343bbd8e">clOptionsCategory</a>)&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00581">vectorTransferPattern()</a>.</p>

</div>
</div>
<a id="a90add7804d73d82485a8df45343bbd8e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90add7804d73d82485a8df45343bbd8e">&#9670;&nbsp;</a></span>clOptionsCategory()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static llvm::cl::OptionCategory clOptionsCategory </td>
          <td>(</td>
          <td class="paramtype">&quot;vectorize <a class="el" href="PassManagerOptions_8cpp.html#a708ec942a8188388392fb8fa522c3d35">options</a>&quot;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a249c54678124db83efe31374e672bf61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a249c54678124db83efe31374e672bf61">&#9670;&nbsp;</a></span>clVirtualVectorSize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="classllvm_1_1cl_1_1list.html">llvm::cl::list</a>&lt;int&gt; clVirtualVectorSize </td>
          <td>(</td>
          <td class="paramtype">&quot;virtual-vector-size&quot;&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">llvm::cl::desc(&quot;Specify an n-D virtual vector size for vectorization&quot;)&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">llvm::cl::ZeroOrMore&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">llvm::cl::cat(<a class="el" href="Vectorize_8cpp.html#a90add7804d73d82485a8df45343bbd8e">clOptionsCategory</a>)&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00581">vectorTransferPattern()</a>.</p>

</div>
</div>
<a id="aa0a9229e47312d2c3eb2ba0ca6056134"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0a9229e47312d2c3eb2ba0ca6056134">&#9670;&nbsp;</a></span>computeMemoryOpIndices()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void computeMemoryOpIndices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a>&#160;</td>
          <td class="paramname"><em>map</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1ValueRange.html">ValueRange</a>&#160;</td>
          <td class="paramname"><em>mapOperands</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl</a>&lt; <a class="el" href="classmlir_1_1Value.html">Value</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>results</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00768">768</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="IR_2Builders_8h_source.html#l00294">mlir::OpBuilder::create()</a>, <a class="el" href="MLIRContext_8cpp_source.html#l00590">mlir::AffineMap::get()</a>, <a class="el" href="Operation_8h_source.html#l00107">mlir::Operation::getLoc()</a>, <a class="el" href="AffineMap_8cpp_source.html#l00150">mlir::AffineMap::getNumDims()</a>, <a class="el" href="AffineMap_8cpp_source.html#l00154">mlir::AffineMap::getNumSymbols()</a>, and <a class="el" href="AffineMap_8cpp_source.html#l00167">mlir::AffineMap::getResults()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01025">vectorizeOneOperation()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00797">vectorizeRootOrTerminal()</a>.</p>

</div>
</div>
<a id="a0b9ab70602b8ab5fa0c4dd6ca35e9185"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b9ab70602b8ab5fa0c4dd6ca35e9185">&#9670;&nbsp;</a></span>isVectorizableLoopPtrFactory()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="namespacemlir.html#a899fdaa9e41cd3d5abb2b4cc44dba232">FilterFunctionType</a> isVectorizableLoopPtrFactory </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespacemlir.html#a59d6aae8a616cd9d13c8b1edb1095948">DenseSet</a>&lt; <a class="el" href="classmlir_1_1Operation.html">Operation</a> *&gt; &amp;&#160;</td>
          <td class="paramname"><em>parallelLoops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>fastestVaryingMemRefDimension</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Forward declaration. </p>
<p>Returns a FilterFunctionType that can be used in NestedPattern to match a loop whose underlying load/store accesses are either invariant or all. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00882">882</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="LoopAnalysis_8cpp_source.html#l00345">mlir::isVectorizableLoopBody()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00581">vectorTransferPattern()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00559">makePatterns()</a>.</p>

</div>
</div>
<a id="a6022d905e9aef0a4801a182d6145c841"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6022d905e9aef0a4801a182d6145c841">&#9670;&nbsp;</a></span>makePatterns()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static std::vector&lt;<a class="el" href="classmlir_1_1NestedPattern.html">NestedPattern</a>&gt; makePatterns </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespacemlir.html#a59d6aae8a616cd9d13c8b1edb1095948">DenseSet</a>&lt; <a class="el" href="classmlir_1_1Operation.html">Operation</a> *&gt; &amp;&#160;</td>
          <td class="paramname"><em>parallelLoops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>vectorRank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classllvm_1_1ArrayRef.html">ArrayRef</a>&lt; int64_t &gt;&#160;</td>
          <td class="paramname"><em>fastestVaryingPattern</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Creates a vectorization pattern from the command line arguments. </p>
<p>Up to 3-D patterns are supported. If the command line argument requests a pattern of higher order, returns an empty pattern list which will conservatively result in no vectorization. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00559">559</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="NestedMatcher_8cpp_source.html#l00132">mlir::matcher::For()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00882">isVectorizableLoopPtrFactory()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01153">vectorizeRootMatch()</a>.</p>

</div>
</div>
<a id="aaa75c99bf8471189cb860537801c6cac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa75c99bf8471189cb860537801c6cac">&#9670;&nbsp;</a></span>vectorizeAffineForOp()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a> vectorizeAffineForOp </td>
          <td>(</td>
          <td class="paramtype">AffineForOp&#160;</td>
          <td class="paramname"><em>loop</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t&#160;</td>
          <td class="paramname"><em>step</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationState *&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>end TODO(ntv): Hoist to a VectorizationMaterialize.cpp when appropriate. /// </p>
<p>Coarsens the loops bounds and transforms all remaining load and store operations into the appropriate vector.transfer. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00847">847</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="LogicalResult_8h_source.html#l00045">mlir::failed()</a>, <a class="el" href="LogicalResult_8h_source.html#l00032">mlir::failure()</a>, <a class="el" href="NestedMatcher_8cpp_source.html#l00147">mlir::matcher::isLoadOrStore()</a>, <a class="el" href="NestedMatcher_8cpp_source.html#l00111">mlir::matcher::Op()</a>, <a class="el" href="LogicalResult_8h_source.html#l00025">mlir::success()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00797">vectorizeRootOrTerminal()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00903">vectorizeLoopsAndLoadsRecursively()</a>.</p>

</div>
</div>
<a id="af472fb41d533cf014150abdc2158f2ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af472fb41d533cf014150abdc2158f2ba">&#9670;&nbsp;</a></span>vectorizeConstant()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="classmlir_1_1Value.html">Value</a> vectorizeConstant </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classConstantOp.html">ConstantOp</a>&#160;</td>
          <td class="paramname"><em>constant</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Type.html">Type</a>&#160;</td>
          <td class="paramname"><em>type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Tries to transform a scalar constant into a vector splat of that constant. </p>
<p>Returns the vectorized splat operation if the constant is a valid vector element type. If <code>type</code> is not a valid vector type or if the scalar constant is not a valid vector element type, returns nullptr. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00944">944</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="Types_8h_source.html#l00264">mlir::Type::cast()</a>, <a class="el" href="IR_2Builders_8cpp_source.html#l00329">mlir::OpBuilder::createOperation()</a>, <a class="el" href="Attributes_8cpp_source.html#l00572">mlir::DenseElementsAttr::get()</a>, <a class="el" href="Operation_8h_source.html#l00107">mlir::Operation::getLoc()</a>, <a class="el" href="IR_2Builders_8cpp_source.html#l00077">mlir::Builder::getNamedAttr()</a>, <a class="el" href="Operation_8h_source.html#l00248">mlir::Operation::getResult()</a>, <a class="el" href="Types_8h_source.html#l00254">mlir::Type::isa()</a>, and <a class="el" href="StandardTypes_8h_source.html#l00280">mlir::VectorType::isValidElementType()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00982">vectorizeOperand()</a>.</p>

</div>
</div>
<a id="a2770a30614289df9645750217ed5b86e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2770a30614289df9645750217ed5b86e">&#9670;&nbsp;</a></span>vectorizeLoopIfProfitable()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void vectorizeLoopIfProfitable </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>loop</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned&#160;</td>
          <td class="paramname"><em>depthInPattern</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned&#160;</td>
          <td class="paramname"><em>patternDepth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationStrategy *&#160;</td>
          <td class="paramname"><em>strategy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00633">633</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00661">analyzeProfitability()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l01153">vectorizeRootMatch()</a>.</p>

</div>
</div>
<a id="a62fafc0565a73ab9db82fc280e623036"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62fafc0565a73ab9db82fc280e623036">&#9670;&nbsp;</a></span>vectorizeLoopsAndLoadsRecursively()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a> vectorizeLoopsAndLoadsRecursively </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1NestedMatch.html">NestedMatch</a>&#160;</td>
          <td class="paramname"><em>oneMatch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationState *&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Apply vectorization of <code>loop</code> according to <code>state</code>. </p>
<p>This is only triggered if all vectorizations in <code>childrenMatches</code> have already succeeded recursively in DFS post-order. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00903">903</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="LogicalResult_8h_source.html#l00045">mlir::failed()</a>, <a class="el" href="LogicalResult_8h_source.html#l00032">mlir::failure()</a>, <a class="el" href="NestedMatcher_8h_source.html#l00056">mlir::NestedMatch::getMatchedChildren()</a>, <a class="el" href="NestedMatcher_8h_source.html#l00055">mlir::NestedMatch::getMatchedOperation()</a>, <a class="el" href="LogicalResult_8h_source.html#l00025">mlir::success()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00847">vectorizeAffineForOp()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01153">vectorizeRootMatch()</a>.</p>

</div>
</div>
<a id="a140d324505dcc37eb813e187b6ff2f05"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a140d324505dcc37eb813e187b6ff2f05">&#9670;&nbsp;</a></span>vectorizeNonTerminals()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a> vectorizeNonTerminals </td>
          <td>(</td>
          <td class="paramtype">VectorizationState *&#160;</td>
          <td class="paramname"><em>state</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Iterates over the forward slice from the loads in the vectorization pattern and rewrites them using their vectorized counterpart by: </p>
<ol type="1">
<li>Create the forward slice starting from the loads in the vectorization pattern.</li>
<li>Topologically sorts the forward slice.</li>
<li>For each operation in the slice, create the vector form of this operation, replacing each operand by a replacement operands retrieved from replacementMap. If any such replacement is missing, vectorization fails. </li>
</ol>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l01109">1109</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="LogicalResult_8h_source.html#l00032">mlir::failure()</a>, <a class="el" href="namespacemlir.html#ab3c9138cd38e82a78b5895b0e606d5d6">mlir::getForwardSlice()</a>, <a class="el" href="AsmPrinter_8cpp_source.html#l02209">mlir::Operation::print()</a>, <a class="el" href="LogicalResult_8h_source.html#l00025">mlir::success()</a>, <a class="el" href="namespacemlir.html#a67f5deb263dc3ca56a8c5ae015cba4af">mlir::topologicalSort()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l01025">vectorizeOneOperation()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01153">vectorizeRootMatch()</a>.</p>

</div>
</div>
<a id="aec3e6b2c8e10d7b0538f41c56f4dfe8e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec3e6b2c8e10d7b0538f41c56f4dfe8e">&#9670;&nbsp;</a></span>vectorizeOneOperation()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="classmlir_1_1Operation.html">Operation</a>* vectorizeOneOperation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>opInst</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationState *&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Encodes Operation-specific behavior for vectorization. </p>
<p>In general we assume that all operands of an op must be vectorized but this is not always true. In the future, it would be nice to have a trait that describes how a particular operation vectorizes. For now we implement the case distinction here. Returns a vectorized form of an operation or nullptr if vectorization fails. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l01025">1025</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="STLExtras_8h_source.html#l00229">mlir::detail::indexed_accessor_range_base&lt; DerivedT, BaseT, T, PointerT, ReferenceT &gt;::begin()</a>, <a class="el" href="Vectorize_8cpp_source.html#l00768">computeMemoryOpIndices()</a>, <a class="el" href="IR_2Builders_8h_source.html#l00294">mlir::OpBuilder::create()</a>, <a class="el" href="IR_2Builders_8cpp_source.html#l00329">mlir::OpBuilder::createOperation()</a>, <a class="el" href="STLExtras_8h_source.html#l00230">mlir::detail::indexed_accessor_range_base&lt; DerivedT, BaseT, T, PointerT, ReferenceT &gt;::end()</a>, <a class="el" href="Operation_8cpp_source.html#l00501">mlir::Operation::erase()</a>, <a class="el" href="Attributes_8cpp_source.html#l00055">mlir::AffineMapAttr::get()</a>, <a class="el" href="StandardTypes_8cpp_source.html#l00199">mlir::VectorType::get()</a>, <a class="el" href="Operation_8h_source.html#l00277">mlir::Operation::getAttrs()</a>, <a class="el" href="Operation_8h_source.html#l00107">mlir::Operation::getLoc()</a>, <a class="el" href="IR_2Builders_8cpp_source.html#l00268">mlir::Builder::getMultiDimIdentityMap()</a>, <a class="el" href="Operation_8h_source.html#l00061">mlir::Operation::getName()</a>, <a class="el" href="Operation_8h_source.html#l00362">mlir::Operation::getNumRegions()</a>, <a class="el" href="Operation_8h_source.html#l00222">mlir::Operation::getOperands()</a>, <a class="el" href="Operation_8h_source.html#l00256">mlir::Operation::getResults()</a>, <a class="el" href="Operation_8cpp_source.html#l00052">mlir::OperationName::getStringRef()</a>, <a class="el" href="Operation_8h_source.html#l00200">mlir::Operation::hasResizableOperandsList()</a>, <a class="el" href="VectorAnalysis_8cpp_source.html#l00102">makePermutationMap()</a>, <a class="el" href="LogicalResult_8h_source.html#l00025">mlir::success()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00982">vectorizeOperand()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01109">vectorizeNonTerminals()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l01153">vectorizeRootMatch()</a>.</p>

</div>
</div>
<a id="a814b7fc67087d49891b27ae9de8118d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a814b7fc67087d49891b27ae9de8118d1">&#9670;&nbsp;</a></span>vectorizeOperand()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="classmlir_1_1Value.html">Value</a> vectorizeOperand </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td>
          <td class="paramname"><em>operand</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationState *&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Tries to vectorize a given operand <code>op</code> of Operation <code>op</code> during def-chain propagation or during terminal vectorization, by applying the following logic: </p>
<ol type="1">
<li>if the defining operation is part of the vectorizedSet (i.e. vectorized useby -def propagation), <code>op</code> is already in the proper vector form;</li>
<li>otherwise, the <code>op</code> may be in some other vector form that fails to vectorize atm (i.e. broadcasting required), returns nullptr to indicate failure;</li>
<li>if the <code>op</code> is a constant, returns the vectorized form of the constant;</li>
<li>non-constant scalars are currently non-vectorizable, in particular to guard against vectorizing an index which may be loop-variant and needs special handling.</li>
</ol>
<p>In particular this logic captures some of the use cases where definitions that are not scoped under the current pattern are needed to vectorize. One such example is top level function constants that need to be splatted.</p>
<p>Returns an operand that has been vectorized to match <code>state</code>'s strategy if vectorization is possible with the above logic. Returns nullptr otherwise.</p>
<p>TODO(ntv): handle more complex cases. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00982">982</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="StandardTypes_8cpp_source.html#l00199">mlir::VectorType::get()</a>, <a class="el" href="Value_8cpp_source.html#l00071">mlir::Value::getDefiningOp()</a>, <a class="el" href="Value_8cpp_source.html#l00034">mlir::Value::getType()</a>, <a class="el" href="Types_8h_source.html#l00254">mlir::Type::isa()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l00944">vectorizeConstant()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01025">vectorizeOneOperation()</a>.</p>

</div>
</div>
<a id="adb897e398a417bdf284192b28c8e2710"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb897e398a417bdf284192b28c8e2710">&#9670;&nbsp;</a></span>vectorizeRootMatch()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a> vectorizeRootMatch </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1NestedMatch.html">NestedMatch</a>&#160;</td>
          <td class="paramname"><em>m</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationStrategy *&#160;</td>
          <td class="paramname"><em>strategy</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Vectorization is a recursive procedure where anything below can fail. </p>
<p>The root match thus needs to maintain a clone for handling failure. Each root may succeed independently but will otherwise clean after itself if anything below it fails. </p>
<p>Sets up error handling for this root loop. This is how the root match maintains a clone for handling failure and restores the proper state via RAII. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l01153">1153</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="Vectorize_8cpp_source.html#l00661">analyzeProfitability()</a>, <a class="el" href="IR_2Builders_8h_source.html#l00356">mlir::OpBuilder::clone()</a>, <a class="el" href="Operation_8cpp_source.html#l00739">mlir::OpState::emitRemark()</a>, <a class="el" href="LogicalResult_8h_source.html#l00045">mlir::failed()</a>, <a class="el" href="LogicalResult_8h_source.html#l00032">mlir::failure()</a>, <a class="el" href="NestedMatcher_8h_source.html#l00055">mlir::NestedMatch::getMatchedOperation()</a>, <a class="el" href="Analysis_2Utils_8cpp_source.html#l00973">mlir::isLoopParallel()</a>, <a class="el" href="LoopAnalysis_8cpp_source.html#l00345">mlir::isVectorizableLoopBody()</a>, <a class="el" href="Vectorize_8cpp_source.html#l00559">makePatterns()</a>, <a class="el" href="Function_8cpp_source.html#l00082">mlir::FuncOp::print()</a>, <a class="el" href="LogicalResult_8h_source.html#l00025">mlir::success()</a>, <a class="el" href="Vectorize_8cpp_source.html#l00633">vectorizeLoopIfProfitable()</a>, <a class="el" href="Vectorize_8cpp_source.html#l00903">vectorizeLoopsAndLoadsRecursively()</a>, <a class="el" href="Vectorize_8cpp_source.html#l01109">vectorizeNonTerminals()</a>, <a class="el" href="Vectorize_8cpp_source.html#l01025">vectorizeOneOperation()</a>, <a class="el" href="Vectorize_8cpp_source.html#l00581">vectorTransferPattern()</a>, and <a class="el" href="OpDefinition_8h_source.html#l00214">mlir::OpState::walk()</a>.</p>

</div>
</div>
<a id="a42c564b5056469c006d10fd180f42c0a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42c564b5056469c006d10fd180f42c0a">&#9670;&nbsp;</a></span>vectorizeRootOrTerminal()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LoadOrStoreOpPointer &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="structmlir_1_1LogicalResult.html">LogicalResult</a> vectorizeRootOrTerminal </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td>
          <td class="paramname"><em>iv</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">LoadOrStoreOpPointer&#160;</td>
          <td class="paramname"><em>memoryOp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VectorizationState *&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Handles the vectorization of load and store MLIR operations. </p>
<p>AffineLoadOp operations are the roots of the vectorizeNonTerminals call. They are vectorized immediately. The resulting vector.transfer_read is immediately registered to replace all uses of the AffineLoadOp in this pattern's scope.</p>
<p>AffineStoreOp are the terminals of the vectorizeNonTerminals call. They need to be vectorized late once all the use-def chains have been traversed. Additionally, they may have ssa-values operands which come from outside the scope of the current pattern. Such special cases force us to delay the vectorization of the stores until the last step. Here we merely register the store operation. </p>

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00797">797</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="STLExtras_8h_source.html#l00229">mlir::detail::indexed_accessor_range_base&lt; DerivedT, BaseT, T, PointerT, ReferenceT &gt;::begin()</a>, <a class="el" href="Vectorize_8cpp_source.html#l00768">computeMemoryOpIndices()</a>, <a class="el" href="IR_2Builders_8h_source.html#l00294">mlir::OpBuilder::create()</a>, <a class="el" href="STLExtras_8h_source.html#l00230">mlir::detail::indexed_accessor_range_base&lt; DerivedT, BaseT, T, PointerT, ReferenceT &gt;::end()</a>, <a class="el" href="LogicalResult_8h_source.html#l00019">mlir::LogicalResult::Failure</a>, <a class="el" href="Attributes_8cpp_source.html#l00055">mlir::AffineMapAttr::get()</a>, <a class="el" href="StandardTypes_8cpp_source.html#l00199">mlir::VectorType::get()</a>, <a class="el" href="IR_2Builders_8cpp_source.html#l00268">mlir::Builder::getMultiDimIdentityMap()</a>, <a class="el" href="StandardTypes_8h_source.html#l00280">mlir::VectorType::isValidElementType()</a>, <a class="el" href="VectorAnalysis_8cpp_source.html#l00102">makePermutationMap()</a>, and <a class="el" href="LogicalResult_8h_source.html#l00025">mlir::success()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00847">vectorizeAffineForOp()</a>.</p>

</div>
</div>
<a id="abb1f05d0a7c2f37383e31c26fad740c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb1f05d0a7c2f37383e31c26fad740c6">&#9670;&nbsp;</a></span>vectorTransferPattern()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="classmlir_1_1NestedPattern.html">NestedPattern</a>&amp; vectorTransferPattern </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Vectorize_8cpp_source.html#l00581">581</a> of file <a class="el" href="Vectorize_8cpp_source.html">Vectorize.cpp</a>.</p>

<p class="reference">References <a class="el" href="Vectorize_8cpp.html#a5535db4ae1556dbf24ef382b8ef61141">clFastestVaryingPattern()</a>, <a class="el" href="Vectorize_8cpp.html#a249c54678124db83efe31374e672bf61">clVirtualVectorSize()</a>, and <a class="el" href="NestedMatcher_8cpp_source.html#l00111">mlir::matcher::Op()</a>.</p>

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l00882">isVectorizableLoopPtrFactory()</a>, and <a class="el" href="Vectorize_8cpp_source.html#l01153">vectorizeRootMatch()</a>.</p>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a8dce754dbf1fbce2a5498585d5133051"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8dce754dbf1fbce2a5498585d5133051">&#9670;&nbsp;</a></span>pass</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structmlir_1_1PassRegistration.html">PassRegistration</a>&lt;Vectorize&gt; pass(&quot;affine-vectorize&quot;, &quot;Vectorize to a target independent n-D vector abstraction&quot;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="reference">Referenced by <a class="el" href="Vectorize_8cpp_source.html#l01285">mlir::createVectorizePass()</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sun Jan 26 2020 16:22:18 for MLIR by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
