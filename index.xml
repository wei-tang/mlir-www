<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MLIR</title><link>https://mlir.llvm.org/</link><description>Recent content on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 19 Oct 2017 15:26:15 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/index.xml" rel="self" type="application/rss+xml"/><item><title>Debugging</title><link>https://mlir.llvm.org/getting_started/Debugging/</link><pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Debugging/</guid><description>MLIR Debugging Tips Inspecting compilation There&amp;rsquo;s no silver bullet for debugging the compilation process. Standard debugging techniques (printf debugging, gdb/lldb, IDE graphical debuggers, etc.) are of course applicable, but here are MLIR-specific facilities that are quite useful before diving into a generic debug flow. These facilities assume that you have reduced your problem to a form that can be reproduced with mlir-opt or another program that hooks into MLIR&amp;rsquo;s option parsing, if this is not the case, see section &amp;ldquo;Isolating test case&amp;rdquo; below.</description></item><item><title>FAQ</title><link>https://mlir.llvm.org/getting_started/Faq/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Faq/</guid><description>TODO</description></item><item><title>How to Contribute</title><link>https://mlir.llvm.org/getting_started/Contributing/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Contributing/</guid><description>Everyone is welcome to contribute to MLIR. There are several ways of getting involved and contributing including reporting bugs, improving documentation and tutorials.
Community Guidelines Please be mindful of the LLVM Code of Conduct , which pledges to foster an open and welcoming environment.
Contributing code We don&amp;rsquo;t accept pull-request on GitHub, instead we use Phabricator . At the moment you need to also join this group to enable build and test of your Phabricator revisions.</description></item><item><title>Developer Guide</title><link>https://mlir.llvm.org/getting_started/DeveloperGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/DeveloperGuide/</guid><description>This document attempts to describe a few developer policies used in MLIR (such as coding standards used) as well as development approach (such as, testing methods).
Style guide MLIR follows the LLVM style guide. We also adhere to the following (which deviate from or are not specified in the LLVM style guide):
Adopts camelBack ; Uses Doxygen-style (///) comments for top-level and class member definitions, regardless of them being visible as public APIs.</description></item><item><title>Open Projects</title><link>https://mlir.llvm.org/getting_started/openprojects/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/openprojects/</guid><description>Below is a list of projects that can be suitable for Google Summer of Code (GSOC) or just for someone to get started with contributing to MLIR. See also the &amp;ldquo;beginner&amp;rdquo; issues on the bugtracker. If you&amp;rsquo;re interested in one of these projects, feel free to discuss it on the MLIR section of the LLVM forums or on the MLIR channel of the LLVM discord server. The mentors are indicative and suggestion of first point of contact for starting on these projects.</description></item><item><title>Glossary</title><link>https://mlir.llvm.org/getting_started/Glossary/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Glossary/</guid><description>This glossary contains definitions of MLIR-specific terminology. It is intended to be a quick reference document. For terms which are well-documented elsewhere, definitions are kept brief and the header links to the more in-depth documentation.
Block A sequential list of operations without control flow.
Also called a basic block .
Conversion The transformation of code represented in one dialect into a semantically equivalent representation in another dialect (i.e. inter-dialect conversion) or the same dialect (i.</description></item><item><title>Testing Guide</title><link>https://mlir.llvm.org/getting_started/TestingGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/TestingGuide/</guid><description>Testing is an integral part of any software infrastructure. In general, all commits to the MLIR repository should include an accompanying test of some form. Commits that include no functional changes, such as API changes like symbol renaming, should be tagged with NFC(no functional changes). This signals to the reviewer why the change doesn&amp;rsquo;t/shouldn&amp;rsquo;t include a test.
MLIR generally separates testing into two main categories, Check tests and Unit tests.</description></item><item><title>'affine' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Affine/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Affine/</guid><description>This dialect provides a powerful abstraction for affine operations and analyses.
Polyhedral Structures Dimensions and Symbols Restrictions on Dimensions and Symbols Affine Expressions Affine Maps Semi-affine maps Integer Sets Operations affine.apply (AffineApplyOp) affine.for (AffineForOp) affine.if (AffineIfOp) affine.max (AffineMaxOp) affine.min (AffineMinOp) affine.parallel (AffineParallelOp) affine.prefetch (AffinePrefetchOp) affine.terminator (AffineTerminatorOp) &amp;lsquo;affine.load&amp;rsquo; operation &amp;lsquo;affine.store&amp;rsquo; operation &amp;lsquo;affine.dma_start&amp;rsquo; operation &amp;lsquo;affine.dma_wait&amp;rsquo; operation Polyhedral Structures MLIR uses techniques from polyhedral compilation to make dependence analysis and loop transformations efficient and reliable.</description></item><item><title>'gpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/GPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPU/</guid><description>Note: this dialect is more likely to change than others in the near future; use with caution.
This dialect provides middle-level abstractions for launching GPU kernels following a programming model similar to that of CUDA or OpenCL. It provides abstractions for kernel invocations (and may eventually provide those for device management) that are not present at the lower level (e.g., as LLVM IR intrinsics for GPUs). Its goal is to abstract away device- and driver-specific manipulations to launch a GPU kernel and provide a simple path towards GPU execution from MLIR.</description></item><item><title>'linalg' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Linalg/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Linalg/</guid><description>Rationale Set of Key Transformations High-Level Description of Linalg Ops Payload-Carrying Ops Data Representation: Views Metadata Ops Named Payload-Carrying Ops Named Payload Ops Specification Open Issues and Design Alternatives Operations linalg.conv (linalg::ConvOp) linalg.copy (linalg::CopyOp) linalg.dot (linalg::DotOp) linalg.fill (linalg::FillOp) linalg.generic (linalg::GenericOp) linalg.indexed_generic (linalg::IndexedGenericOp) linalg.range (linalg::RangeOp) linalg.reshape (linalg::ReshapeOp) linalg.slice (linalg::SliceOp) linalg.tensor_reshape (linalg::TensorReshapeOp) linalg.transpose (linalg::TransposeOp) linalg.yield (linalg::YieldOp) linalg.matmul (linalg::MatmulOp) linalg.matvec (linalg::MatvecOp) linalg.pooling_max (linalg::PoolingMaxOp) linalg.pooling_min (linalg::PoolingMinOp) linalg.pooling_sum (linalg::PoolingSumOp) Rationale Linalg is designed to solve the High-level Hierarchical Optimization (HHO box) in MLIR and to interoperate nicely within a Mixture Of Expert Compilers environment (i.</description></item><item><title>'llvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LLVM/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVM/</guid><description>This dialect wraps the LLVM IR types and instructions into MLIR types and operations. It provides several additional operations that are necessary to cover for the differences in the IR structure (e.g., MLIR does not have phi operations and LLVM IR does not have a constant operation).
In this document, we use &amp;ldquo;LLVM IR&amp;rdquo; to designate the intermediate representation of LLVM and &amp;ldquo;LLVM IR dialect&amp;rdquo; to refer to the MLIR dialect reflecting LLVM instructions and types.</description></item><item><title>'loop' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LoopDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LoopDialect/</guid><description>Operation definition loop.for (ForOp) loop.if (IfOp) loop.parallel (ParallelOp) loop.reduce (ReduceOp) loop.reduce.return (ReduceReturnOp) loop.yield (YieldOp) Operation definition loop.for (ForOp) for operation
The &amp;ldquo;loop.for&amp;rdquo; operation represents a loop taking 3 SSA value as operands that represent the lower bound, upper bound and step respectively. The operation defines an SSA value for its induction variable. It has one region capturing the loop body. The induction variable is represented as an argument of this region.</description></item><item><title>'nvvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</guid><description>Operation definition nvvm.barrier0 (NVVM::Barrier0Op) nvvm.read.ptx.sreg.ntid.x (NVVM::BlockDimXOp) nvvm.read.ptx.sreg.ntid.y (NVVM::BlockDimYOp) nvvm.read.ptx.sreg.ntid.z (NVVM::BlockDimZOp) nvvm.read.ptx.sreg.ctaid.x (NVVM::BlockIdXOp) nvvm.read.ptx.sreg.ctaid.y (NVVM::BlockIdYOp) nvvm.read.ptx.sreg.ctaid.z (NVVM::BlockIdZOp) nvvm.read.ptx.sreg.nctaid.x (NVVM::GridDimXOp) nvvm.read.ptx.sreg.nctaid.y (NVVM::GridDimYOp) nvvm.read.ptx.sreg.nctaid.z (NVVM::GridDimZOp) nvvm.read.ptx.sreg.laneid (NVVM::LaneIdOp) nvvm.mma.sync (NVVM::MmaOp) nvvm.shfl.sync.bfly (NVVM::ShflBflyOp) nvvm.read.ptx.sreg.tid.x (NVVM::ThreadIdXOp) nvvm.read.ptx.sreg.tid.y (NVVM::ThreadIdYOp) nvvm.read.ptx.sreg.tid.z (NVVM::ThreadIdZOp) nvvm.vote.ballot.sync (NVVM::VoteBallotOp) nvvm.read.ptx.sreg.warpsize (NVVM::WarpSizeOp) Operation definition nvvm.barrier0 (NVVM::Barrier0Op) Syntax:
operation ::= `nvvm.barrier0` attr-dict nvvm.read.ptx.sreg.ntid.x (NVVM::BlockDimXOp) Syntax:
operation ::= `nvvm.read.ptx.sreg.ntid.x` attr-dict `:` type($res) Results: Result Description res LLVM dialect type nvvm.</description></item><item><title>'omp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/</guid><description>Operation definition omp.barrier (omp::BarrierOp) omp.taskwait (omp::TaskwaitOp) omp.taskyield (omp::TaskyieldOp) Operation definition omp.barrier (omp::BarrierOp) barrier construct
Syntax:
operation ::= `omp.barrier` attr-dict The barrier construct specifies an explicit barrier at the point at which the construct appears.
omp.taskwait (omp::TaskwaitOp) taskwait construct
Syntax:
operation ::= `omp.taskwait` attr-dict The taskwait construct specifies a wait on the completion of child tasks of the current task.
omp.taskyield (omp::TaskyieldOp) taskyield construct
Syntax:</description></item><item><title>'quant' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/QuantDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/QuantDialect/</guid><description>Type definition UniformQuantizedType Operation definition quant.const_fake_quant (quant::ConstFakeQuant) quant.const_fake_quant_per_axis (quant::ConstFakeQuantPerAxis) quant.coupled_ref (quant::CoupledRefOp) quant.dcast (quant::DequantizeCastOp) quant.qcast (quant::QuantizeCastOp) quant.region (quant::QuantizeRegionOp) quant.return (quant::ReturnOp) quant.stats (quant::StatisticsOp) quant.stats_ref (quant::StatisticsRefOp) quant.scast (quant::StorageCastOp) Type definition UniformQuantizedType Operation definition quant.const_fake_quant (quant::ConstFakeQuant) Simulates the effect of uniform quantization with const range. Given a const min, max, num_bits and narrow_range attribute, applies the same uniform quantization simulation as is done by the TensorFlow fake_quant_with_min_max_args op.</description></item><item><title>'rocdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</guid><description>Operation definition rocdl.workgroup.dim.x (ROCDL::BlockDimXOp) rocdl.workgroup.dim.y (ROCDL::BlockDimYOp) rocdl.workgroup.dim.z (ROCDL::BlockDimZOp) rocdl.workgroup.id.x (ROCDL::BlockIdXOp) rocdl.workgroup.id.y (ROCDL::BlockIdYOp) rocdl.workgroup.id.z (ROCDL::BlockIdZOp) rocdl.grid.dim.x (ROCDL::GridDimXOp) rocdl.grid.dim.y (ROCDL::GridDimYOp) rocdl.grid.dim.z (ROCDL::GridDimZOp) rocdl.workitem.id.x (ROCDL::ThreadIdXOp) rocdl.workitem.id.y (ROCDL::ThreadIdYOp) rocdl.workitem.id.z (ROCDL::ThreadIdZOp) Operation definition rocdl.workgroup.dim.x (ROCDL::BlockDimXOp) Syntax:
operation ::= `rocdl.workgroup.dim.x` attr-dict `:` type($res) Results: Result Description res LLVM dialect type rocdl.workgroup.dim.y (ROCDL::BlockDimYOp) Syntax:
operation ::= `rocdl.workgroup.dim.y` attr-dict `:` type($res) Results: Result Description res LLVM dialect type rocdl.</description></item><item><title>'shape' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</guid><description>Types and operations for shape dialect
This dialect contains operations for shape inference.
Note: Unless explicitly stated, all functions that return a shape and take shapes as input, return the invalid shape if one of its operands is an invalid shape. This avoids flagging multiple errors for one verification failure. The dialect itself does not specify how errors should be combined (there are multiple different options, from always choosing first operand, concatting etc.</description></item><item><title>'spv' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SPIR-V/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIR-V/</guid><description>This document describes the design of the SPIR-V dialect in MLIR. It lists various design choices we made for modeling different SPIR-V mechanisms, and their rationale.
This document also explains in a high-level manner how different components are organized and implemented in the code and gives steps to follow for extending them.
This document assumes familiarity with SPIR-V. SPIR-V is the Khronos Group’s binary intermediate language for representing graphics shaders and compute kernels.</description></item><item><title>'std' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Standard/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Standard/</guid><description>This dialect provides documentation for operations within the Standard dialect.
Note: This dialect is a collection of operations for several different concepts, and should be split into multiple more-focused dialects accordingly.
Operations std.absf (AbsFOp) std.addf (AddFOp) std.addi (AddIOp) std.alloc (AllocOp) std.alloca (AllocaOp) std.and (AndOp) std.assume_alignment (AssumeAlignmentOp) std.atomic_rmw (AtomicRMWOp) std.br (BranchOp) std.call_indirect (CallIndirectOp) std.call (CallOp) std.ceilf (CeilFOp) std.cmpf (CmpFOp) std.cmpi (CmpIOp) std.cond_br (CondBranchOp) std.constant (ConstantOp) std.copysign (CopySignOp) std.cos (CosOp) std.</description></item><item><title>'vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Vector/</guid><description>Positioning in the Codegen Infrastructure Components of a Generic Retargetable Vector-Level Dialect Short Description of the Existing Infrastructure LLVM level Hardware Vector Ops Virtual Vector Ops Virtual Vector Rewrite Patterns Virtual Vector to Hardware Vector Lowering Rationale Hardware as vector Machines of Minimum Granularity Transformations Problems Avoided The Big Out-Of-Scope Piece: Automatic Vectorization Bikeshed Naming Discussion DeeperDive Alternatives For Lowering an n-D Vector Type to LLVM Constraints Inherited from LLVM (see LangRef) Nested Aggregate Flattened 1-D Vector Type Discussion Relationship to LLVM matrix type proposal.</description></item><item><title>Background: declarative builders API</title><link>https://mlir.llvm.org/docs/EDSC/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/EDSC/</guid><description>The main purpose of the declarative builders API is to provide an intuitive way of constructing MLIR programmatically. In the majority of cases, the IR we wish to construct exhibits structured control-flow. The Declarative builders in the EDSC library (Embedded Domain Specific Constructs) provide an API to make MLIR construction and manipulation very idiomatic, for the structured control-flow case, in C++.
ScopedContext mlir::edsc::ScopedContext provides an implicit thread-local context, supporting a simple declarative API with globally accessible builders.</description></item><item><title>Chapter 1: Toy Tutorial Introduction</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</guid><description>The Chapters The Language The AST This tutorial runs through the implementation of a basic toy language on top of MLIR. The goal of this tutorial is to introduce the concepts of MLIR; in particular, how dialects can help easily support language specific constructs and transformations while still offering an easy path to lower to LLVM or other codegen infrastructure. This tutorial is based on the model of the LLVM Kaleidoscope Tutorial .</description></item><item><title>Chapter 2: Emitting Basic MLIR</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</guid><description>Introduction: Multi-Level Intermediate Representation Interfacing with MLIR Opaque API Defining a Toy Dialect Defining Toy Operations Op vs Operation: Using MLIR Operations Using the Operation Definition Specification (ODS) Framework Complete Toy Example Now that we&amp;rsquo;re familiar with our language and the AST, let&amp;rsquo;s see how MLIR can help to compile Toy.
Introduction: Multi-Level Intermediate Representation Other compilers, like LLVM (see the Kaleidoscope tutorial ), offer a fixed set of predefined types and (usually low-level / RISC-like) instructions.</description></item><item><title>Chapter 3: High-level Language-Specific Analysis and Transformation</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</guid><description>Optimize Transpose using C++ style pattern-match and rewrite Optimize Reshapes using DRR Creating a dialect that closely represents the semantics of an input language enables analyses, transformations and optimizations in MLIR that require high-level language information and are generally performed on the language AST. For example, clang has a fairly heavy mechanism for performing template instantiation in C++.
We divide compiler transformations into two categories: local and global.</description></item><item><title>Chapter 4: Enabling Generic Transformation with Interfaces</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</guid><description>Background: Grappling with an Extensible IR Shape Inference: Preparing for Code Generation Inlining Intraprocedural Shape Inference Background: Grappling with an Extensible IR Through dialects, MLIR allows for the representation of many different levels of abstraction; the Toy dialect that we have previously defined is one such example. Though these different dialects may represent different abstractions, there is often a set of common transformations and analyses that we would like to perform.</description></item><item><title>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</guid><description>Conversion Target Conversion Patterns Partial Lowering Design Considerations With Partial Lowering Complete Toy Example Taking Advantage of Affine Optimization At this point, we are eager to generate actual code and see our Toy language take life. We will use LLVM to generate code, but just showing the LLVM builder interface here wouldn&amp;rsquo;t be very exciting. Instead, we will show how to perform progressive lowering through a mix of dialects coexisting in the same function.</description></item><item><title>Chapter 6: Lowering to LLVM and CodeGeneration</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</guid><description>Lowering to LLVM Conversion Target Type Converter Conversion Patterns Full Lowering CodeGen: Getting Out of MLIR Emitting LLVM IR Setting up a JIT In the previous chapter , we introduced the dialect conversion framework and partially lowered many of the Toy operations to affine loop nests for optimization. In this chapter, we will finally lower to LLVM for code generation.
Lowering to LLVM For this lowering, we will again use the dialect conversion framework to perform the heavy lifting.</description></item><item><title>Chapter 7: Adding a Composite Type to Toy</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</guid><description>Defining a struct in Toy Defining a struct in MLIR Defining the Type Class Parsing and Printing Operating on StructType In the previous chapter , we demonstrated an end-to-end compilation flow from our Toy front-end to LLVM IR. In this chapter, we will extend the Toy language to support a new composite struct type.
Defining a struct in Toy The first thing we need to define is the interface of this type in our toy source language.</description></item><item><title>Conversion to the LLVM Dialect</title><link>https://mlir.llvm.org/docs/ConversionToLLVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ConversionToLLVMDialect/</guid><description>Conversion from the Standard to the LLVM Dialect can be performed by the specialized dialect conversion pass by running:
mlir-opt -convert-std-to-llvm &amp;lt;filename.mlir&amp;gt; It performs type and operation conversions for a subset of operations from standard dialect (operations on scalars and vectors, control flow operations) as described in this document. We use the terminology defined by the LLVM IR Dialect description throughout this document.
Type Conversion Scalar Types Index Type Vector Types Memref Types Function Types Calling Convention Function Signature Conversion Result Packing Calling Convention for memref C-compatible wrapper emission Repeated Successor Removal Default Memref Model Memref Descriptor Index Linearization Type Conversion Scalar Types Scalar types are converted to their LLVM counterparts if they exist.</description></item><item><title>Creating a Dialect</title><link>https://mlir.llvm.org/docs/Tutorials/CreatingADialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/CreatingADialect/</guid><description>CMake best practices TableGen Targets Library Targets CMake best practices Public dialects are typically separated into at least 3 directories:
mlir/include/mlir/Dialect/Foo (for public include files) mlir/lib/Dialect/Foo (for sources) mlir/lib/Dialect/Foo/IR (for operations) mlir/lib/Dialect/Foo/Transforms (for transforms) mlir/test/Dialect/Foo (for tests) Along with other public headers, the &amp;lsquo;include&amp;rsquo; directory contains a TableGen file in the ODS format , describing the operations in the dialect. This is used to generate operation declarations (FooOps.</description></item><item><title>Defining Dialect Attributes and Types</title><link>https://mlir.llvm.org/docs/Tutorials/DefiningAttributesAndTypes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/DefiningAttributesAndTypes/</guid><description>This document is a quickstart to defining dialect specific extensions to the attribute and type system . The main part of the tutorial focuses on defining types, but the instructions are nearly identical for defining attributes.
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc.
Types Types in MLIR (like attributes, locations, and many other things) are value-typed. This means that instances of Type should be passed around by-value, as opposed to by-pointer or by-reference.</description></item><item><title>Diagnostic Infrastructure</title><link>https://mlir.llvm.org/docs/Diagnostics/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Diagnostics/</guid><description>Source Locations CallSite Location FileLineCol Location Fused Location Name Location Opaque Location Unknown Location Diagnostic Engine Constructing a Diagnostic Diagnostic Appending arguments Attaching notes InFlight Diagnostic Diagnostic Configuration Options Print Operation On Diagnostic Print StackTrace On Diagnostic Common Diagnostic Handlers Scoped Diagnostic Handler SourceMgr Diagnostic Handler SourceMgr Diagnostic Verifier Handler Parallel Diagnostic Handler This document presents an introduction to using and interfacing with MLIR&amp;rsquo;s diagnostics infrastructure.</description></item><item><title>Dialect Conversion</title><link>https://mlir.llvm.org/docs/DialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DialectConversion/</guid><description>This document describes a framework in MLIR in which to perform operation conversions between, and within dialects. This framework allows for transforming illegal operations to those supported by a provided conversion target, via a set of pattern-based operation rewriting patterns.
Modes of Conversion Conversion Target Recursive Legality Rewrite Pattern Specification Restrictions Type Conversion Type Converter Conversion Patterns Region Signature Conversion To utilize the framework, a few things must be provided:</description></item><item><title>Generic DAG Rewriter Infrastructure</title><link>https://mlir.llvm.org/docs/GenericDAGRewriter/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/GenericDAGRewriter/</guid><description>Introduction and Motivation The goal of a compiler IR is to represent code - at various levels of abstraction which pose different sets of tradeoffs in terms of representational capabilities and ease of transformation. However, the ability to represent code is not itself very useful - you also need to be able to implement those transformations.
There are many different sorts of compiler transformations, but this document focuses on a particularly important class of transformation that comes up repeatedly at scale, and is important for the immediate goals of MLIR: that of pattern matching on a set of operations and replacing with another set.</description></item><item><title>Interfaces</title><link>https://mlir.llvm.org/docs/Interfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Interfaces/</guid><description>MLIR is generic and very extensible; it allows for opaquely representing many different dialects that have their own operations, attributes, types, and so on. This allows for dialects to be very expressive in their semantics and for MLIR to capture many different levels of abstraction. The downside to this is that transformations and analyses must be extremely conservative about the operations that they encounter, and must special-case the different dialects that they support.</description></item><item><title>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</title><link>https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/</guid><description>Introduction Positioning Inception Evolution Prior Art Lessons from ONNX Lessons from LIFT Lessons from XLA Lessons from Halide and TVM Lessons from Tensor Comprehensions Lessons from Polyhedral compilers Lessons from the Affine dialect Core Guiding Principles Transformations and Simplicity First Preservation of Information Composable and Declarative Transformations Suitability for Search and Machine Learning Extensibility and Future-Proofness Key Observations Algorithms + Data Structures = Programs The Dialect Need not be Closed Under Transformations Summary of Existing Alternatives a Picture Introduction Positioning This document describes the key design principles that led to the existing implementation of Linalg and aims at exposing the tradeoffs involved when building higher-level Intermediate Representations (IR) and Dialects to facilitate code generation.</description></item><item><title>MLIR Language Reference</title><link>https://mlir.llvm.org/docs/LangRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/LangRef/</guid><description>MLIR (Multi-Level IR) is a compiler intermediate representation with similarities to traditional three-address SSA representations (like LLVM IR or SIL ), but which introduces notions from polyhedral loop optimization as first-class concepts. This hybrid design is optimized to represent, analyze, and transform high level dataflow graphs as well as target-specific code generated for high performance data parallel systems. Beyond its representational capabilities, its single continuous design provides a framework to lower from dataflow graphs to high-performance target-specific code.</description></item><item><title>MLIR Rationale</title><link>https://mlir.llvm.org/docs/Rationale/Rationale/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/Rationale/</guid><description>This document is intended to capture some of the alternatives considered and open debates in the design of MLIR, along with the rationale for certain decisions we made. This is not intended to be a &amp;ldquo;finely groomed&amp;rdquo; document - we prefer the ability to dump in interesting tidbits without worrying too much about their consistency or readability.
Abstract Introduction and Motivation Design Decisions Loads and stores Symbols and types Block Arguments vs PHI nodes Index type disallowed in vector/memref types Bit width of a non-primitive types and index is undefined Integer signedness semantics Splitting floating point vs integer operations Specifying sign in integer comparison operations Specifying comparison kind as attribute &amp;lsquo;select&amp;rsquo; operation to implement min/max Regions Quantized integer operations Dialect type extensions Tuple types Assembly forms Examples Non-affine control flow Non-affine loop bounds Reference 2D Convolution Design alternatives and extensions Polyhedral code representation alternatives: schedule lists vs schedules trees vs affine loop/if forms Affine Relations Regions Read/Write/May_Read/May_Write sets for External Functions Memref Extensions affine.</description></item><item><title>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</title><link>https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/</guid><description>The existing documentation about MLIR focuses on long term vision, how its pieces fit together, and the benefits of modular and composable infrastructure in the vast and distant future. While this viewpoint appeals to some, it causes concern for others who are more concerned about the &amp;ldquo;here and now&amp;rdquo; - why does it make sense to make a &amp;ldquo;revolutionary&amp;rdquo; change when any individual problem can be fixed in place?
This document explains that adoption of MLIR to solve graph based problems isn&amp;rsquo;t a revolutionary change: it is an incremental series of steps which build on each other, each of which delivers local value.</description></item><item><title>MLIR: The case for a simplified polyhedral form</title><link>https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/</guid><description>MLIR embraces polyhedral compiler techniques for their many advantages representing and transforming dense numerical kernels, but it uses a form that differs significantly from other polyhedral frameworks.
Disclaimer / Warning
This document is a very early design proposal (which has since been accepted) that explored the tradeoffs of using this simplified form vs the traditional polyhedral schedule list form. At some point, this document could be dusted off and written as a proper academic paper, but until now, it is better to included it in this crafty form than not to.</description></item><item><title>Operation Canonicalization</title><link>https://mlir.llvm.org/docs/Canonicalization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Canonicalization/</guid><description>Canonicalization is an important part of compiler IR design: it makes it easier to implement reliable compiler transformations and to reason about what is better or worse in the code, and it forces interesting discussions about the goals of a particular level of IR. Dan Gohman wrote an article exploring these issues; it is worth reading if you&amp;rsquo;re not familiar with these concepts.
Most compilers have canonicalization passes, and sometimes they have many different ones (e.</description></item><item><title>Operation Traits</title><link>https://mlir.llvm.org/docs/Traits/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Traits/</guid><description>Defining a Trait Parametric Traits Attaching a Trait Using a Trait Trait List AutomaticAllocationScope Broadcastable Commutative Function-Like HasParent IsolatedFromAbove Single Block with Implicit Terminator Symbol SymbolTable Terminator MLIR allows for a truly open operation ecosystem, as any dialect may define operations that suit a specific level of abstraction. Traits are a mechanism in which to abstract implementation details and properties that are common across many different operations.</description></item><item><title>Pass Infrastructure</title><link>https://mlir.llvm.org/docs/PassManagement/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PassManagement/</guid><description>Operation Pass OperationPass : Op-Specific OperationPass : Op-Agnostic Analysis Management Querying Analyses Preserving Analyses Pass Failure Pass Manager OpPassManager Pass Registration Pass Pipeline Registration Textual Pass Pipeline Specification Instance Specific Pass Options Pass Statistics Declarative Pass Specification Tablegen Specification Pass Instrumentation Standard Instrumentations Crash and Failure Reproduction Passes represent the basic infrastructure for transformation and optimization.</description></item><item><title>Passes</title><link>https://mlir.llvm.org/docs/Passes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Passes/</guid><description>This document describes the available MLIR passes and their contracts.
General Transformation Passes -affine-loop-fusion: Fuse affine loop nests -affine-pipeline-data-transfer: Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy -canonicalize: Canonicalize operations -cse: Eliminate common sub-expressions -inline: Inline function calls -loop-coalescing: Coalesce nested loops with independent bounds into a single loop -loop-invariant-code-motion: Hoist loop invariant instructions outside of the loop -memref-dataflow-opt: Perform store/load forwarding for memrefs -parallel-loop-collapsing: Collapse parallel loops to use less induction variables -print-cfg-graph: Print CFG graph per-Region -print-op-graph: Print op graph per-Region -print-op-stats: Print statistics of operations -snapshot-op-locations: Generate new locations from the current IR -strip-debuginfo: Strip debug info from all operations -symbol-dce: Eliminate dead symbols Conversion Passes -convert-avx512-to-llvm: Convert the operations from the avx512 dialect into the LLVM dialect -convert-gpu-launch-to-vulkan-launch: Convert gpu.</description></item><item><title>Quantization</title><link>https://mlir.llvm.org/docs/Quantization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Quantization/</guid><description>This document outlines the design of the MLIR quantization system. While the term &amp;ldquo;quantization&amp;rdquo; is highly overloaded, in this case, it refers to a fairly narrow scope of techniques in use to enable conversion of floating-point computations to corresponding and plausible variants expressed in integer math for inference, as has historically been supported by low-bit depth inference engines such as TFLite, various accelerator hardware, and many DSPs.
Much of this is inspired by the approach taken in this paper with many extensions and adaptations folded in.</description></item><item><title>Quickstart tutorial to adding MLIR graph rewrite</title><link>https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/</guid><description>This document will present a quickstart to adding graph rewrites. We shall start by defining an operation, showing multiple ways to define the rewrite using patterns, as well as defining the rewrite using a graph walker (note: using patterns and the rewrite engine is preferred, showing the walker is for demonstration purposes).
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc. See Table-driven Operation Definition and Declarative Rewrite Rule for the detailed explanation of all available mechanisms for defining operations and rewrites in a table-driven manner.</description></item><item><title>Shape Inference</title><link>https://mlir.llvm.org/docs/ShapeInference/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ShapeInference/</guid><description>Shape inference as discussed here is considered a specific instance of type inference for ShapedType . Type constraints are along (at least) three axis: 1) elemental type, 2) rank (including static or dynamic), 3) dimensions. While some operations have no compile time fixed shape (e.g., output shape is dictated by data) we could still have some knowledge of constraints/bounds in the system for that operation (e.g., the output of a tf.</description></item><item><title>Symbols and Symbol Tables</title><link>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</guid><description>Symbol Defining a Symbol Symbol Table Referencing a Symbol Manipulating a Symbol Symbol Visibility With Regions , the multi-level aspect of MLIR is structural in the IR. A lot of infrastructure within the compiler is built around this nesting structure; including the processing of operations within the pass manager . One advantage of the MLIR design is that it is able to process operations in parallel, utilizing multiple threads.</description></item><item><title>Table-driven Declarative Rewrite Rule (DRR)</title><link>https://mlir.llvm.org/docs/DeclarativeRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DeclarativeRewrites/</guid><description>In addition to subclassing the mlir::RewritePattern C++ class, MLIR also supports defining rewrite rules in a declarative manner. Similar to Op Definition Specification (ODS), this is achieved via TableGen , which is a language to maintain records of domain-specific information. The rewrite rules are specified concisely in a TableGen record, which will be expanded into an equivalent mlir::RewritePattern subclass at compiler build time.
This manual explains in detail all of the available mechanisms for defining rewrite rules in such a declarative manner.</description></item><item><title>Table-driven Operation Definition Specification (ODS)</title><link>https://mlir.llvm.org/docs/OpDefinitions/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/OpDefinitions/</guid><description>In addition to specializing the mlir::Op C++ template, MLIR also supports defining operations in a table-driven manner. This is achieved via TableGen , which is both a generic language and its tooling to maintain records of domain-specific information. Facts regarding an operation are specified concisely into a TableGen record, which will be expanded into an equivalent mlir::Op C++ template specialization at compiler build time.
This manual explains in detail all the available mechanisms for defining operations in such a table-driven manner.</description></item><item><title>Usage of 'Const' in MLIR, for core IR types</title><link>https://mlir.llvm.org/docs/Rationale/UsageOfConst/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/UsageOfConst/</guid><description>aka, where&amp;rsquo;d const go?
The MLIR data structures that represent the IR itself (Instruction, Block, etc) form a graph-based data structure, and the compiler analyses and passes frequently walk this graph (e.g. traversing from defs to users). The early design of MLIR adopted the const model of LLVM, which is familiar and well understood (even though the LLVM implementation is flawed in many ways).
The design team since decided to change to a different module, which eschews const entirely for the core IR types: you should never see a const method on Operation, should never see the type const Value, and you shouldn&amp;rsquo;t feel bad about this.</description></item></channel></rss>