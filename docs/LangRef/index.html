<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>MLIR Language Reference - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.64.1"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/LangRef/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/master/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/master/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li></ul></nav></div><div class=content-container><main><h1>MLIR Language Reference</h1><p>MLIR (Multi-Level IR) is a compiler intermediate representation with
similarities to traditional three-address SSA representations (like
<a href=http://llvm.org/docs/LangRef.html>LLVM IR</a>
or
<a href=https://github.com/apple/swift/blob/master/docs/SIL.rst>SIL</a>
), but which
introduces notions from polyhedral loop optimization as first-class concepts.
This hybrid design is optimized to represent, analyze, and transform high level
dataflow graphs as well as target-specific code generated for high performance
data parallel systems. Beyond its representational capabilities, its single
continuous design provides a framework to lower from dataflow graphs to
high-performance target-specific code.</p><p>This document defines and describes the key concepts in MLIR, and is intended to
be a dry reference document - the
<a href=/docs/Rationale/Rationale/>rationale documentation</a>
,
<a href=/getting_started/Glossary/>glossary</a>
, and other content are hosted elsewhere.</p><p>MLIR is designed to be used in three different forms: a human-readable textual
form suitable for debugging, an in-memory form suitable for programmatic
transformations and analysis, and a compact serialized form suitable for storage
and transport. The different forms all describe the same semantic content. This
document describes the human-readable textual form.</p><p><nav id=TableOfContents><ul><li><a href=#high-level-structure>High-Level Structure</a></li><li><a href=#notation>Notation</a><ul><li><a href=#common-syntax>Common syntax</a></li><li><a href=#identifiers-and-keywords>Identifiers and keywords</a></li></ul></li><li><a href=#dialects>Dialects</a><ul><li><a href=#target-specific-operations>Target specific operations</a></li></ul></li><li><a href=#operations>Operations</a><ul><li><a href=#terminator-operations>Terminator Operations</a></li><li><a href=#module>Module</a></li><li><a href=#functions>Functions</a></li></ul></li><li><a href=#blocks>Blocks</a></li><li><a href=#regions>Regions</a><ul><li><a href=#definition>Definition</a></li><li><a href=#control-and-value-scoping>Control and Value Scoping</a></li><li><a href=#control-flow>Control Flow</a></li><li><a href=#arguments-and-results>Arguments and Results</a></li></ul></li><li><a href=#type-system>Type System</a><ul><li><a href=#type-aliases>Type Aliases</a></li><li><a href=#dialect-types>Dialect Types</a></li><li><a href=#standard-types>Standard Types</a></li></ul></li><li><a href=#attributes>Attributes</a><ul><li><a href=#attribute-value-aliases>Attribute Value Aliases</a></li><li><a href=#dialect-attribute-values>Dialect Attribute Values</a></li><li><a href=#standard-attribute-values>Standard Attribute Values</a></li></ul></li></ul></nav><h2 id=high-level-structure>High-Level Structure&nbsp;<a class=headline-hash href=#high-level-structure>¶</a></h2><p>MLIR is an
<a href=https://en.wikipedia.org/wiki/Static_single_assignment_form>SSA-based</a>
IR,
which means that values are defined before use and have scope defined by their
dominance relations. Operations may produce zero or more results, and each is a
distinct SSA value with its own type defined by the
<a href=#type-system>type system</a>
.</p><p>The unit of code in MLIR is an
<a href=#operations>Operation</a>
. Operations allow for
representing many different concepts: allocating buffers, producing views to
transform them, target-independent arithmetic, target-specific operations, and
even arbitrary user-defined high-level operations including the
<a href=#module>Module</a>
and
<a href=#functions>Function</a>
operations. Operations may contain
<a href=#regions>Regions</a>
that represent a Control Flow Graph (CFG) of
<a href=#blocks>Blocks</a>
, that contain operations and end with a
<a href=#terminator-operations>terminator operation</a>
(like branches).</p><p>Here&rsquo;s an example of an MLIR module:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Compute A*B using an implementation of multiply kernel and print the
</span><span class=c></span><span class=c>// result using a TensorFlow op. The dimensions of A and B are partially
</span><span class=c></span><span class=c>// known. The shapes are assumed to match.
</span><span class=c></span><span class=kt>func</span> <span class=nf>@mul</span><span class=p>(</span><span class=nv>%A</span><span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=nv>%B</span><span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x50x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>{</span>
  <span class=c>// Compute the inner dimension of %A using the dim operation.
</span><span class=c></span>  <span class=nv>%n</span> <span class=p>=</span> dim <span class=nv>%A</span><span class=p>,</span> <span class=m>1</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span>

  <span class=c>// Allocate addressable &#34;buffers&#34; and copy tensors %A and %B into them.
</span><span class=c></span>  <span class=nv>%A_m</span> <span class=p>=</span> alloc<span class=p>(</span><span class=nv>%n</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=kt>tensor</span>_store <span class=nv>%A</span> to <span class=nv>%A_m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span>

  <span class=nv>%B_m</span> <span class=p>=</span> alloc<span class=p>(</span><span class=nv>%n</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x50x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=kt>tensor</span>_store <span class=nv>%B</span> to <span class=nv>%B_m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x50x</span><span class=k>f32</span><span class=p>&gt;</span>

  <span class=c>// Call function @multiply passing memrefs as arguments,
</span><span class=c></span>  <span class=c>// and getting returned the result of the multiplication.
</span><span class=c></span>  <span class=nv>%C_m</span> <span class=p>=</span> call <span class=nf>@multiply</span><span class=p>(</span><span class=nv>%A_m</span><span class=p>,</span> <span class=nv>%B_m</span><span class=p>)</span>
          <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x50x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>

  dealloc <span class=nv>%A_m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span>
  dealloc <span class=nv>%B_m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x50x</span><span class=k>f32</span><span class=p>&gt;</span>

  <span class=c>// Load the buffer data into a higher level &#34;tensor&#34; value.
</span><span class=c></span>  <span class=nv>%C</span> <span class=p>=</span> <span class=kt>tensor</span>_load <span class=nv>%C_m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>
  dealloc <span class=nv>%C_m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>

  <span class=c>// Call TensorFlow built-in function to print the result tensor.
</span><span class=c></span>  <span class=s>&#34;tf.Print&#34;</span><span class=p>(</span><span class=nv>%C</span><span class=p>)</span><span class=p>{</span>message<span class=p>:</span> <span class=s>&#34;mul result&#34;</span><span class=p>}</span>
                  <span class=p>:</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>

  <span class=kt>return</span> <span class=nv>%C</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=p>}</span>

<span class=c>// A function that multiplies two memrefs and returns the result.
</span><span class=c></span><span class=kt>func</span> <span class=nf>@multiply</span><span class=p>(</span><span class=nv>%A</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=nv>%B</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x50x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>
          <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>  <span class=p>{</span>
  <span class=c>// Compute the inner dimension of %A.
</span><span class=c></span>  <span class=nv>%n</span> <span class=p>=</span> dim <span class=nv>%A</span><span class=p>,</span> <span class=m>1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span>

  <span class=c>// Allocate memory for the multiplication result.
</span><span class=c></span>  <span class=nv>%C</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>

  <span class=c>// Multiplication loop nest.
</span><span class=c></span>  affine<span class=p>.</span>for <span class=nv>%i</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>100</span> <span class=p>{</span>
     affine<span class=p>.</span>for <span class=nv>%j</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>50</span> <span class=p>{</span>
        store <span class=m>0</span> to <span class=nv>%C</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>
        affine<span class=p>.</span>for <span class=nv>%k</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%n</span> <span class=p>{</span>
           <span class=nv>%a_v</span>  <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%k</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x?x</span><span class=k>f32</span><span class=p>&gt;</span>
           <span class=nv>%b_v</span>  <span class=p>=</span> load <span class=nv>%B</span><span class=p>[</span><span class=nv>%k</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x50x</span><span class=k>f32</span><span class=p>&gt;</span>
           <span class=nv>%prod</span> <span class=p>=</span> mulf <span class=nv>%a_v</span><span class=p>,</span> <span class=nv>%b_v</span> <span class=p>:</span> <span class=k>f32</span>
           <span class=nv>%c_v</span>  <span class=p>=</span> load <span class=nv>%C</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>
           <span class=nv>%sum</span>  <span class=p>=</span> addf <span class=nv>%c_v</span><span class=p>,</span> <span class=nv>%prod</span> <span class=p>:</span> <span class=k>f32</span>
           store <span class=nv>%sum</span><span class=p>,</span> <span class=nv>%C</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>
        <span class=p>}</span>
     <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span> <span class=nv>%C</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x50x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><h2 id=notation>Notation&nbsp;<a class=headline-hash href=#notation>¶</a></h2><p>MLIR has a simple and unambiguous grammar, allowing it to reliably round-trip
through a textual form. This is important for development of the compiler - e.g.
for understanding the state of code as it is being transformed and writing test
cases.</p><p>This document describes the grammar using
<a href=https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form>Extended Backus-Naur Form (EBNF)</a>
.</p><p>This is the EBNF grammar used in this document, presented in yellow boxes.</p><pre><code>alternation ::= expr0 | expr1 | expr2  // Either expr0 or expr1 or expr2.
sequence    ::= expr0 expr1 expr2      // Sequence of expr0 expr1 expr2.
repetition0 ::= expr*  // 0 or more occurrences.
repetition1 ::= expr+  // 1 or more occurrences.
optionality ::= expr?  // 0 or 1 occurrence.
grouping    ::= (expr) // Everything inside parens is grouped together.
literal     ::= `abcd` // Matches the literal `abcd`.
</code></pre><p>Code examples are presented in blue boxes.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// This is an example use of the grammar above:
</span><span class=c></span><span class=c>// This matches things like: ba, bana, boma, banana, banoma, bomana...
</span><span class=c></span>example <span class=p>:</span><span class=p>:</span><span class=p>=</span> <span class=err>`</span>b<span class=err>`</span> <span class=p>(</span><span class=err>`</span>an<span class=err>`</span> <span class=err>|</span> <span class=err>`</span>om<span class=err>`</span><span class=p>)</span><span class=p>*</span> <span class=err>`</span>a<span class=err>`</span>
</code></pre></div><h3 id=common-syntax>Common syntax&nbsp;<a class=headline-hash href=#common-syntax>¶</a></h3><p>The following core grammar productions are used in this document:</p><pre><code>// TODO: Clarify the split between lexing (tokens) and parsing (grammar).
digit     ::= [0-9]
hex_digit ::= [0-9a-fA-F]
letter    ::= [a-zA-Z]
id-punct  ::= [$._-]

integer-literal ::= decimal-literal | hexadecimal-literal
decimal-literal ::= digit+
hexadecimal-literal ::= `0x` hex_digit+
float-literal ::= [-+]?[0-9]+[.][0-9]*([eE][-+]?[0-9]+)?
string-literal  ::= `&quot;` [^&quot;\n\f\v\r]* `&quot;`   TODO define escaping rules
</code></pre><p>Not listed here, but MLIR does support comments. They use standard BCPL syntax,
starting with a <code>//</code> and going until the end of the line.</p><h3 id=identifiers-and-keywords>Identifiers and keywords&nbsp;<a class=headline-hash href=#identifiers-and-keywords>¶</a></h3><p>Syntax:</p><pre><code>// Identifiers
bare-id ::= (letter|[_]) (letter|digit|[_$.])*
bare-id-list ::= bare-id (`,` bare-id)*
ssa-id ::= `%` suffix-id
suffix-id ::= (digit+ | ((letter|id-punct) (letter|id-punct|digit)*))

symbol-ref-id ::= `@` (suffix-id | string-literal)
ssa-id-list ::= ssa-id (`,` ssa-id)*

// Uses of an SSA value, e.g. in an operand list to an operation.
ssa-use ::= ssa-id
ssa-use-list ::= ssa-use (`,` ssa-use)*
</code></pre><p>Identifiers name entities such as SSA values, types and functions, and are
chosen by the writer of MLIR code. Identifiers may be descriptive (e.g.
<code>%batch_size</code>, <code>@matmul</code>), or may be non-descriptive when they are
auto-generated (e.g. <code>%23</code>, <code>@func42</code>). Identifier names for SSA values may be
used in an MLIR text file but are not persisted as part of the IR - the printer
will give them anonymous names like <code>%42</code>.</p><p>MLIR guarantees identifiers never collide with keywords by prefixing identifiers
with a sigil (e.g. <code>%</code>, <code>#</code>, <code>@</code>, <code>^</code>, <code>!</code>). In certain unambiguous contexts
(e.g. affine expressions), identifiers are not prefixed, for brevity. New
keywords may be added to future versions of MLIR without danger of collision
with existing identifiers.</p><p>The scope of SSA values is defined based on the standard definition of
<a href=https://en.wikipedia.org/wiki/Dominator_%5c%28graph_theory%5c%29>dominance</a>
. Argument
identifiers in mapping functions are in scope for the mapping body. Function
identifiers and mapping identifiers are visible across the entire module.</p><h2 id=dialects>Dialects&nbsp;<a class=headline-hash href=#dialects>¶</a></h2><p>Dialects are the mechanism by which to engage with and extend the MLIR
ecosystem. They allow for defining new
<a href=#operations>operations</a>
, as well as
<a href=#attributes>attributes</a>
and
<a href=#type-system>types</a>
. Each dialect is given a
unique <code>namespace</code> that is prefixed to each defined attribute/operation/type.
For example, the
<a href=/docs/Dialects/Affine/>Affine dialect</a>
defines the namespace:
<code>affine</code>.</p><p>MLIR allows for multiple dialects, even those outside of the main tree, to
co-exist together within one module. Dialects are produced and consumed by
certain passes. MLIR provides a
<a href=/docs/DialectConversion/>framework</a>
to convert
between, and within, different dialects.</p><p>A few of the dialects supported by MLIR:</p><ul><li><a href=/docs/Dialects/Affine/>Affine dialect</a></li><li><a href=/docs/Dialects/GPU/>GPU dialect</a></li><li><a href=/docs/Dialects/LLVM/>LLVM dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>SPIR-V dialect</a></li><li><a href=/docs/Dialects/Standard/>Standard dialect</a></li><li><a href=/docs/Dialects/Vector/>Vector dialect</a></li></ul><h3 id=target-specific-operations>Target specific operations&nbsp;<a class=headline-hash href=#target-specific-operations>¶</a></h3><p>Dialects provide a modular way in which targets can expose target-specific
operations directly through to MLIR. As an example, some targets go through
LLVM. LLVM has a rich set of intrinsics for certain target-independent
operations (e.g. addition with overflow check) as well as providing access to
target-specific operations for the targets it supports (e.g. vector permutation
operations). LLVM intrinsics in MLIR are represented via operations that start
with an &ldquo;llvm.&rdquo; name.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// LLVM: %x = call {i16, i1} @llvm.sadd.with.overflow.i16(i16 %a, i16 %b)
</span><span class=c></span><span class=nv>%x</span><span class=p>:</span><span class=nl>2 =</span> <span class=s>&#34;llvm.sadd.with.overflow.i16&#34;</span><span class=p>(</span><span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>i16</span><span class=p>,</span> <span class=k>i16</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>i16</span><span class=p>,</span> <span class=k>i1</span><span class=p>)</span>
</code></pre></div><p>These operations only work when targeting LLVM as a backend (e.g. for CPUs and
GPUs), and are required to align with the LLVM definition of these intrinsics.</p><h2 id=operations>Operations&nbsp;<a class=headline-hash href=#operations>¶</a></h2><p>Syntax:</p><pre><code>operation         ::= op-result-list? (generic-operation | custom-operation)
                      trailing-location?
generic-operation ::= string-literal `(` ssa-use-list? `)`  successor-list?
                      (`(` region-list `)`)? attribute-dict? `:` function-type
custom-operation  ::= bare-id custom-operation-format
op-result-list    ::= op-result (`,` op-result)* `=`
op-result         ::= ssa-id (`:` integer-literal)
successor-list    ::= successor (`,` successor)*
successor         ::= caret-id (`:` bb-arg-list)?
region-list       ::= region (`,` region)*
trailing-location ::= (`loc` `(` location `)`)?
</code></pre><p>MLIR introduces a uniform concept called <em>operations</em> to enable describing many
different levels of abstractions and computations. Operations in MLIR are fully
extensible (there is no fixed list of operations) and have application-specific
semantics. For example, MLIR supports
<a href=/docs/Dialects/Standard/#memory-operations>target-independent operations</a>
,
<a href=/docs/Dialects/Affine/>affine operations</a>
, and
<a href=#target-specific-operations>target-specific machine operations</a>
.</p><p>The internal representation of an operation is simple: an operation is
identified by a unique string (e.g. <code>dim</code>, <code>tf.Conv2d</code>, <code>x86.repmovsb</code>,
<code>ppc.eieio</code>, etc), can return zero or more results, take zero or more SSA
operands, may have zero or more attributes, may have zero or more successors,
and zero or more enclosed
<a href=#regions>regions</a>
. The generic printing form
includes all these elements literally, with a function type to indicate the
types of the results and operands.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// An operation that produces two results.
</span><span class=c></span><span class=c>// The results of %result can be accessed via the &lt;name&gt; `#` &lt;opNo&gt; syntax.
</span><span class=c></span><span class=nv>%result</span><span class=p>:</span><span class=nl>2 =</span> <span class=s>&#34;foo_div&#34;</span><span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>f32</span><span class=p>,</span> <span class=k>i32</span><span class=p>)</span>

<span class=c>// Pretty form that defines a unique name for each result.
</span><span class=c></span><span class=nv>%foo</span><span class=p>,</span> <span class=nv>%bar</span> <span class=p>=</span> <span class=s>&#34;foo_div&#34;</span><span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>f32</span><span class=p>,</span> <span class=k>i32</span><span class=p>)</span>

<span class=c>// Invoke a TensorFlow function called tf.scramble with two inputs
</span><span class=c></span><span class=c>// and an attribute &#34;fruit&#34;.
</span><span class=c></span><span class=nv>%2</span> <span class=p>=</span> <span class=s>&#34;tf.scramble&#34;</span><span class=p>(</span><span class=nv>%result</span><span class=nv>#0</span><span class=p>,</span> <span class=nv>%bar</span><span class=p>)</span> <span class=p>{</span>fruit<span class=p>:</span> <span class=s>&#34;banana&#34;</span><span class=p>}</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>,</span> <span class=k>i32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
</code></pre></div><p>In addition to the basic syntax above, dialects may register known operations.
This allows those dialects to support <em>custom assembly form</em> for parsing and
printing operations. In the operation sets listed below, we show both forms.</p><h3 id=terminator-operations>Terminator Operations&nbsp;<a class=headline-hash href=#terminator-operations>¶</a></h3><p>These are a special category of operations that <em>must</em> terminate a block, e.g.
<a href=/docs/Dialects/Standard/#terminator-operations>branches</a>
. These operations may
also have a list of successors (
<a href=#blocks>blocks</a>
and their arguments).</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Branch to ^bb1 or ^bb2 depending on the condition %cond.
</span><span class=c></span><span class=c>// Pass value %v to ^bb2, but not to ^bb1.
</span><span class=c></span><span class=s>&#34;cond_br&#34;</span><span class=p>(</span><span class=nv>%cond</span><span class=p>)</span><span class=p>[</span><span class=nl>^bb1</span><span class=p>,</span> <span class=nl>^bb2</span><span class=p>(</span><span class=nv>%v</span> <span class=p>:</span> <span class=k>index</span><span class=p>)</span><span class=p>]</span> <span class=p>:</span> <span class=p>(</span><span class=k>i1</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
</code></pre></div><h3 id=module>Module&nbsp;<a class=headline-hash href=#module>¶</a></h3><pre><code>module ::= `module` symbol-ref-id? (`attributes` attribute-dict)? region
</code></pre><p>An MLIR module represents an opaque top-level container operation. It contains a
single region containing a single block that is comprised of any operations.
Operations within this region must not implicitly capture values defined above
it. Modules have an optional symbol name that can be used to refer to them in
operations.</p><h3 id=functions>Functions&nbsp;<a class=headline-hash href=#functions>¶</a></h3><p>An MLIR Function is an operation with a name containing one
<a href=#regions>region</a>
.
The region of a function is not allowed to implicitly capture values defined
outside of the function, and all external references must use function arguments
or attributes that establish a symbolic connection (e.g. symbols referenced by
name via a string attribute like
<a href=#symbol-reference-attribute>SymbolRefAttr</a>
):</p><pre><code>function ::= `func` function-signature function-attributes? function-body?

function-signature ::= symbol-ref-id `(` argument-list `)`
                       (`-&gt;` function-result-list)?

argument-list ::= (named-argument (`,` named-argument)*) | /*empty*/
argument-list ::= (type attribute-dict? (`,` type attribute-dict?)*) | /*empty*/
named-argument ::= ssa-id `:` type attribute-dict?

function-result-list ::= function-result-list-parens
                       | non-function-type
function-result-list-parens ::= `(` `)`
                              | `(` function-result-list-no-parens `)`
function-result-list-no-parens ::= function-result (`,` function-result)*
function-result ::= type attribute-dict?

function-attributes ::= `attributes` attribute-dict
function-body ::= region
</code></pre><p>An external function declaration (used when referring to a function declared in
some other module) has no body. While the MLIR textual form provides a nice
inline syntax for function arguments, they are internally represented as &ldquo;block
arguments&rdquo; to the first block in the region.</p><p>Only dialect attribute names may be specified in the attribute dictionaries for
function arguments, results, or the function itself.</p><p>Examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// External function definitions.
</span><span class=c></span><span class=kt>func</span> <span class=nf>@abort</span><span class=p>(</span><span class=p>)</span>
<span class=kt>func</span> <span class=nf>@scribble</span><span class=p>(</span><span class=k>i32</span><span class=p>,</span> <span class=k>i64</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>? x</span> <span class=m>128 x</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>#layout_map0</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f64</span>

<span class=c>// A function that returns its argument twice:
</span><span class=c></span><span class=kt>func</span> <span class=nf>@count</span><span class=p>(</span><span class=nv>%x</span><span class=p>:</span> <span class=k>i64</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>i64</span><span class=p>,</span> <span class=k>i64</span><span class=p>)</span>
  attributes <span class=p>{</span>fruit<span class=p>:</span> <span class=s>&#34;banana&#34;</span><span class=p>}</span> <span class=p>{</span>
  <span class=kt>return</span> <span class=nv>%x</span><span class=p>,</span> <span class=nv>%x</span><span class=p>:</span> <span class=k>i64</span><span class=p>,</span> <span class=k>i64</span>
<span class=p>}</span>

<span class=c>// A function with an argument attribute
</span><span class=c></span><span class=kt>func</span> <span class=nf>@example_fn_arg</span><span class=p>(</span><span class=nv>%x</span><span class=p>:</span> <span class=k>i32</span> <span class=p>{</span><span class=nl>swift.self =</span> unit<span class=p>}</span><span class=p>)</span>

<span class=c>// A function with a result attribute
</span><span class=c></span><span class=kt>func</span> <span class=nf>@example_fn_result</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>f64</span> <span class=p>{</span><span class=nl>dialectName.attrName =</span> <span class=m>0</span> <span class=p>:</span> <span class=k>i64</span><span class=p>}</span><span class=p>)</span>

<span class=c>// A function with an attribute
</span><span class=c></span><span class=kt>func</span> <span class=nf>@example_fn_attr</span><span class=p>(</span><span class=p>)</span> attributes <span class=p>{</span><span class=nl>dialectName.attrName =</span> false<span class=p>}</span>
</code></pre></div><h2 id=blocks>Blocks&nbsp;<a class=headline-hash href=#blocks>¶</a></h2><p>Syntax:</p><pre><code>block           ::= block-label operation+
block-label     ::= block-id block-arg-list? `:`
block-id        ::= caret-id
caret-id        ::= `^` suffix-id
ssa-id-and-type ::= ssa-id `:` type

// Non-empty list of names and types.
ssa-id-and-type-list ::= ssa-id-and-type (`,` ssa-id-and-type)*

block-arg-list ::= `(` ssa-id-and-type-list? `)`
</code></pre><p>A
<a href=https://en.wikipedia.org/wiki/Basic_block>block</a>
is a sequential list of
operations without control flow (a call or entering an op&rsquo;s region is not
considered control flow for this purpose) that are executed from top to bottom.
The last operation in a block is a
<a href=#terminator-operations>terminator operation</a>
, which ends the block.</p><p>Blocks in MLIR take a list of block arguments, which represent SSA PHI nodes in
a functional notation. The arguments are defined by the block, and values are
provided for these block arguments by branches that go to the block.</p><p>Here is a simple example function showing branches, returns, and block
arguments:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@simple</span><span class=p>(</span><span class=k>i64</span><span class=p>,</span> <span class=k>i1</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>i64</span> <span class=p>{</span>
<span class=nl>^bb0</span><span class=p>(</span><span class=nv>%a</span><span class=p>:</span> <span class=k>i64</span><span class=p>,</span> <span class=nv>%cond</span><span class=p>:</span> <span class=k>i1</span><span class=p>)</span><span class=p>:</span> <span class=c>// Code dominated by ^bb0 may refer to %a
</span><span class=c></span>  cond_br <span class=nv>%cond</span><span class=p>,</span> <span class=nl>^bb1</span><span class=p>,</span> <span class=nl>^bb2
</span><span class=nl>
</span><span class=nl></span><span class=nl>^bb1</span><span class=p>:</span>
  br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%a</span><span class=p>:</span> <span class=k>i64</span><span class=p>)</span>    <span class=c>// Branch passes %a as the argument
</span><span class=c></span>
<span class=nl>^bb2</span><span class=p>:</span>
  <span class=nv>%b</span> <span class=p>=</span> addi <span class=nv>%a</span><span class=p>,</span> <span class=nv>%a</span> <span class=p>:</span> <span class=k>i64</span>
  br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%b</span><span class=p>:</span> <span class=k>i64</span><span class=p>)</span>    <span class=c>// Branch passes %b as the argument
</span><span class=c></span>
<span class=c>// ^bb3 receives an argument, named %c, from predecessors
</span><span class=c></span><span class=c>// and passes it on to bb4 twice.
</span><span class=c></span><span class=nl>^bb3</span><span class=p>(</span><span class=nv>%c</span><span class=p>:</span> <span class=k>i64</span><span class=p>)</span><span class=p>:</span>
  br <span class=nl>^bb4</span><span class=p>(</span><span class=nv>%c</span><span class=p>,</span> <span class=nv>%c</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span> <span class=k>i64</span><span class=p>)</span>

<span class=nl>^bb4</span><span class=p>(</span><span class=nv>%d</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span> <span class=nv>%e</span> <span class=p>:</span> <span class=k>i64</span><span class=p>)</span><span class=p>:</span>
  <span class=nv>%0</span> <span class=p>=</span> addi <span class=nv>%d</span><span class=p>,</span> <span class=nv>%e</span> <span class=p>:</span> <span class=k>i64</span>
  <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=k>i64</span>
<span class=p>}</span>
</code></pre></div><p><strong>Context:</strong> The &ldquo;block argument&rdquo; representation eliminates a number of special
cases from the IR compared to traditional &ldquo;PHI nodes are operations&rdquo; SSA IRs
(like LLVM). For example, the
<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.524.5461&rep=rep1&type=pdf">parallel copy semantics</a>
of SSA is immediately apparent, and function arguments are no longer a special
case: they become arguments to the entry block
[
<a href=/docs/Rationale/Rationale/#block-arguments-vs-phi-nodes>more rationale</a>
].</p><h2 id=regions>Regions&nbsp;<a class=headline-hash href=#regions>¶</a></h2><h3 id=definition>Definition&nbsp;<a class=headline-hash href=#definition>¶</a></h3><p>A region is a CFG of MLIR
<a href=#blocks>Blocks</a>
. Regions serve to group semantically
connected blocks, where the semantics is not imposed by the IR. Instead, the
containing operation defines the semantics of the regions it contains. Regions
do not have a name or an address, only the blocks contained in a region do.
Regions are meaningless outside of the containing entity and have no type or
attributes.</p><p>The first block in the region cannot be a successor of any other block. The
syntax for the region is as follows:</p><pre><code>region ::= `{` block* `}`
</code></pre><p>The function body is an example of a region: it consists of a CFG of blocks and
has additional semantic restrictions that other types of regions may not have
(block terminators must either branch to a different block, or return from a
function where the types of the <code>return</code> arguments must match the result types
of the function signature).</p><h3 id=control-and-value-scoping>Control and Value Scoping&nbsp;<a class=headline-hash href=#control-and-value-scoping>¶</a></h3><p>Regions provide nested control isolation: it is impossible to branch to a block
within a region from outside it or to branch from within a region to a block
outside it. Similarly, it provides a natural scoping for value visibility: SSA
values defined in a region don&rsquo;t escape to the enclosing region, if any. By
default, a region can reference values defined outside of the region whenever it
would have been legal to use them as operands to the enclosing operation.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@accelerator_compute</span><span class=p>(</span><span class=k>i64</span><span class=p>,</span> <span class=k>i1</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>i64</span> <span class=p>{</span>
<span class=nl>^bb0</span><span class=p>(</span><span class=nv>%a</span><span class=p>:</span> <span class=k>i64</span><span class=p>,</span> <span class=nv>%cond</span><span class=p>:</span> <span class=k>i1</span><span class=p>)</span><span class=p>:</span> <span class=c>// Code dominated by ^bb0 may refer to %a
</span><span class=c></span>  cond_br <span class=nv>%cond</span><span class=p>,</span> <span class=nl>^bb1</span><span class=p>,</span> <span class=nl>^bb2
</span><span class=nl>
</span><span class=nl></span><span class=nl>^bb1</span><span class=p>:</span>
  <span class=c>// This def for %value does not dominate ^bb2
</span><span class=c></span>  <span class=nv>%value</span> <span class=p>=</span> <span class=s>&#34;op.convert&#34;</span><span class=p>(</span><span class=nv>%a</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>i64</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>i64</span>
  br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%a</span><span class=p>:</span> <span class=k>i64</span><span class=p>)</span>    <span class=c>// Branch passes %a as the argument
</span><span class=c></span>
<span class=nl>^bb2</span><span class=p>:</span>
  <span class=s>&#34;accelerator.launch&#34;</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
    <span class=nl>^bb0</span><span class=p>:</span>
      <span class=c>// Region of code nested under &#34;accelerator.launch&#34;, it can reference %a but
</span><span class=c></span>      <span class=c>// not %value.
</span><span class=c></span>      <span class=nv>%new_value</span> <span class=p>=</span> <span class=s>&#34;accelerator.do_something&#34;</span><span class=p>(</span><span class=nv>%a</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>i64</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
  <span class=p>}</span>
  <span class=c>// %new_value cannot be referenced outside of the region
</span><span class=c></span>
<span class=nl>^bb3</span><span class=p>:</span>
  <span class=p>.</span><span class=p>.</span><span class=p>.</span>
<span class=p>}</span>
</code></pre></div><p>This can be further restricted using the custom verifier associated with the
enclosing operation, for example, disallowing references to values defined
outside the region completely.</p><h3 id=control-flow>Control Flow&nbsp;<a class=headline-hash href=#control-flow>¶</a></h3><p>Regions are Single-Entry-Multiple-Exit (SEME). This means that control can only
flow into the first block of the region, but can flow out of the region at the
end of any of the contained blocks (This behavior is similar to that of a
function body in most programming languages). A terminator of a block within a
region may transfer the control flow to another block in this region, or return
it to the immediately enclosing op. The semantics of the enclosing op defines
where the control flow is transmitted next. It may, for example, enter a region
of the same op, including the same region that returned the control flow.</p><p>The enclosing operation determines the way in which control is transmitted into
the entry block of a Region. The successor to a region’s exit points may not
necessarily exist: for example a call to a function that does not return.
Concurrent or asynchronous execution of regions is unspecified. Operations may
define specific rules of execution, e.g. sequential loops or switch cases.</p><p>A Region may also enter another region within the enclosing operation. If an
operation has multiple regions, the semantics of the operation defines into
which regions the control flows and in which order, if any. An operation may
transmit control into regions that were specified in other operations, in
particular those that defined the values the given operation uses. Thus such
operations can be treated opaquely in the enclosing control flow graph,
providing a level of control flow isolation similar to that of the call
operation.</p><h4 id=closure>Closure&nbsp;<a class=headline-hash href=#closure>¶</a></h4><p>Regions allow defining an operation that creates a closure, for example by
“boxing” the body of the region into a value they produce. It remains up to the
operation to define its semantics. Note that if an operation triggers
asynchronous execution of the region, it is under the responsibility of the
operation caller to wait for the region to be executed guaranteeing that any
directly used values remain live.</p><h3 id=arguments-and-results>Arguments and Results&nbsp;<a class=headline-hash href=#arguments-and-results>¶</a></h3><p>The arguments of the first block of a region are treated as arguments of the
region. The source of these arguments is defined by the semantics of the parent
operation. They may correspond to some of the values the operation itself uses.</p><p>Regions produce a (possibly empty) list of values. The operation semantics
defines the relation between the region results and the operation results.</p><h2 id=type-system>Type System&nbsp;<a class=headline-hash href=#type-system>¶</a></h2><p>Each SSA value in MLIR has a type defined by the type system below. There are a
number of primitive types (like integers) and also aggregate types for tensors
and memory buffers. MLIR
<a href=#standard-types>standard types</a>
do not include
structures, arrays, or dictionaries.</p><p>MLIR has an open type system (i.e. there is no fixed list of types), and types
may have application-specific semantics. For example, MLIR supports a set of
<a href=#dialect-types>dialect types</a>
.</p><pre><code>type ::= type-alias | dialect-type | standard-type

type-list-no-parens ::=  type (`,` type)*
type-list-parens ::= `(` `)`
                   | `(` type-list-no-parens `)`

// This is a common way to refer to an SSA value with a specified type.
ssa-use-and-type ::= ssa-use `:` type

// Non-empty list of names and types.
ssa-use-and-type-list ::= ssa-use-and-type (`,` ssa-use-and-type)*
</code></pre><h3 id=type-aliases>Type Aliases&nbsp;<a class=headline-hash href=#type-aliases>¶</a></h3><pre><code>type-alias-def ::= '!' alias-name '=' 'type' type
type-alias ::= '!' alias-name
</code></pre><p>MLIR supports defining named aliases for types. A type alias is an identifier
that can be used in the place of the type that it defines. These aliases <em>must</em>
be defined before their uses. Alias names may not contain a &lsquo;.', since those
names are reserved for
<a href=#dialect-types>dialect types</a>
.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=p>!</span><span class=nl>avx_m128 =</span> type <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4 x</span> <span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Using the original type.
</span><span class=c></span><span class=s>&#34;foo&#34;</span><span class=p>(</span><span class=nv>%x</span><span class=p>)</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4 x</span> <span class=k>f32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>

<span class=c>// Using the type alias.
</span><span class=c></span><span class=s>&#34;foo&#34;</span><span class=p>(</span><span class=nv>%x</span><span class=p>)</span> <span class=p>:</span> <span class=p>!</span>avx_m128 <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
</code></pre></div><h3 id=dialect-types>Dialect Types&nbsp;<a class=headline-hash href=#dialect-types>¶</a></h3><p>Similarly to operations, dialects may define custom extensions to the type
system.</p><pre><code>dialect-namespace ::= bare-id

opaque-dialect-item ::= dialect-namespace '&lt;' string-literal '&gt;'

pretty-dialect-item ::= dialect-namespace '.' pretty-dialect-item-lead-ident
                                              pretty-dialect-item-body?

pretty-dialect-item-lead-ident ::= '[A-Za-z][A-Za-z0-9._]*'
pretty-dialect-item-body ::= '&lt;' pretty-dialect-item-contents+ '&gt;'
pretty-dialect-item-contents ::= pretty-dialect-item-body
                              | '(' pretty-dialect-item-contents+ ')'
                              | '[' pretty-dialect-item-contents+ ']'
                              | '{' pretty-dialect-item-contents+ '}'
                              | '[^[&lt;({&gt;\])}\0]+'

dialect-type ::= '!' opaque-dialect-item
dialect-type ::= '!' pretty-dialect-item
</code></pre><p>Dialect types can be specified in a verbose form, e.g. like this:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// LLVM type that wraps around llvm IR types.
</span><span class=c></span><span class=p>!</span>llvm<span class=p>&lt;</span><span class=s>&#34;i32*&#34;</span><span class=p>&gt;</span>

<span class=c>// Tensor flow string type.
</span><span class=c></span><span class=p>!</span>tf<span class=p>.</span>string

<span class=c>// Complex type
</span><span class=c></span><span class=p>!</span>foo<span class=p>&lt;</span><span class=s>&#34;something&lt;abcd&gt;&#34;</span><span class=p>&gt;</span>

<span class=c>// Even more complex type
</span><span class=c></span><span class=p>!</span>foo<span class=p>&lt;</span><span class=s>&#34;something&lt;a%%123^^^&gt;&gt;&gt;&#34;</span><span class=p>&gt;</span>
</code></pre></div><p>Dialect types that are simple enough can use the pretty format, which is a
lighter weight syntax that is equivalent to the above forms:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Tensor flow string type.
</span><span class=c></span><span class=p>!</span>tf<span class=p>.</span>string

<span class=c>// Complex type
</span><span class=c></span><span class=p>!</span>foo<span class=p>.</span>something<span class=p>&lt;</span>abcd<span class=p>&gt;</span>
</code></pre></div><p>Sufficiently complex dialect types are required to use the verbose form for
generality. For example, the more complex type shown above wouldn&rsquo;t be valid in
the lighter syntax: <code>!foo.something&lt;a%%123^^^>>></code> because it contains characters
that are not allowed in the lighter syntax, as well as unbalanced <code>&lt;></code>
characters.</p><p>See
<a href=/docs/Tutorials/DefiningAttributesAndTypes/>here</a>
to learn how to define dialect types.</p><h3 id=standard-types>Standard Types&nbsp;<a class=headline-hash href=#standard-types>¶</a></h3><p>Standard types are a core set of
<a href=#dialect-types>dialect types</a>
that are
defined in a builtin dialect and thus available to all users of MLIR.</p><pre><code>standard-type ::=     complex-type
                    | float-type
                    | function-type
                    | index-type
                    | integer-type
                    | memref-type
                    | none-type
                    | tensor-type
                    | tuple-type
                    | vector-type
</code></pre><h4 id=complex-type>Complex Type&nbsp;<a class=headline-hash href=#complex-type>¶</a></h4><p>Syntax:</p><pre><code>complex-type ::= `complex` `&lt;` type `&gt;`
</code></pre><p>The value of <code>complex</code> type represents a complex number with a parameterized
element type, which is composed of a real and imaginary value of that element
type. The element must be a floating point or integer scalar type.</p><p>Examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>complex<span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>
complex<span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span>
</code></pre></div><h4 id=floating-point-types>Floating Point Types&nbsp;<a class=headline-hash href=#floating-point-types>¶</a></h4><p>Syntax:</p><pre><code>// Floating point.
float-type ::= `f16` | `bf16` | `f32` | `f64`
</code></pre><p>MLIR supports float types of certain widths that are widely used as indicated
above.</p><h4 id=function-type>Function Type&nbsp;<a class=headline-hash href=#function-type>¶</a></h4><p>Syntax:</p><pre><code>// MLIR functions can return multiple values.
function-result-type ::= type-list-parens
                       | non-function-type

function-type ::= type-list-parens `-&gt;` function-result-type
</code></pre><p>MLIR supports first-class functions: for example, the
<a href=/docs/Dialects/Standard/#constant-operation><code>constant</code> operation</a>
produces the
address of a function as an SSA value. This SSA value may be passed to and
returned from functions, merged across control flow boundaries with
<a href=#blocks>block arguments</a>
, and called with the
<a href=/docs/Dialects/Standard/#call-indirect-operation><code>call_indirect</code> operation</a>
.</p><p>Function types are also used to indicate the arguments and results of
<a href=#operations>operations</a>
.</p><h4 id=index-type>Index Type&nbsp;<a class=headline-hash href=#index-type>¶</a></h4><p>Syntax:</p><pre><code>// Target word-sized integer.
index-type ::= `index`
</code></pre><p>The <code>index</code> type is a signless integer whose size is equal to the natural
machine word of the target (
<a href=/docs/Rationale/Rationale/#signless-types>rationale</a>
) and is
used by the affine constructs in MLIR. Unlike fixed-size integers, it cannot be
used as an element of vector, tensor or memref type
(
<a href=/docs/Rationale/Rationale/#index-type-disallowed-in-vectortensormemref-types>rationale</a>
).</p><p><strong>Rationale:</strong> integers of platform-specific bit widths are practical to express
sizes, dimensionalities and subscripts.</p><h4 id=integer-type>Integer Type&nbsp;<a class=headline-hash href=#integer-type>¶</a></h4><p>Syntax:</p><pre><code>// Sized integers like i1, i4, i8, i16, i32.
signed-integer-type ::= `si` [1-9][0-9]*
unsigned-integer-type ::= `ui` [1-9][0-9]*
signless-integer-type ::= `i` [1-9][0-9]*
integer-type ::= signed-integer-type |
                 unsigned-integer-type |
                 signless-integer-type
</code></pre><p>MLIR supports arbitrary precision integer types. Integer types have a designated
width and may have signedness semantics.</p><p><strong>Rationale:</strong> low precision integers (like <code>i2</code>, <code>i4</code> etc) are useful for
low-precision inference chips, and arbitrary precision integers are useful for
hardware synthesis (where a 13 bit multiplier is a lot cheaper/smaller than a 16
bit one).</p><p>TODO: Need to decide on a representation for quantized integers
(
<a href=/docs/Rationale/Rationale/#quantized-integer-operations>initial thoughts</a>
).</p><h4 id=memref-type>Memref Type&nbsp;<a class=headline-hash href=#memref-type>¶</a></h4><p>Syntax:</p><pre><code>memref-type ::= ranked-memref-type | unranked-memref-type

ranked-memref-type ::= `memref` `&lt;` dimension-list-ranked tensor-memref-element-type
                      (`,` layout-specification)? |
                      (`,` memory-space)? `&gt;`

unranked-memref-type ::= `memref` `&lt;*x` tensor-memref-element-type
                         (`,` memory-space)? `&gt;`

stride-list ::= `[` (dimension (`,` dimension)*)? `]`
strided-layout ::= `offset:` dimension `,` `strides: ` stride-list
layout-specification ::= semi-affine-map | strided-layout
memory-space ::= integer-literal /* | TODO: address-space-id */
</code></pre><p>A <code>memref</code> type is a reference to a region of memory (similar to a buffer
pointer, but more powerful). The buffer pointed to by a memref can be allocated,
aliased and deallocated. A memref can be used to read and write data from/to the
memory region which it references. Memref types use the same shape specifier as
tensor types. Note that <code>memref&lt;f32></code>, <code>memref&lt;0 x f32></code>, <code>memref&lt;1 x 0 x f32></code>,
and <code>memref&lt;0 x 1 x f32></code> are all different types.</p><p>A <code>memref</code> is allowed to have an unknown rank (e.g. <code>memref&lt;*xf32></code>). The
purpose of unranked memrefs is to allow external library functions to receive
memref arguments of any rank without versioning the functions based on the rank.
Other uses of this type are disallowed or will have undefined behavior.</p><h5 id=codegen-of-unranked-memref>Codegen of Unranked Memref&nbsp;<a class=headline-hash href=#codegen-of-unranked-memref>¶</a></h5><p>Using unranked memref in codegen besides the case mentioned above is highly
discouraged. Codegen is concerned with generating loop nests and specialized
instructions for high-performance, unranked memref is concerned with hiding the
rank and thus, the number of enclosing loops required to iterate over the data.
However, if there is a need to code-gen unranked memref, one possible path is to
cast into a static ranked type based on the dynamic rank. Another possible path
is to emit a single while loop conditioned on a linear index and perform
delinearization of the linear index to a dynamic array containing the (unranked)
indices. While this is possible, it is expected to not be a good idea to perform
this during codegen as the cost of the translations is expected to be
prohibitive and optimizations at this level are not expected to be worthwhile.
If expressiveness is the main concern, irrespective of performance, passing
unranked memrefs to an external C++ library and implementing rank-agnostic logic
there is expected to be significantly simpler.</p><p>Unranked memrefs may provide expressiveness gains in the future and help bridge
the gap with unranked tensors. Unranked memrefs will not be expected to be
exposed to codegen but one may query the rank of an unranked memref (a special
op will be needed for this purpose) and perform a switch and cast to a ranked
memref as a prerequisite to codegen.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// With static ranks, we need a function for each possible argument type
</span><span class=c></span><span class=nv>%A</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=nv>%B</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span>
<span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;</span> call <span class=nf>@helper_2D</span><span class=p>(</span><span class=nv>%A</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span><span class=p>-&gt;</span><span class=p>(</span><span class=p>)</span> call
<span class=nf>@helper_3D</span><span class=p>(</span><span class=nv>%B</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span><span class=p>-&gt;</span><span class=p>(</span><span class=p>)</span>

<span class=c>// With unknown rank, the functions can be unified under one unranked type
</span><span class=c></span><span class=nv>%A</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=nv>%B</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=c>// Remove rank info
</span><span class=c></span><span class=nv>%A_u</span> <span class=p>=</span> <span class=kt>memref</span>_cast <span class=nv>%A</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=p>*</span>xf32<span class=p>&gt;</span>
<span class=nv>%B_u</span> <span class=p>=</span> <span class=kt>memref</span>_cast <span class=nv>%B</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=p>*</span>xf32<span class=p>&gt;</span>
<span class=c>// call same function with dynamic ranks
</span><span class=c></span>call <span class=nf>@helper</span><span class=p>(</span><span class=nv>%A_u</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=p>*</span>xf32<span class=p>&gt;</span><span class=p>)</span><span class=p>-&gt;</span><span class=p>(</span><span class=p>)</span>
call <span class=nf>@helper</span><span class=p>(</span><span class=nv>%B_u</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=p>*</span>xf32<span class=p>&gt;</span><span class=p>)</span><span class=p>-&gt;</span><span class=p>(</span><span class=p>)</span>
</code></pre></div><p>The core syntax and representation of a layout specification is a
<a href=/docs/Dialects/Affine/#semi-affine-maps>semi-affine map</a>
. Additionally, syntactic
sugar is supported to make certain layout specifications more intuitive to read.
For the moment, a <code>memref</code> supports parsing a strided form which is converted to
a semi-affine map automatically.</p><p>The memory space of a memref is specified by a target-specific integer index. If
no memory space is specified, then the default memory space (0) is used. The
default space is target specific but always at index 0.</p><p>TODO: MLIR will eventually have target-dialects which allow symbolic use of
memory hierarchy names (e.g. L3, L2, L1, &mldr;) but we have not spec&rsquo;d the details
of that mechanism yet. Until then, this document pretends that it is valid to
refer to these memories by <code>bare-id</code>.</p><p>The notionally dynamic value of a memref value includes the address of the
buffer allocated, as well as the symbols referred to by the shape, layout map,
and index maps.</p><p>Examples of memref static type</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Identity index/layout map
</span><span class=c></span><span class=nv>#identity</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span><span class=p>&gt;</span>

<span class=c>// Column major layout.
</span><span class=c></span><span class=nv>#col_major</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>,</span> d1<span class=p>,</span> d2<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d2<span class=p>,</span> d1<span class=p>,</span> d0<span class=p>)</span><span class=p>&gt;</span>

<span class=c>// A 2-d tiled layout with tiles of size 128 x 256.
</span><span class=c></span><span class=nv>#tiled_2d_128x256</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0 div <span class=m>128</span><span class=p>,</span> d1 div <span class=m>256</span><span class=p>,</span> d0 mod <span class=m>128</span><span class=p>,</span> d1 mod <span class=m>256</span><span class=p>)</span><span class=p>&gt;</span>

<span class=c>// A tiled data layout with non-constant tile sizes.
</span><span class=c></span><span class=nv>#tiled_dynamic</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span><span class=p>[</span>s0<span class=p>,</span> s1<span class=p>]</span> <span class=p>-&gt;</span> <span class=p>(</span>d0 floordiv s0<span class=p>,</span> d1 floordiv s1<span class=p>,</span>
                             d0 mod s0<span class=p>,</span> d1 mod s1<span class=p>)</span><span class=p>&gt;</span>

<span class=c>// A layout that yields a padding on two at either end of the minor dimension.
</span><span class=c></span><span class=nv>#padded</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>,</span> <span class=p>(</span>d1 <span class=err>+</span> <span class=m>2</span><span class=p>)</span> floordiv <span class=m>2</span><span class=p>,</span> <span class=p>(</span>d1 <span class=err>+</span> <span class=m>2</span><span class=p>)</span> mod <span class=m>2</span><span class=p>)</span><span class=p>&gt;</span>


<span class=c>// The dimension list &#34;16x32&#34; defines the following 2D index space:
</span><span class=c></span><span class=c>//
</span><span class=c></span><span class=c>//   { (i, j) : 0 &lt;= i &lt; 16, 0 &lt;= j &lt; 32 }
</span><span class=c></span><span class=c>//
</span><span class=c></span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#identity</span><span class=p>,</span> memspace0<span class=p>&gt;</span>

<span class=c>// The dimension list &#34;16x4x?&#34; defines the following 3D index space:
</span><span class=c></span><span class=c>//
</span><span class=c></span><span class=c>//   { (i, j, k) : 0 &lt;= i &lt; 16, 0 &lt;= j &lt; 4, 0 &lt;= k &lt; N }
</span><span class=c></span><span class=c>//
</span><span class=c></span><span class=c>// where N is a symbol which represents the runtime value of the size of
</span><span class=c></span><span class=c>// the third dimension.
</span><span class=c></span><span class=c>//
</span><span class=c></span><span class=c>// %N here binds to the size of the third dimension.
</span><span class=c></span><span class=nv>%A</span> <span class=p>=</span> alloc<span class=p>(</span><span class=nv>%N</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x4x?x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#col_major</span><span class=p>,</span> memspace0<span class=p>&gt;</span>

<span class=c>// A 2-d dynamic shaped memref that also has a dynamically sized tiled layout.
</span><span class=c></span><span class=c>// The memref index space is of size %M x %N, while %B1 and %B2 bind to the
</span><span class=c></span><span class=c>// symbols s0, s1 respectively of the layout map #tiled_dynamic. Data tiles of
</span><span class=c></span><span class=c>// size %B1 x %B2 in the logical space will be stored contiguously in memory.
</span><span class=c></span><span class=c>// The allocation size will be (%M ceildiv %B1) * %B1 * (%N ceildiv %B2) * %B2
</span><span class=c></span><span class=c>// f32 elements.
</span><span class=c></span><span class=nv>%T</span> <span class=p>=</span> alloc<span class=p>(</span><span class=nv>%M</span><span class=p>,</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>[</span><span class=nv>%B1</span><span class=p>,</span> <span class=nv>%B2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#tiled_dynamic</span><span class=p>&gt;</span>

<span class=c>// A memref that has a two-element padding at either end. The allocation size
</span><span class=c></span><span class=c>// will fit 16 * 64 float elements of data.
</span><span class=c></span><span class=nv>%P</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x64x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#padded</span><span class=p>&gt;</span>

<span class=c>// Affine map with symbol &#39;s0&#39; used as offset for the first dimension.
</span><span class=c></span><span class=nv>#imapS</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span> <span class=p>[</span>s0<span class=p>]</span> <span class=p>-&gt;</span> <span class=p>(</span>d0 <span class=err>+</span> s0<span class=p>,</span> d1<span class=p>)</span><span class=p>&gt;</span>
<span class=c>// Allocate memref and bind the following symbols:
</span><span class=c></span><span class=c>// &#39;%n&#39; is bound to the dynamic second dimension of the memref type.
</span><span class=c></span><span class=c>// &#39;%o&#39; is bound to the symbol &#39;s0&#39; in the affine map of the memref type.
</span><span class=c></span><span class=nv>%n</span> <span class=p>=</span> <span class=p>.</span><span class=p>.</span><span class=p>.</span>
<span class=nv>%o</span> <span class=p>=</span> <span class=p>.</span><span class=p>.</span><span class=p>.</span>
<span class=nv>%A</span> <span class=p>=</span> alloc <span class=p>(</span><span class=nv>%n</span><span class=p>)</span><span class=p>[</span><span class=nv>%o</span><span class=p>]</span> <span class=p>:</span> <span class=p>&lt;</span><span class=m>16x?x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#imapS</span><span class=p>&gt;</span>
</code></pre></div><h5 id=index-space>Index Space&nbsp;<a class=headline-hash href=#index-space>¶</a></h5><p>A memref dimension list defines an index space within which the memref can be
indexed to access data.</p><h5 id=index>Index&nbsp;<a class=headline-hash href=#index>¶</a></h5><p>Data is accessed through a memref type using a multidimensional index into the
multidimensional index space defined by the memref&rsquo;s dimension list.</p><p>Examples</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Allocates a memref with 2D index space:
</span><span class=c></span><span class=c>//   { (i, j) : 0 &lt;= i &lt; 16, 0 &lt;= j &lt; 32 }
</span><span class=c></span><span class=nv>%A</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#imapA</span><span class=p>,</span> memspace0<span class=p>&gt;</span>

<span class=c>// Loads data from memref &#39;%A&#39; using a 2D index: (%i, %j)
</span><span class=c></span><span class=nv>%v</span> <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x32x</span><span class=k>f32</span><span class=p>,</span> <span class=nv>#imapA</span><span class=p>,</span> memspace0<span class=p>&gt;</span>
</code></pre></div><h5 id=index-map>Index Map&nbsp;<a class=headline-hash href=#index-map>¶</a></h5><p>An index map is a one-to-one
<a href=/docs/Dialects/Affine/#semi-affine-maps>semi-affine map</a>
that transforms a
multidimensional index from one index space to another. For example, the
following figure shows an index map which maps a 2-dimensional index from a 2x2
index space to a 3x3 index space, using symbols <code>S0</code> and <code>S1</code> as offsets.</p><p><img src=/includes/img/index-map.svg alt="Index Map Example"></p><p>The number of domain dimensions and range dimensions of an index map can be
different, but must match the number of dimensions of the input and output index
spaces on which the map operates. The index space is always non-negative and
integral. In addition, an index map must specify the size of each of its range
dimensions onto which it maps. Index map symbols must be listed in order with
symbols for dynamic dimension sizes first, followed by other required symbols.</p><h5 id=layout-map>Layout Map&nbsp;<a class=headline-hash href=#layout-map>¶</a></h5><p>A layout map is a
<a href=/docs/Dialects/Affine/#semi-affine-maps>semi-affine map</a>
which
encodes logical to physical index space mapping, by mapping input dimensions to
their ordering from most-major (slowest varying) to most-minor (fastest
varying). Therefore, an identity layout map corresponds to a row-major layout.
Identity layout maps do not contribute to the MemRef type identification and are
discarded on construction. That is, a type with an explicit identity map is
<code>memref&lt;?x?xf32, (i,j)->(i,j)></code> is strictly the same as the one without layout
maps, <code>memref&lt;?x?xf32></code>.</p><p>Layout map examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// MxN matrix stored in row major layout in memory:
</span><span class=c></span><span class=nv>#layout_map_row_major</span> <span class=p>=</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span>

<span class=c>// MxN matrix stored in column major layout in memory:
</span><span class=c></span><span class=nv>#layout_map_col_major</span> <span class=p>=</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>j<span class=p>,</span> i<span class=p>)</span>

<span class=c>// MxN matrix stored in a 2-d blocked/tiled layout with 64x64 tiles.
</span><span class=c></span><span class=nv>#layout_tiled</span> <span class=p>=</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i floordiv <span class=m>64</span><span class=p>,</span> j floordiv <span class=m>64</span><span class=p>,</span> i mod <span class=m>64</span><span class=p>,</span> j mod <span class=m>64</span><span class=p>)</span>
</code></pre></div><h5 id=affine-map-composition>Affine Map Composition&nbsp;<a class=headline-hash href=#affine-map-composition>¶</a></h5><p>A memref specifies a semi-affine map composition as part of its type. A
semi-affine map composition is a composition of semi-affine maps beginning with
zero or more index maps, and ending with a layout map. The composition must be
conformant: the number of dimensions of the range of one map, must match the
number of dimensions of the domain of the next map in the composition.</p><p>The semi-affine map composition specified in the memref type, maps from accesses
used to index the memref in load/store operations to other index spaces (i.e.
logical to physical index mapping). Each of the
<a href=/docs/Dialects/Affine/>semi-affine maps</a>
and thus its composition is required to
be one-to-one.</p><p>The semi-affine map composition can be used in dependence analysis, memory
access pattern analysis, and for performance optimizations like vectorization,
copy elision and in-place updates. If an affine map composition is not specified
for the memref, the identity affine map is assumed.</p><h5 id=strided-memref>Strided MemRef&nbsp;<a class=headline-hash href=#strided-memref>¶</a></h5><p>A memref may specify strides as part of its type. A stride specification is a
list of integer values that are either static or <code>?</code> (dynamic case). Strides
encode the distance, in number of elements, in (linear) memory between
successive entries along a particular dimension. A stride specification is
syntactic sugar for an equivalent strided memref representation using
semi-affine maps. For example, <code>memref&lt;42x16xf32, offset: 33 strides: [1, 64]></code>
specifies a non-contiguous memory region of <code>42</code> by <code>16</code> <code>f32</code> elements such
that:</p><ol><li>the minimal size of the enclosing memory region must be <code>33 + 42 * 1 + 16 * 64 = 1066</code> elements;</li><li>the address calculation for accessing element <code>(i, j)</code> computes <code>33 + i + 64 * j</code></li><li>the distance between two consecutive elements along the outer dimension is
<code>1</code> element and the distance between two consecutive elements along the
outer dimension is <code>64</code> elements.</li></ol><p>This corresponds to a column major view of the memory region and is internally
represented as the type <code>memref&lt;42x16xf32, (i, j) -> (33 + i + 64 * j)></code>.</p><p>The specification of strides must not alias: given an n-D strided memref,
indices <code>(i1, ..., in)</code> and <code>(j1, ..., jn)</code> may not refer to the same memory
address unless <code>i1 == j1, ..., in == jn</code>.</p><p>Strided memrefs represent a view abstraction over preallocated data. They are
constructed with special ops, yet to be introduced. Strided memrefs are a
special subclass of memrefs with generic semi-affine map and correspond to a
normalized memref descriptor when lowering to LLVM.</p><h4 id=none-type>None Type&nbsp;<a class=headline-hash href=#none-type>¶</a></h4><p>Syntax:</p><pre><code>none-type ::= `none`
</code></pre><p>The <code>none</code> type is a unit type, i.e. a type with exactly one possible value,
where its value does not have a defined dynamic representation.</p><h4 id=tensor-type>Tensor Type&nbsp;<a class=headline-hash href=#tensor-type>¶</a></h4><p>Syntax:</p><pre><code>tensor-type ::= `tensor` `&lt;` dimension-list tensor-memref-element-type `&gt;`
tensor-memref-element-type ::= vector-element-type | vector-type | complex-type

// memref requires a known rank, but tensor does not.
dimension-list ::= dimension-list-ranked | (`*` `x`)
dimension-list-ranked ::= (dimension `x`)*
dimension ::= `?` | decimal-literal
</code></pre><p>SSA values of tensor type represents aggregate N-dimensional data values, and
have a known element type. It may have an unknown rank (indicated by <code>*</code>) or may
have a fixed rank with a list of dimensions. Each dimension may be a static
non-negative decimal constant or be dynamically determined (indicated by <code>?</code>).</p><p>The runtime representation of the MLIR tensor type is intentionally abstracted -
you cannot control layout or get a pointer to the data. For low level buffer
access, MLIR has a
<a href=#memref-type><code>memref</code> type</a>
. This abstracted runtime
representation holds both the tensor data values as well as information about
the (potentially dynamic) shape of the tensor. The
<a href=/docs/Dialects/Standard/#dim-operation><code>dim</code> operation</a>
returns the size of a
dimension from a value of tensor type.</p><p>Note: hexadecimal integer literals are not allowed in tensor type declarations
to avoid confusion between <code>0xf32</code> and <code>0 x f32</code>. Zero sizes are allowed in
tensors and treated as other sizes, e.g., <code>tensor&lt;0 x 1 x i32></code> and <code>tensor&lt;1 x 0 x i32></code> are different types. Since zero sizes are not allowed in some other
types, such tensors should be optimized away before lowering tensors to vectors.</p><p>Examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Tensor with unknown rank.
</span><span class=c></span><span class=kt>tensor</span><span class=p>&lt;</span><span class=p>*</span> <span class=p>x</span> <span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Known rank but unknown dimensions.
</span><span class=c></span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>? x</span> <span class=m>? x</span> <span class=m>? x</span> <span class=m>? x</span> <span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Partially known dimensions.
</span><span class=c></span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>? x</span> <span class=m>? x</span> <span class=m>13 x</span> <span class=m>? x</span> <span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Full static shape.
</span><span class=c></span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>17 x</span> <span class=m>4 x</span> <span class=m>13 x</span> <span class=m>4 x</span> <span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Tensor with rank zero. Represents a scalar.
</span><span class=c></span><span class=kt>tensor</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Zero-element dimensions are allowed.
</span><span class=c></span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>0</span> <span class=p>x</span> <span class=m>42 x</span> <span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Zero-element tensor of f32 type (hexadecimal literals not allowed here).
</span><span class=c></span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>0xf32</span><span class=p>&gt;</span>
</code></pre></div><h4 id=tuple-type>Tuple Type&nbsp;<a class=headline-hash href=#tuple-type>¶</a></h4><p>Syntax:</p><pre><code>tuple-type ::= `tuple` `&lt;` (type ( `,` type)*)? `&gt;`
</code></pre><p>The value of <code>tuple</code> type represents a fixed-size collection of elements, where
each element may be of a different type.</p><p><strong>Rationale:</strong> Though this type is first class in the type system, MLIR provides
no standard operations for operating on <code>tuple</code> types
(
<a href=/docs/Rationale/Rationale/#tuple-types>rationale</a>
).</p><p>Examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Empty tuple.
</span><span class=c></span>tuple<span class=p>&lt;</span><span class=p>&gt;</span>

<span class=c>// Single element
</span><span class=c></span>tuple<span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>

<span class=c>// Many elements.
</span><span class=c></span>tuple<span class=p>&lt;</span><span class=k>i32</span><span class=p>,</span> <span class=k>f32</span><span class=p>,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=k>i1</span><span class=p>&gt;</span><span class=p>,</span> <span class=k>i5</span><span class=p>&gt;</span>
</code></pre></div><h4 id=vector-type>Vector Type&nbsp;<a class=headline-hash href=#vector-type>¶</a></h4><p>Syntax:</p><pre><code>vector-type ::= `vector` `&lt;` static-dimension-list vector-element-type `&gt;`
vector-element-type ::= float-type | integer-type

static-dimension-list ::= (decimal-literal `x`)+
</code></pre><p>The vector type represents a SIMD style vector, used by target-specific
operation sets like AVX. While the most common use is for 1D vectors (e.g.
vector&lt;16 x f32>) we also support multidimensional registers on targets that
support them (like TPUs).</p><p>Vector shapes must be positive decimal integers.</p><p>Note: hexadecimal integer literals are not allowed in vector type declarations,
<code>vector&lt;0x42xi32></code> is invalid because it is interpreted as a 2D vector with
shape <code>(0, 42)</code> and zero shapes are not allowed.</p><h2 id=attributes>Attributes&nbsp;<a class=headline-hash href=#attributes>¶</a></h2><p>Syntax:</p><pre><code>attribute-dict ::= `{` `}`
                 | `{` attribute-entry (`,` attribute-entry)* `}`
attribute-entry ::= dialect-attribute-entry | dependent-attribute-entry
dialect-attribute-entry ::= dialect-namespace `.` bare-id `=` attribute-value
dependent-attribute-entry ::= dependent-attribute-name `=` attribute-value
dependent-attribute-name ::= ((letter|[_]) (letter|digit|[_$])*)
                           | string-literal
</code></pre><p>Attributes are the mechanism for specifying constant data on operations in
places where a variable is never allowed - e.g. the index of a
<a href=/docs/Dialects/Standard/#dim-operation><code>dim</code> operation</a>
, or the stride of a
convolution. They consist of a name and a concrete attribute value. The set of
expected attributes, their structure, and their interpretation are all
contextually dependent on what they are attached to.</p><p>There are two main classes of attributes: dependent and dialect. Dependent
attributes derive their structure and meaning from what they are attached to;
e.g., the meaning of the <code>index</code> attribute on a <code>dim</code> operation is defined by
the <code>dim</code> operation. Dialect attributes, on the other hand, derive their context
and meaning from a specific dialect. An example of a dialect attribute may be a
<code>swift.self</code> function argument attribute that indicates an argument is the
self/context parameter. The context of this attribute is defined by the <code>swift</code>
dialect and not the function argument.</p><p>Attribute values are represented by the following forms:</p><pre><code>attribute-value ::= attribute-alias | dialect-attribute | standard-attribute
</code></pre><h3 id=attribute-value-aliases>Attribute Value Aliases&nbsp;<a class=headline-hash href=#attribute-value-aliases>¶</a></h3><pre><code>attribute-alias ::= '#' alias-name '=' attribute-value
attribute-alias ::= '#' alias-name
</code></pre><p>MLIR supports defining named aliases for attribute values. An attribute alias is
an identifier that can be used in the place of the attribute that it defines.
These aliases <em>must</em> be defined before their uses. Alias names may not contain a
&lsquo;.', since those names are reserved for
<a href=#dialect-attribute-values>dialect attributes</a>
.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#map</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0 <span class=err>+</span> <span class=m>10</span><span class=p>)</span><span class=p>&gt;</span>

<span class=c>// Using the original attribute.
</span><span class=c></span><span class=nv>%b</span> <span class=p>=</span> affine<span class=p>.</span>apply affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0 <span class=err>+</span> <span class=m>10</span><span class=p>)</span><span class=p>&gt;</span> <span class=p>(</span><span class=nv>%a</span><span class=p>)</span>

<span class=c>// Using the attribute alias.
</span><span class=c></span><span class=nv>%b</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map</span><span class=p>(</span><span class=nv>%a</span><span class=p>)</span>
</code></pre></div><h3 id=dialect-attribute-values>Dialect Attribute Values&nbsp;<a class=headline-hash href=#dialect-attribute-values>¶</a></h3><p>Similarly to operations, dialects may define custom attribute values. The
syntactic structure of these values is identical to custom dialect type values,
except that dialect attributes values are distinguished with a leading &lsquo;#',
while dialect types are distinguished with a leading &lsquo;!'.</p><pre><code>dialect-attribute ::= '#' opaque-dialect-item
dialect-attribute ::= '#' pretty-dialect-item
</code></pre><p>Dialect attributes can be specified in a verbose form, e.g. like this:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Complex attribute
</span><span class=c></span><span class=nv>#foo</span><span class=p>&lt;</span><span class=s>&#34;something&lt;abcd&gt;&#34;</span><span class=p>&gt;</span>

<span class=c>// Even more complex attribute
</span><span class=c></span><span class=nv>#foo</span><span class=p>&lt;</span><span class=s>&#34;something&lt;a%%123^^^&gt;&gt;&gt;&#34;</span><span class=p>&gt;</span>
</code></pre></div><p>Dialect attributes that are simple enough can use the pretty format, which is a
lighter weight syntax that is equivalent to the above forms:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// Complex attribute
</span><span class=c></span><span class=nv>#foo.something</span><span class=p>&lt;</span>abcd<span class=p>&gt;</span>
</code></pre></div><p>Sufficiently complex dialect attributes are required to use the verbose form for
generality. For example, the more complex type shown above wouldn&rsquo;t be valid in
the lighter syntax: <code>#foo.something&lt;a%%123^^^>>></code> because it contains characters
that are not allowed in the lighter syntax, as well as unbalanced <code>&lt;></code>
characters.</p><p>See
<a href=/docs/Tutorials/DefiningAttributesAndTypes/>here</a>
to learn how to define dialect
attribute values.</p><h3 id=standard-attribute-values>Standard Attribute Values&nbsp;<a class=headline-hash href=#standard-attribute-values>¶</a></h3><p>Standard attributes are a core set of
<a href=#dialect-attribute-values>dialect attributes</a>
that are defined in a builtin
dialect and thus available to all users of MLIR.</p><pre><code>standard-attribute ::=   affine-map-attribute
                       | array-attribute
                       | bool-attribute
                       | dictionary-attribute
                       | elements-attribute
                       | float-attribute
                       | integer-attribute
                       | integer-set-attribute
                       | string-attribute
                       | symbol-ref-attribute
                       | type-attribute
                       | unit-attribute
</code></pre><h4 id=affinemap-attribute>AffineMap Attribute&nbsp;<a class=headline-hash href=#affinemap-attribute>¶</a></h4><p>Syntax:</p><pre><code>affine-map-attribute ::= `affine_map` `&lt;` affine-map `&gt;`
</code></pre><p>An affine-map attribute is an attribute that represents an affine-map object.</p><h4 id=array-attribute>Array Attribute&nbsp;<a class=headline-hash href=#array-attribute>¶</a></h4><p>Syntax:</p><pre><code>array-attribute ::= `[` (attribute-value (`,` attribute-value)*)? `]`
</code></pre><p>An array attribute is an attribute that represents a collection of attribute
values.</p><h4 id=boolean-attribute>Boolean Attribute&nbsp;<a class=headline-hash href=#boolean-attribute>¶</a></h4><p>Syntax:</p><pre><code>bool-attribute ::= bool-literal
</code></pre><p>A boolean attribute is a literal attribute that represents a one-bit boolean
value, true or false.</p><h4 id=dictionary-attribute>Dictionary Attribute&nbsp;<a class=headline-hash href=#dictionary-attribute>¶</a></h4><p>Syntax:</p><pre><code>dictionary-attribute ::= `{` (attribute-entry (`,` attribute-entry)*)? `}`
</code></pre><p>A dictionary attribute is an attribute that represents a sorted collection of
named attribute values. The elements are sorted by name, and each name must be
unique within the collection.</p><h4 id=elements-attributes>Elements Attributes&nbsp;<a class=headline-hash href=#elements-attributes>¶</a></h4><p>Syntax:</p><pre><code>elements-attribute ::= dense-elements-attribute
                     | opaque-elements-attribute
                     | sparse-elements-attribute
</code></pre><p>An elements attribute is a literal attribute that represents a constant
<a href=#vector-type>vector</a>
or
<a href=#tensor-type>tensor</a>
value.</p><h5 id=dense-elements-attribute>Dense Elements Attribute&nbsp;<a class=headline-hash href=#dense-elements-attribute>¶</a></h5><p>Syntax:</p><pre><code>dense-elements-attribute ::= `dense` `&lt;` attribute-value `&gt;` `:`
                             ( tensor-type | vector-type )
</code></pre><p>A dense elements attribute is an elements attribute where the storage for the
constant vector or tensor value has been packed to the element bitwidth. The
element type of the vector or tensor constant must be of integer, index, or
floating point type.</p><h5 id=opaque-elements-attribute>Opaque Elements Attribute&nbsp;<a class=headline-hash href=#opaque-elements-attribute>¶</a></h5><p>Syntax:</p><pre><code>opaque-elements-attribute ::= `opaque` `&lt;` dialect-namespace  `,`
                              hex-string-literal `&gt;` `:`
                              ( tensor-type | vector-type )
</code></pre><p>An opaque elements attribute is an elements attribute where the content of the
value is opaque. The representation of the constant stored by this elements
attribute is only understood, and thus decodable, by the dialect that created
it.</p><p>Note: The parsed string literal must be in hexadecimal form.</p><h5 id=sparse-elements-attribute>Sparse Elements Attribute&nbsp;<a class=headline-hash href=#sparse-elements-attribute>¶</a></h5><p>Syntax:</p><pre><code>sparse-elements-attribute ::= `sparse` `&lt;` attribute-value `,` attribute-value
                              `&gt;` `:` ( tensor-type | vector-type )
</code></pre><p>A sparse elements attribute is an elements attribute that represents a sparse
vector or tensor object. This is where very few of the elements are non-zero.</p><p>The attribute uses COO (coordinate list) encoding to represent the sparse
elements of the elements attribute. The indices are stored via a 2-D tensor of
64-bit integer elements with shape [N, ndims], which specifies the indices of
the elements in the sparse tensor that contains non-zero values. The element
values are stored via a 1-D tensor with shape [N], that supplies the
corresponding values for the indices.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  sparse<span class=p>&lt;</span><span class=p>[</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span><span class=p>,</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span><span class=p>]</span><span class=p>,</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>5</span><span class=p>]</span><span class=p>&gt;</span> <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>3x4x</span><span class=k>i32</span><span class=p>&gt;</span>

<span class=c>// This represents the following tensor:
</span><span class=c></span><span class=c>///  [[1, 0, 0, 0],
</span><span class=c></span><span class=c>///   [0, 0, 5, 0],
</span><span class=c></span><span class=c>///   [0, 0, 0, 0]]
</span></code></pre></div><h4 id=float-attribute>Float Attribute&nbsp;<a class=headline-hash href=#float-attribute>¶</a></h4><p>Syntax:</p><pre><code>float-attribute ::= (float-literal (`:` float-type)?)
                  | (hexadecimal-literal `:` float-type)
</code></pre><p>A float attribute is a literal attribute that represents a floating point value
of the specified
<a href=#floating-point-types>float type</a>
. It can be represented in
the hexadecimal form where the hexadecimal value is interpreted as bits of the
underlying binary representation. This form is useful for representing infinity
and NaN floating point values. To avoid confusion with integer attributes,
hexadecimal literals <em>must</em> be followed by a float type to define a float
attribute.</p><p>Examples:</p><pre><code>42.0         // float attribute defaults to f64 type
42.0 : f32   // float attribute of f32 type
0x7C00 : f16 // positive infinity
0x7CFF : f16 // NaN (one of possible values)
42 : f32     // Error: expected integer type
</code></pre><h4 id=integer-attribute>Integer Attribute&nbsp;<a class=headline-hash href=#integer-attribute>¶</a></h4><p>Syntax:</p><pre><code>integer-attribute ::= integer-literal ( `:` (index-type | integer-type) )?
</code></pre><p>An integer attribute is a literal attribute that represents an integral value of
the specified integer or index type. The default type for this attribute, if one
is not specified, is a 64-bit integer.</p><h5 id=integer-set-attribute>Integer Set Attribute&nbsp;<a class=headline-hash href=#integer-set-attribute>¶</a></h5><p>Syntax:</p><pre><code>integer-set-attribute ::= `affine_set` `&lt;` integer-set `&gt;`
</code></pre><p>An integer-set attribute is an attribute that represents an integer-set object.</p><h4 id=string-attribute>String Attribute&nbsp;<a class=headline-hash href=#string-attribute>¶</a></h4><p>Syntax:</p><pre><code>string-attribute ::= string-literal (`:` type)?
</code></pre><p>A string attribute is an attribute that represents a string literal value.</p><h4 id=symbol-reference-attribute>Symbol Reference Attribute&nbsp;<a class=headline-hash href=#symbol-reference-attribute>¶</a></h4><p>Syntax:</p><pre><code>symbol-ref-attribute ::= symbol-ref-id (`::` symbol-ref-id)*
</code></pre><p>A symbol reference attribute is a literal attribute that represents a named
reference to an operation that is nested within an operation with the
<code>OpTrait::SymbolTable</code> trait. As such, this reference is given meaning by the
nearest parent operation containing the <code>OpTrait::SymbolTable</code> trait. It may
optionally contain a set of nested references that further resolve to a symbol
nested within a different symbol table.</p><p>This attribute can only be held internally by
<a href=#array-attribute>array attributes</a>
and
<a href=#dictionary-attribute>dictionary attributes</a>
(including the top-level operation
attribute dictionary), i.e. no other attribute kinds such as Locations or
extended attribute kinds.</p><p><strong>Rationale:</strong> Given that MLIR models global accesses with symbol references, to
enable efficient multi-threading, it becomes difficult to effectively reason
about their uses. By restricting the places that can legally hold a symbol
reference, we can always opaquely reason about a symbols usage characteristics.</p><p>See
<a href=/docs/SymbolsAndSymbolTables/><code>Symbols And SymbolTables</code></a>
for more
information.</p><h4 id=type-attribute>Type Attribute&nbsp;<a class=headline-hash href=#type-attribute>¶</a></h4><p>Syntax:</p><pre><code>type-attribute ::= type
</code></pre><p>A type attribute is an attribute that represents a
<a href=#type-system>type object</a>
.</p><h4 id=unit-attribute>Unit Attribute&nbsp;<a class=headline-hash href=#unit-attribute>¶</a></h4><pre><code>unit-attribute ::= `unit`
</code></pre><p>A unit attribute is an attribute that represents a value of <code>unit</code> type. The
<code>unit</code> type allows only one value forming a singleton set. This attribute value
is used to represent attributes that only have meaning from their existence.</p><p>One example of such an attribute could be the <code>swift.self</code> attribute. This
attribute indicates that a function parameter is the self/context parameter. It
could be represented as a
<a href=#boolean-attribute>boolean attribute</a>
(true or
false), but a value of false doesn&rsquo;t really bring any value. The parameter
either is the self/context or it isn&rsquo;t.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// A unit attribute defined with the `unit` value specifier.
</span><span class=c></span><span class=kt>func</span> <span class=nf>@verbose_form</span><span class=p>(</span><span class=k>i1</span><span class=p>)</span> attributes <span class=p>{</span><span class=nl>dialectName.unitAttr =</span> unit<span class=p>}</span>

<span class=c>// A unit attribute can also be defined without the value specifier.
</span><span class=c></span><span class=kt>func</span> <span class=nf>@simple_form</span><span class=p>(</span><span class=k>i1</span><span class=p>)</span> attributes <span class=p>{</span>dialectName<span class=p>.</span>unitAttr<span class=p>}</span>
</code></pre></div><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/Interfaces/ title=Interfaces><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Interfaces</a>
<a class="nav nav-next" href=/docs/Canonicalization/ title="Operation Canonicalization">Next - Operation Canonicalization <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=/docs/Dialects/Linalg/>'linalg' Dialect</a></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/LoopDialect/>'loop' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li><a href=/docs/Dialects/Standard/>'std' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li></ul></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'Const' in MLIR, for core IR types</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Tutorial Introduction</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/DefiningAttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li></ul></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li><a href=/docs/GenericDAGRewriter/>Generic DAG Rewriter Infrastructure</a></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li class=active><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/Traits/>Operation Traits</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/OpDefinitions/>Table-driven Operation Definition Specification (ODS)</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>