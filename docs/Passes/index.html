<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Passes - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.64.1"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Passes/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/master/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/master/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li></ul></nav></div><div class=content-container><main><h1>Passes</h1><p>This document describes the available MLIR passes and their contracts.</p><p><nav id=TableOfContents><ul><li><a href=#general-transformation-passes>General Transformation Passes</a><ul><li><a href=#-affine-loop-fusion-fuse-affine-loop-nests>-affine-loop-fusion: Fuse affine loop nests</a></li><li><a href=#-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy>-affine-pipeline-data-transfer: Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy</a></li><li><a href=#-canonicalize-canonicalize-operations>-canonicalize: Canonicalize operations</a></li><li><a href=#-cse-eliminate-common-sub-expressions>-cse: Eliminate common sub-expressions</a></li><li><a href=#-inline-inline-function-calls>-inline: Inline function calls</a></li><li><a href=#-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop>-loop-coalescing: Coalesce nested loops with independent bounds into a single loop</a></li><li><a href=#-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop>-loop-invariant-code-motion: Hoist loop invariant instructions outside of the loop</a></li><li><a href=#-memref-dataflow-opt-perform-storeload-forwarding-for-memrefs>-memref-dataflow-opt: Perform store/load forwarding for memrefs</a></li><li><a href=#-parallel-loop-collapsing-collapse-parallel-loops-to-use-less-induction-variables>-parallel-loop-collapsing: Collapse parallel loops to use less induction variables</a></li><li><a href=#-print-cfg-graph-print-cfg-graph-per-region>-print-cfg-graph: Print CFG graph per-Region</a></li><li><a href=#-print-op-graph-print-op-graph-per-region>-print-op-graph: Print op graph per-Region</a></li><li><a href=#-print-op-stats-print-statistics-of-operations>-print-op-stats: Print statistics of operations</a></li><li><a href=#-snapshot-op-locations-generate-new-locations-from-the-current-ir>-snapshot-op-locations: Generate new locations from the current IR</a></li><li><a href=#-strip-debuginfo-strip-debug-info-from-all-operations>-strip-debuginfo: Strip debug info from all operations</a></li><li><a href=#-symbol-dce-eliminate-dead-symbols>-symbol-dce: Eliminate dead symbols</a></li></ul></li><li><a href=#conversion-passes>Conversion Passes</a><ul><li><a href=#-convert-avx512-to-llvm-convert-the-operations-from-the-avx512-dialect-into-the-llvm-dialect>-convert-avx512-to-llvm: Convert the operations from the avx512 dialect into the LLVM dialect</a></li><li><a href=#-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call>-convert-gpu-launch-to-vulkan-launch: Convert gpu.launch_func to vulkanLaunch external call</a></li><li><a href=#-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations>-convert-gpu-to-nvvm: Generate NVVM operations for gpu operations</a></li><li><a href=#-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations>-convert-gpu-to-rocdl: Generate ROCDL operations for gpu operations</a></li><li><a href=#-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect>-convert-gpu-to-spirv: Convert GPU dialect to SPIR-V dialect</a></li><li><a href=#-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect>-convert-linalg-to-llvm: Convert the operations from the linalg dialect into the LLVM dialect</a></li><li><a href=#-convert-linalg-to-spirv-convert-linalg-ops-to-spir-v-ops>-convert-linalg-to-spirv: Convert Linalg ops to SPIR-V ops</a></li><li><a href=#-convert-loop-op-to-gpu-convert-top-level-loopforop-to-gpu-kernels>-convert-loop-op-to-gpu: Convert top-level loop::ForOp to GPU kernels</a></li><li><a href=#-convert-loop-to-std-convert-loop-dialect-to-standard-dialect-replacing-structured-control-flow-with-a-cfg>-convert-loop-to-std: Convert Loop dialect to Standard dialect, replacing structured control flow with a CFG</a></li><li><a href=#-convert-loops-to-gpu-convert-top-level-loops-to-gpu-kernels>-convert-loops-to-gpu: Convert top-level loops to GPU kernels</a></li><li><a href=#-convert-parallel-loops-to-gpu-convert-mapped-loopparallel-ops-to-gpu-launch-operations>-convert-parallel-loops-to-gpu: Convert mapped loop.parallel ops to gpu launch operations</a></li><li><a href=#-convert-std-to-llvm-convert-scalar-and-vector-operations-from-the-standard-to-the-llvm-dialect>-convert-std-to-llvm: Convert scalar and vector operations from the Standard to the LLVM dialect</a></li><li><a href=#-convert-std-to-spirv-convert-standard-ops-to-spir-v-dialect>-convert-std-to-spirv: Convert Standard Ops to SPIR-V dialect</a></li><li><a href=#-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect>-convert-vector-to-llvm: Lower the operations from the vector dialect into the LLVM dialect</a></li><li><a href=#-launch-func-to-cuda-convert-all-launch_func-ops-to-cuda-runtime-calls>-launch-func-to-cuda: Convert all launch_func ops to CUDA runtime calls</a></li><li><a href=#-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls>-launch-func-to-vulkan: Convert vulkanLaunch external call to Vulkan runtime external calls</a></li><li><a href=#-legalize-std-for-spirv-legalize-standard-ops-for-spir-v-lowering>-legalize-std-for-spirv: Legalize standard ops for SPIR-V lowering</a></li><li><a href=#-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-loop-operations>-lower-affine: Lower Affine operations to a combination of Standard and Loop operations</a></li></ul></li><li><a href=#affine-dialect-passes>affine Dialect Passes</a><ul><li><a href=#-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations>-affine-data-copy-generate: Generate explicit copying for affine memory operations</a></li><li><a href=#-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops>-affine-loop-invariant-code-motion: Hoist loop invariant instructions outside of affine loops</a></li><li><a href=#-affine-loop-tile-tile-affine-loop-nests>-affine-loop-tile: Tile affine loop nests</a></li><li><a href=#-affine-loop-unroll-unroll-affine-loops>-affine-loop-unroll: Unroll affine loops</a></li><li><a href=#-affine-loop-unroll-jam-unroll-and-jam-affine-loops>-affine-loop-unroll-jam: Unroll and jam affine loops</a></li><li><a href=#-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction>-affine-super-vectorize: Vectorize to a target independent n-D vector abstraction</a></li><li><a href=#-simplify-affine-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs>-simplify-affine-structures: Simplify affine expressions in maps/sets and normalize memrefs</a></li></ul></li><li><a href=#gpu-dialect-passes>gpu Dialect Passes</a><ul><li><a href=#-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions>-gpu-kernel-outlining: Outline gpu.launch bodies to kernel functions</a></li></ul></li><li><a href=#linalg-dialect-passes>linalg Dialect Passes</a><ul><li><a href=#-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops>-convert-linalg-to-affine-loops: Lower the operations from the linalg dialect into affine loops</a></li><li><a href=#-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops>-convert-linalg-to-loops: Lower the operations from the linalg dialect into loops</a></li><li><a href=#-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops>-convert-linalg-to-parallel-loops: Lower the operations from the linalg dialect into parallel loops</a></li><li><a href=#-linalg-fusion-fuse-operations-in-the-linalg-dialect>-linalg-fusion: Fuse operations in the linalg dialect</a></li><li><a href=#-linalg-fusion-for-tensor-ops-fuse-operations-on-rankedtensortype-in-linalg-dialect>-linalg-fusion-for-tensor-ops: Fuse operations on RankedTensorType in linalg dialect</a></li><li><a href=#-linalg-promote-subviews-promote-subview-ops-to-local-buffers>-linalg-promote-subviews: Promote subview ops to local buffers</a></li><li><a href=#-linalg-tile-tile-operations-in-the-linalg-dialect>-linalg-tile: Tile operations in the linalg dialect</a></li><li><a href=#-linalg-tile-to-parallel-loops-tile-operations-in-the-linalg-dialect-to-parallel-loops>-linalg-tile-to-parallel-loops: Tile operations in the linalg dialect to parallel loops</a></li></ul></li><li><a href=#llvm-dialect-passes>llvm Dialect Passes</a><ul><li><a href=#-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir>-llvm-legalize-for-export: Legalize LLVM dialect to be convertible to LLVM IR</a></li></ul></li><li><a href=#loop-dialect-passes>loop Dialect Passes</a><ul><li><a href=#-parallel-loop-fusion-fuse-adjacent-parallel-loops>-parallel-loop-fusion: Fuse adjacent parallel loops</a></li><li><a href=#-parallel-loop-specialization-specialize-parallel-loops-for-vectorization>-parallel-loop-specialization: Specialize parallel loops for vectorization</a></li><li><a href=#-parallel-loop-tiling-tile-parallel-loops>-parallel-loop-tiling: Tile parallel loops</a></li></ul></li><li><a href=#quant-dialect-passes>quant Dialect Passes</a><ul><li><a href=#-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values>-quant-convert-const: Converts constants followed by qbarrier to actual quantized values</a></li><li><a href=#-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts>-quant-convert-simulated-quantization: Converts training-time simulated quantization ops to corresponding quantize/dequantize casts</a></li></ul></li><li><a href=#spv-dialect-passes>spv Dialect Passes</a><ul><li><a href=#-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info>-decorate-spirv-composite-type-layout: Decorate SPIR-V composite type with layout info</a></li><li><a href=#-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info>-spirv-lower-abi-attrs: Decorate SPIR-V composite type with layout info</a></li><li><a href=#-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops>-spirv-update-vce: Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops</a></li></ul></li></ul></nav><h2 id=general-transformation-passes>General Transformation Passes&nbsp;<a class=headline-hash href=#general-transformation-passes>¶</a></h2><h3 id=-affine-loop-fusion-fuse-affine-loop-nests><code>-affine-loop-fusion</code>: Fuse affine loop nests&nbsp;<a class=headline-hash href=#-affine-loop-fusion-fuse-affine-loop-nests>¶</a></h3><h4 id=options>Options&nbsp;<a class=headline-hash href=#options>¶</a></h4><pre><code>-fusion-compute-tolerance   : Fractional increase in additional computation tolerated while fusing
-fusion-fast-mem-space      : Faster memory space number to promote fusion buffers to
-fusion-local-buf-threshold : Threshold size (KiB) for promoting local buffers to fast memory space
-fusion-maximal             : Enables maximal loop fusion
</code></pre><h3 id=-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy><code>-affine-pipeline-data-transfer</code>: Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy&nbsp;<a class=headline-hash href=#-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy>¶</a></h3><p>This pass performs a transformation to overlap non-blocking DMA operations
in a loop with computations through double buffering. This is achieved by
advancing dma_start operations with respect to other operations.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
  <span class=nv>%c128</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>8</span> <span class=p>{</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%4</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
    <span class=nv>%c8</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>8</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%c0_0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c128</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>1</span> to <span class=m>8</span> <span class=p>{</span>
      affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%8</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>)</span>
      <span class=nv>%9</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      <span class=nv>%10</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%11</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
      <span class=nv>%12</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%11</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%12</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=p>}</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%c8</span><span class=p>)</span>
    <span class=nv>%4</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    <span class=nv>%5</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%6</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%7</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%6</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%7</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    dealloc <span class=nv>%2</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=kt>return</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><h3 id=-canonicalize-canonicalize-operations><code>-canonicalize</code>: Canonicalize operations&nbsp;<a class=headline-hash href=#-canonicalize-canonicalize-operations>¶</a></h3><p>This pass performs various types of canonicalizations over a set of
operations. See
<a href=/docs/Canonicalization/>Operation Canonicalization</a>
for more
details.</p><h3 id=-cse-eliminate-common-sub-expressions><code>-cse</code>: Eliminate common sub-expressions&nbsp;<a class=headline-hash href=#-cse-eliminate-common-sub-expressions>¶</a></h3><p>This pass implements a generalized algorithm for common sub-expression
elimination. This pass relies on information provided by the
<code>Memory SideEffect</code> interface to identify when it is safe to eliminate
operations. See
<a href=https://en.wikipedia.org/wiki/Common_subexpression_elimination>Common subexpression elimination</a>
for more general details on this optimization.</p><h4 id=statistics>Statistics&nbsp;<a class=headline-hash href=#statistics>¶</a></h4><pre><code>num-cse'd : Number of operations CSE'd
num-dce'd : Number of operations DCE'd
</code></pre><h3 id=-inline-inline-function-calls><code>-inline</code>: Inline function calls&nbsp;<a class=headline-hash href=#-inline-inline-function-calls>¶</a></h3><h4 id=options-1>Options&nbsp;<a class=headline-hash href=#options-1>¶</a></h4><pre><code>-disable-simplify : Disable running simplifications during inlining
-max-iterations   : Maximum number of iterations when inlining within an SCC
</code></pre><h3 id=-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop><code>-loop-coalescing</code>: Coalesce nested loops with independent bounds into a single loop&nbsp;<a class=headline-hash href=#-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop>¶</a></h3><h3 id=-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop><code>-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of the loop&nbsp;<a class=headline-hash href=#-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop>¶</a></h3><h3 id=-memref-dataflow-opt-perform-storeload-forwarding-for-memrefs><code>-memref-dataflow-opt</code>: Perform store/load forwarding for memrefs&nbsp;<a class=headline-hash href=#-memref-dataflow-opt-perform-storeload-forwarding-for-memrefs>¶</a></h3><p>This pass performs store to load forwarding for memref&rsquo;s to eliminate memory
accesses and potentially the entire memref if all its accesses are
forwarded.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
  <span class=nv>%cf7</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>7.0</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%m</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>store <span class=nv>%cf7</span><span class=p>,</span> <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v1</span> <span class=p>=</span> addf <span class=nv>%v0</span><span class=p>,</span> <span class=nv>%v0</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span> <span class=nv>%m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
    <span class=nv>%cst</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>7.000000e+00</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>for <span class=nv>%arg1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
        affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
        <span class=nv>%1</span> <span class=p>=</span> addf <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%cst</span> <span class=p>:</span> <span class=k>f32</span>
      <span class=p>}</span>
    <span class=p>}</span>
    <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><h3 id=-parallel-loop-collapsing-collapse-parallel-loops-to-use-less-induction-variables><code>-parallel-loop-collapsing</code>: Collapse parallel loops to use less induction variables&nbsp;<a class=headline-hash href=#-parallel-loop-collapsing-collapse-parallel-loops-to-use-less-induction-variables>¶</a></h3><h4 id=options-2>Options&nbsp;<a class=headline-hash href=#options-2>¶</a></h4><pre><code>-collapsed-indices-0 : Which loop indices to combine 0th loop index
-collapsed-indices-1 : Which loop indices to combine into the position 1 loop index
-collapsed-indices-2 : Which loop indices to combine into the position 2 loop index
</code></pre><h3 id=-print-cfg-graph-print-cfg-graph-per-region><code>-print-cfg-graph</code>: Print CFG graph per-Region&nbsp;<a class=headline-hash href=#-print-cfg-graph-print-cfg-graph-per-region>¶</a></h3><h3 id=-print-op-graph-print-op-graph-per-region><code>-print-op-graph</code>: Print op graph per-Region&nbsp;<a class=headline-hash href=#-print-op-graph-print-op-graph-per-region>¶</a></h3><h3 id=-print-op-stats-print-statistics-of-operations><code>-print-op-stats</code>: Print statistics of operations&nbsp;<a class=headline-hash href=#-print-op-stats-print-statistics-of-operations>¶</a></h3><h3 id=-snapshot-op-locations-generate-new-locations-from-the-current-ir><code>-snapshot-op-locations</code>: Generate new locations from the current IR&nbsp;<a class=headline-hash href=#-snapshot-op-locations-generate-new-locations-from-the-current-ir>¶</a></h3><p>This pass allows for generating new locations from the IR during any stage
of compilation, by snapshotting the IR to a file and using that file to
generate new locations for the operations.</p><p>Depending on the value of the <code>tag</code> option, different resulting locations
may be generated:</p><ul><li>If unset, the original location of the operation is replaced.</li></ul><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// old:
</span><span class=c></span><span class=p>.</span><span class=p>.</span><span class=p>.</span> <span class=kt>loc</span><span class=p>(</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>)</span>

<span class=c>// new:
</span><span class=c></span><span class=p>.</span><span class=p>.</span><span class=p>.</span> <span class=kt>loc</span><span class=p>(</span><span class=s>&#34;snapshot_source.mlir&#34;</span><span class=p>:</span><span class=m>10</span><span class=p>:</span><span class=m>10</span><span class=p>)</span>
</code></pre></div><ul><li>If set, the new location is fused with the original location in the form
of a
<a href=/docs/Diagnostics/#name-location><code>Name Location</code></a>
with the specified tag.</li></ul><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// old:
</span><span class=c></span><span class=p>.</span><span class=p>.</span><span class=p>.</span> <span class=kt>loc</span><span class=p>(</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>)</span>

<span class=c>// new:
</span><span class=c></span><span class=p>.</span><span class=p>.</span><span class=p>.</span> <span class=kt>loc</span><span class=p>(</span>fused<span class=p>[</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>,</span> <span class=s>&#34;snapshot&#34;</span><span class=p>(</span><span class=s>&#34;snapshot_source.mlir&#34;</span><span class=p>:</span><span class=m>10</span><span class=p>:</span><span class=m>10</span><span class=p>)</span><span class=p>]</span><span class=p>)</span>
</code></pre></div><h4 id=options-3>Options&nbsp;<a class=headline-hash href=#options-3>¶</a></h4><pre><code>-filename : The filename to print the generated IR
-tag      : A tag to use when fusing the new locations with the original. If unset, the locations are replaced.
</code></pre><h3 id=-strip-debuginfo-strip-debug-info-from-all-operations><code>-strip-debuginfo</code>: Strip debug info from all operations&nbsp;<a class=headline-hash href=#-strip-debuginfo-strip-debug-info-from-all-operations>¶</a></h3><p>This pass strips the IR of any location information, by replacing all
operation locations with
<a href=/docs/Diagnostics/#unknown-location><code>unknown</code></a>
.</p><h3 id=-symbol-dce-eliminate-dead-symbols><code>-symbol-dce</code>: Eliminate dead symbols&nbsp;<a class=headline-hash href=#-symbol-dce-eliminate-dead-symbols>¶</a></h3><p>This pass deletes all symbols that are found to be unreachable. This is done
by computing the set of operations that are known to be live, propagating
that liveness to other symbols, and then deleting all symbols that are not
within this live set. Live symbols are those that have a
<a href=/docs/SymbolsAndSymbolTables/#symbol-visibility>visibility</a>
that extends
beyond the IR, e.g. <code>public</code>, or those that are referenced by live symbols
or other non-Symbol operations.</p><p>For example, consider the following input:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@dead_private_function</span><span class=p>(</span><span class=p>)</span> attributes <span class=p>{</span> <span class=nl>sym_visibility =</span> <span class=s>&#34;private&#34;</span> <span class=p>}</span>
<span class=kt>func</span> <span class=nf>@live_private_function</span><span class=p>(</span><span class=p>)</span> attributes <span class=p>{</span> <span class=nl>sym_visibility =</span> <span class=s>&#34;private&#34;</span> <span class=p>}</span>

<span class=c>// Note: The `public` isn&#39;t necessary here, as this is the default.
</span><span class=c></span><span class=kt>func</span> <span class=nf>@public_function</span><span class=p>(</span><span class=p>)</span> attributes <span class=p>{</span> <span class=nl>sym_visibility =</span> <span class=s>&#34;public&#34;</span> <span class=p>}</span> <span class=p>{</span>
  <span class=s>&#34;foo.return&#34;</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span><span class=nl>uses =</span> <span class=p>[</span><span class=nf>@live_private_function</span><span class=p>]</span><span class=p>}</span> <span class=p>:</span> <span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></div><p>A known live function, <code>public_function</code>, contains a reference to an
otherwise non-live function <code>live_private_function</code>. After running
<code>symbol-dce</code>, only these two symbols should remain, as the final symbol
<code>dead_private_function</code> is not visible outside of the current IR and there
are no links to known-live operations. After running, we get the expected:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@live_private_function</span><span class=p>(</span><span class=p>)</span> attributes <span class=p>{</span> <span class=nl>sym_visibility =</span> <span class=s>&#34;private&#34;</span> <span class=p>}</span>

<span class=kt>func</span> <span class=nf>@public_function</span><span class=p>(</span><span class=p>)</span> attributes <span class=p>{</span> <span class=nl>sym_visibility =</span> <span class=s>&#34;public&#34;</span> <span class=p>}</span> <span class=p>{</span>
  <span class=s>&#34;foo.return&#34;</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span><span class=nl>uses =</span> <span class=p>[</span><span class=nf>@live_private_function</span><span class=p>]</span><span class=p>}</span> <span class=p>:</span> <span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></div><p>See
<a href=/docs/SymbolsAndSymbolTables/>Symbols and SymbolTables</a>
for more
information on <code>Symbols</code>.</p><h2 id=conversion-passes>Conversion Passes&nbsp;<a class=headline-hash href=#conversion-passes>¶</a></h2><h3 id=-convert-avx512-to-llvm-convert-the-operations-from-the-avx512-dialect-into-the-llvm-dialect><code>-convert-avx512-to-llvm</code>: Convert the operations from the avx512 dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-avx512-to-llvm-convert-the-operations-from-the-avx512-dialect-into-the-llvm-dialect>¶</a></h3><h3 id=-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call><code>-convert-gpu-launch-to-vulkan-launch</code>: Convert gpu.launch_func to vulkanLaunch external call&nbsp;<a class=headline-hash href=#-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call>¶</a></h3><h3 id=-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations><code>-convert-gpu-to-nvvm</code>: Generate NVVM operations for gpu operations&nbsp;<a class=headline-hash href=#-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations>¶</a></h3><h3 id=-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations><code>-convert-gpu-to-rocdl</code>: Generate ROCDL operations for gpu operations&nbsp;<a class=headline-hash href=#-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations>¶</a></h3><h3 id=-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect><code>-convert-gpu-to-spirv</code>: Convert GPU dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect>¶</a></h3><h3 id=-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect><code>-convert-linalg-to-llvm</code>: Convert the operations from the linalg dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect>¶</a></h3><h3 id=-convert-linalg-to-spirv-convert-linalg-ops-to-spir-v-ops><code>-convert-linalg-to-spirv</code>: Convert Linalg ops to SPIR-V ops&nbsp;<a class=headline-hash href=#-convert-linalg-to-spirv-convert-linalg-ops-to-spir-v-ops>¶</a></h3><h3 id=-convert-loop-op-to-gpu-convert-top-level-loopforop-to-gpu-kernels><code>-convert-loop-op-to-gpu</code>: Convert top-level loop::ForOp to GPU kernels&nbsp;<a class=headline-hash href=#-convert-loop-op-to-gpu-convert-top-level-loopforop-to-gpu-kernels>¶</a></h3><h4 id=options-4>Options&nbsp;<a class=headline-hash href=#options-4>¶</a></h4><pre><code>-gpu-num-workgroups : Num workgroups in the GPU launch
-gpu-workgroup-size : Workgroup Size in the GPU launch
</code></pre><h3 id=-convert-loop-to-std-convert-loop-dialect-to-standard-dialect-replacing-structured-control-flow-with-a-cfg><code>-convert-loop-to-std</code>: Convert Loop dialect to Standard dialect, replacing structured control flow with a CFG&nbsp;<a class=headline-hash href=#-convert-loop-to-std-convert-loop-dialect-to-standard-dialect-replacing-structured-control-flow-with-a-cfg>¶</a></h3><h3 id=-convert-loops-to-gpu-convert-top-level-loops-to-gpu-kernels><code>-convert-loops-to-gpu</code>: Convert top-level loops to GPU kernels&nbsp;<a class=headline-hash href=#-convert-loops-to-gpu-convert-top-level-loops-to-gpu-kernels>¶</a></h3><h4 id=options-5>Options&nbsp;<a class=headline-hash href=#options-5>¶</a></h4><pre><code>-gpu-block-dims  : Number of GPU block dimensions for mapping
-gpu-thread-dims : Number of GPU thread dimensions for mapping
</code></pre><h3 id=-convert-parallel-loops-to-gpu-convert-mapped-loopparallel-ops-to-gpu-launch-operations><code>-convert-parallel-loops-to-gpu</code>: Convert mapped loop.parallel ops to gpu launch operations&nbsp;<a class=headline-hash href=#-convert-parallel-loops-to-gpu-convert-mapped-loopparallel-ops-to-gpu-launch-operations>¶</a></h3><h3 id=-convert-std-to-llvm-convert-scalar-and-vector-operations-from-the-standard-to-the-llvm-dialect><code>-convert-std-to-llvm</code>: Convert scalar and vector operations from the Standard to the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-std-to-llvm-convert-scalar-and-vector-operations-from-the-standard-to-the-llvm-dialect>¶</a></h3><p>Convert standard operations into the LLVM IR dialect operations.</p><h4 id=input-invariant>Input invariant&nbsp;<a class=headline-hash href=#input-invariant>¶</a></h4><ul><li>operations including: arithmetic on integers and floats, constants,
direct calls, returns and branches;</li><li>no <code>tensor</code> types;</li><li>all <code>vector</code> are one-dimensional;</li><li>all blocks are reachable by following the successors of the first basic
block;</li></ul><p>If other operations are present and their results are required by the LLVM
IR dialect operations, the pass will fail. Any LLVM IR operations or types
already present in the IR will be kept as is.</p><h4 id=output-ir>Output IR&nbsp;<a class=headline-hash href=#output-ir>¶</a></h4><p>Functions converted to LLVM IR. Function arguments types are converted
one-to-one. Function results are converted one-to-one and, in case more than
1 value is returned, packed into an LLVM IR struct type. Function calls and
returns are updated accordingly. Block argument types are updated to use
LLVM IR types.</p><h4 id=options-6>Options&nbsp;<a class=headline-hash href=#options-6>¶</a></h4><pre><code>-use-aligned-alloc             : Use aligned_alloc in place of malloc for heap allocations
-use-bare-ptr-memref-call-conv : Replace FuncOp's MemRef arguments with bare pointers to the MemRef element types
-emit-c-wrappers               : Emit wrappers for C-compatible pointer-to-struct memref descriptors
-index-bitwidth                : Bitwidth of the index type, 0 to use size of machine word
</code></pre><h3 id=-convert-std-to-spirv-convert-standard-ops-to-spir-v-dialect><code>-convert-std-to-spirv</code>: Convert Standard Ops to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-std-to-spirv-convert-standard-ops-to-spir-v-dialect>¶</a></h3><h3 id=-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect><code>-convert-vector-to-llvm</code>: Lower the operations from the vector dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect>¶</a></h3><h3 id=-launch-func-to-cuda-convert-all-launch_func-ops-to-cuda-runtime-calls><code>-launch-func-to-cuda</code>: Convert all launch_func ops to CUDA runtime calls&nbsp;<a class=headline-hash href=#-launch-func-to-cuda-convert-all-launch_func-ops-to-cuda-runtime-calls>¶</a></h3><h3 id=-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls><code>-launch-func-to-vulkan</code>: Convert vulkanLaunch external call to Vulkan runtime external calls&nbsp;<a class=headline-hash href=#-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls>¶</a></h3><h3 id=-legalize-std-for-spirv-legalize-standard-ops-for-spir-v-lowering><code>-legalize-std-for-spirv</code>: Legalize standard ops for SPIR-V lowering&nbsp;<a class=headline-hash href=#-legalize-std-for-spirv-legalize-standard-ops-for-spir-v-lowering>¶</a></h3><h3 id=-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-loop-operations><code>-lower-affine</code>: Lower Affine operations to a combination of Standard and Loop operations&nbsp;<a class=headline-hash href=#-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-loop-operations>¶</a></h3><p>Convert operations from the affine dialect into operations from the loop and
standard dialects.</p><p><code>affine.for</code> operations are converted to <code>loop.for</code> operations that are free
of certain structural restrictions (on their bounds and step). <code>affine.if</code>
is similarly converted to the <code>loop.if</code> operation. <code>affine.apply</code> operations
are converted into sequences of primitive arithmetic operations from the
standard dialect that have the same effect, using operands of the <code>index</code>
type. Consequently, named maps and sets thare are no longer in use may be
removed from the module.</p><p>For example, <code>%r = affine.apply affine_map&lt;(d0, d1)[s0] -> (d0 + 2*d1 + s0)>(%d0, %d1)[%s0]</code>
can be converted into:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%d0</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%d1</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%s0</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>2</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%1</span> <span class=p>=</span> muli <span class=nv>%0</span><span class=p>,</span> <span class=nv>%d1</span>
<span class=nv>%2</span> <span class=p>=</span> addi <span class=nv>%d0</span><span class=p>,</span> <span class=nv>%1</span>
<span class=nv>%r</span> <span class=p>=</span> addi <span class=nv>%2</span><span class=p>,</span> <span class=nv>%s0</span>
</code></pre></div><h4 id=input-invariant-1>Input invariant&nbsp;<a class=headline-hash href=#input-invariant-1>¶</a></h4><ul><li>no <code>Tensor</code> types;</li></ul><p>These restrictions may be lifted in the future.</p><h4 id=output-ir-1>Output IR&nbsp;<a class=headline-hash href=#output-ir-1>¶</a></h4><p>Functions with <code>affine.for</code> and <code>affine.if</code> operations eliminated. These
functions may contain operations from the Standard dialect in addition to
those already present before the pass.</p><h4 id=invariants>Invariants&nbsp;<a class=headline-hash href=#invariants>¶</a></h4><ul><li>Functions without a body are not modified.</li><li>The semantics of the other functions is preserved.</li><li>Individual operations other than those mentioned above are not modified
if they do not depend on the loop iterator value or on the result of
<code>affine.apply</code>.</li></ul><h2 id=affine-dialect-passes><code>affine</code> Dialect Passes&nbsp;<a class=headline-hash href=#affine-dialect-passes>¶</a></h2><h3 id=-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations><code>-affine-data-copy-generate</code>: Generate explicit copying for affine memory operations&nbsp;<a class=headline-hash href=#-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations>¶</a></h3><h4 id=options-7>Options&nbsp;<a class=headline-hash href=#options-7>¶</a></h4><pre><code>-fast-mem-capacity          : Set fast memory space capacity in KiB (default: unlimited)
-fast-mem-space             : Fast memory space identifier for copy generation (default: 1)
-generate-dma               : Generate DMA instead of point-wise copy
-min-dma-transfer           : Minimum DMA transfer size supported by the target in bytes
-slow-mem-space             : Slow memory space identifier for copy generation (default: 0)
-skip-non-unit-stride-loops : Testing purposes: avoid non-unit stride loop choice depths for copy placement
-tag-mem-space              : Tag memory space identifier for copy generation (default: 0)
</code></pre><h3 id=-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops><code>-affine-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of affine loops&nbsp;<a class=headline-hash href=#-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops>¶</a></h3><h3 id=-affine-loop-tile-tile-affine-loop-nests><code>-affine-loop-tile</code>: Tile affine loop nests&nbsp;<a class=headline-hash href=#-affine-loop-tile-tile-affine-loop-nests>¶</a></h3><h4 id=options-8>Options&nbsp;<a class=headline-hash href=#options-8>¶</a></h4><pre><code>-cache-size : Set size of cache to tile for in KiB
-separate   : Separate full and partial tiles
-tile-size  : Use this tile size for all loops
-tile-sizes : List of tile sizes for each perfect nest (overridden by -tile-size)
</code></pre><h3 id=-affine-loop-unroll-unroll-affine-loops><code>-affine-loop-unroll</code>: Unroll affine loops&nbsp;<a class=headline-hash href=#-affine-loop-unroll-unroll-affine-loops>¶</a></h3><h4 id=options-9>Options&nbsp;<a class=headline-hash href=#options-9>¶</a></h4><pre><code>-unroll-factor         : Use this unroll factor for all loops being unrolled
-unroll-full           : Fully unroll loops
-unroll-num-reps       : Unroll innermost loops repeatedly this many times
-unroll-full-threshold : Unroll all loops with trip count less than or equal to this
</code></pre><h3 id=-affine-loop-unroll-jam-unroll-and-jam-affine-loops><code>-affine-loop-unroll-jam</code>: Unroll and jam affine loops&nbsp;<a class=headline-hash href=#-affine-loop-unroll-jam-unroll-and-jam-affine-loops>¶</a></h3><h4 id=options-10>Options&nbsp;<a class=headline-hash href=#options-10>¶</a></h4><pre><code>-unroll-jam-factor : Use this unroll jam factor for all loops (default 4)
</code></pre><h3 id=-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction><code>-affine-super-vectorize</code>: Vectorize to a target independent n-D vector abstraction&nbsp;<a class=headline-hash href=#-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction>¶</a></h3><h4 id=options-11>Options&nbsp;<a class=headline-hash href=#options-11>¶</a></h4><pre><code>-virtual-vector-size  : Specify an n-D virtual vector size for vectorization
-test-fastest-varying : Specify a 1-D, 2-D or 3-D pattern of fastest varying memory dimensions to match. See defaultPatterns in Vectorize.cpp for a description and examples. This is used for testing purposes
</code></pre><h3 id=-simplify-affine-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs><code>-simplify-affine-structures</code>: Simplify affine expressions in maps/sets and normalize memrefs&nbsp;<a class=headline-hash href=#-simplify-affine-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs>¶</a></h3><h2 id=gpu-dialect-passes><code>gpu</code> Dialect Passes&nbsp;<a class=headline-hash href=#gpu-dialect-passes>¶</a></h2><h3 id=-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions><code>-gpu-kernel-outlining</code>: Outline gpu.launch bodies to kernel functions&nbsp;<a class=headline-hash href=#-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions>¶</a></h3><h2 id=linalg-dialect-passes><code>linalg</code> Dialect Passes&nbsp;<a class=headline-hash href=#linalg-dialect-passes>¶</a></h2><h3 id=-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops><code>-convert-linalg-to-affine-loops</code>: Lower the operations from the linalg dialect into affine loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops>¶</a></h3><h3 id=-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops><code>-convert-linalg-to-loops</code>: Lower the operations from the linalg dialect into loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops>¶</a></h3><h3 id=-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops><code>-convert-linalg-to-parallel-loops</code>: Lower the operations from the linalg dialect into parallel loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops>¶</a></h3><h3 id=-linalg-fusion-fuse-operations-in-the-linalg-dialect><code>-linalg-fusion</code>: Fuse operations in the linalg dialect&nbsp;<a class=headline-hash href=#-linalg-fusion-fuse-operations-in-the-linalg-dialect>¶</a></h3><h3 id=-linalg-fusion-for-tensor-ops-fuse-operations-on-rankedtensortype-in-linalg-dialect><code>-linalg-fusion-for-tensor-ops</code>: Fuse operations on RankedTensorType in linalg dialect&nbsp;<a class=headline-hash href=#-linalg-fusion-for-tensor-ops-fuse-operations-on-rankedtensortype-in-linalg-dialect>¶</a></h3><h3 id=-linalg-promote-subviews-promote-subview-ops-to-local-buffers><code>-linalg-promote-subviews</code>: Promote subview ops to local buffers&nbsp;<a class=headline-hash href=#-linalg-promote-subviews-promote-subview-ops-to-local-buffers>¶</a></h3><h4 id=options-12>Options&nbsp;<a class=headline-hash href=#options-12>¶</a></h4><pre><code>-test-promote-dynamic : Test generation of dynamic promoted buffers
</code></pre><h3 id=-linalg-tile-tile-operations-in-the-linalg-dialect><code>-linalg-tile</code>: Tile operations in the linalg dialect&nbsp;<a class=headline-hash href=#-linalg-tile-tile-operations-in-the-linalg-dialect>¶</a></h3><h4 id=options-13>Options&nbsp;<a class=headline-hash href=#options-13>¶</a></h4><pre><code>-linalg-tile-sizes : Test generation of dynamic promoted buffers
</code></pre><h3 id=-linalg-tile-to-parallel-loops-tile-operations-in-the-linalg-dialect-to-parallel-loops><code>-linalg-tile-to-parallel-loops</code>: Tile operations in the linalg dialect to parallel loops&nbsp;<a class=headline-hash href=#-linalg-tile-to-parallel-loops-tile-operations-in-the-linalg-dialect-to-parallel-loops>¶</a></h3><h4 id=options-14>Options&nbsp;<a class=headline-hash href=#options-14>¶</a></h4><pre><code>-linalg-tile-sizes : Test generation of dynamic promoted buffers
</code></pre><h2 id=llvm-dialect-passes><code>llvm</code> Dialect Passes&nbsp;<a class=headline-hash href=#llvm-dialect-passes>¶</a></h2><h3 id=-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir><code>-llvm-legalize-for-export</code>: Legalize LLVM dialect to be convertible to LLVM IR&nbsp;<a class=headline-hash href=#-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir>¶</a></h3><h2 id=loop-dialect-passes><code>loop</code> Dialect Passes&nbsp;<a class=headline-hash href=#loop-dialect-passes>¶</a></h2><h3 id=-parallel-loop-fusion-fuse-adjacent-parallel-loops><code>-parallel-loop-fusion</code>: Fuse adjacent parallel loops&nbsp;<a class=headline-hash href=#-parallel-loop-fusion-fuse-adjacent-parallel-loops>¶</a></h3><h3 id=-parallel-loop-specialization-specialize-parallel-loops-for-vectorization><code>-parallel-loop-specialization</code>: Specialize parallel loops for vectorization&nbsp;<a class=headline-hash href=#-parallel-loop-specialization-specialize-parallel-loops-for-vectorization>¶</a></h3><h3 id=-parallel-loop-tiling-tile-parallel-loops><code>-parallel-loop-tiling</code>: Tile parallel loops&nbsp;<a class=headline-hash href=#-parallel-loop-tiling-tile-parallel-loops>¶</a></h3><h4 id=options-15>Options&nbsp;<a class=headline-hash href=#options-15>¶</a></h4><pre><code>-parallel-loop-tile-sizes : Factors to tile parallel loops by
</code></pre><h2 id=quant-dialect-passes><code>quant</code> Dialect Passes&nbsp;<a class=headline-hash href=#quant-dialect-passes>¶</a></h2><h3 id=-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values><code>-quant-convert-const</code>: Converts constants followed by qbarrier to actual quantized values&nbsp;<a class=headline-hash href=#-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values>¶</a></h3><h3 id=-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts><code>-quant-convert-simulated-quantization</code>: Converts training-time simulated quantization ops to corresponding quantize/dequantize casts&nbsp;<a class=headline-hash href=#-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts>¶</a></h3><h2 id=spv-dialect-passes><code>spv</code> Dialect Passes&nbsp;<a class=headline-hash href=#spv-dialect-passes>¶</a></h2><h3 id=-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info><code>-decorate-spirv-composite-type-layout</code>: Decorate SPIR-V composite type with layout info&nbsp;<a class=headline-hash href=#-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info>¶</a></h3><h3 id=-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info><code>-spirv-lower-abi-attrs</code>: Decorate SPIR-V composite type with layout info&nbsp;<a class=headline-hash href=#-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info>¶</a></h3><h3 id=-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops><code>-spirv-update-vce</code>: Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops&nbsp;<a class=headline-hash href=#-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops>¶</a></h3><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/PassManagement/ title="Pass Infrastructure"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Pass Infrastructure</a>
<a class="nav nav-next" href=/docs/Quantization/ title=Quantization>Next - Quantization <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=/docs/Dialects/Linalg/>'linalg' Dialect</a></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/LoopDialect/>'loop' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li><a href=/docs/Dialects/Standard/>'std' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li></ul></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'Const' in MLIR, for core IR types</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Tutorial Introduction</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/DefiningAttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li></ul></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li><a href=/docs/GenericDAGRewriter/>Generic DAG Rewriter Infrastructure</a></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/Traits/>Operation Traits</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li class=active><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/OpDefinitions/>Table-driven Operation Definition Specification (ODS)</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>